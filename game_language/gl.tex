\documentclass{article}

\input{../common/preamble}

\usepackage[T1]{fontenc}

\newcommand{\game}{\textsc{game}}
\newcommand{\play}{\textsc{play}}
\newcommand{\move}{\textsc{move}}
\newcommand{\team}{\textsc{team}}
\newcommand{\strategy}{\textsc{strategy}}

\begin{document}

\section{A language of games}
\label{sec:game-language}

\subsection{Terms}

In this section, we describe a general framework of the language of games.  
The underlying language we shall normally start with is the simply typed lambda calculus.  
To this, we fix a finite set $\A$ of countable sets and for each $A\in\A$ we add a type $\ul{A}$ to the language.  The types of the form $\ul{A}$ are called the \emph{ground types}.
We then add a set of constants to the language.  These take one of two forms:
\begin{description}
  \item[Value constants] A \emph{value constant} takes the form $\ul{a}\from\ul{A}$, where $A\in\A$ and $a\in A$.  For our purposes, we shall assume that our language includes a value constant for every element of every set $A\in\A$.
  \item[Function constants] Given $A\in\A$ and a type $T$, a \emph{function constant} takes the form $\ul{\phi}$, where $\phi$ is some function sending elements of $A$ to terms of type $T$.
\end{description}

\begin{example}
  In the usual presentation of PCF, we have a type $\nat=\ul{\bN}$.  Then numerals $\n$ are the value constants $\ul{n}$, while the terms $\suc\from\nat\to\nat$ and $\IfO_T\from\nat\to T\to T\to T$ are function constants corresponding to the functions
  \begin{gather*}
    \phi_\suc \from n \mapsto \ul{n + 1} \\
    \phi_{\IfO} \from n \mapsto \begin{cases}
      \lambda x . \lambda y . x & \text{if $n=0$} \\
      \lambda x . \lambda y . y & \text{otherwise}
    \end{cases}
  \end{gather*}
\end{example}

\begin{remark}
  Function constants may refer to other function constants.  To avoid circular definitions, define a directed graph on the set of function constants by drawing an edge from $\ul{\phi}$ to $\ul{\psi}$ if $\phi(n)$ contains an occurrence of $\ul{\psi}$ for some $n$.  We require that this graph be acyclic (in particular, having no loops) and that it be well-founded in the sense that there is no infinite sequence $\ul{\phi_1} \to \ul{\phi_2} \to \cdots$.
\end{remark}

This framework is enough to formalize simple deterministic languages such as PCF.  In order to turn it into a language that can model games, we shall add additional constants to our language:

\begin{definition}
  We fix a finite set $\P$ of \emph{players}.  
  
  \begin{description}
    \item[Move constants] A \emph{move constant} takes the form $S^b\from \ul{A}$, where $S\subset A$ is non-empty and $b\in\mathcal P$.
  \end{description}

  We read $S^b$ as `Player $b$ chooses a value from $S$'.

  Our language will be given by the tuple $(\A,\F, \M)$, where $\F$ the set of function constants and $\M$ the set of move constants.
\end{definition}

\begin{example}
  We can recover the language PCF by setting $\P = \{\RN{1}\}$ and defining numerals by $\n=\ul{n}$, using the function constants $\suc$ and $\IfO$ as defined above.  We can add a nondeterministic oracle to the language by setting $\wn = \bN^\RN{1}$.
\end{example}

\subsection{Operational semantics}

We define a notion of \emph{evaluation context} in the style of Felleisen:

\[
  C ::= \hole \mid C\; M\mid\ul{\phi}\;C
  \]
Here, $M$ ranges over terms in the language and $\ul{\phi}$ ranges over the function constants in $\F$.  We write $M=C[M']$ if the term $M$ is obtained from $C$ by replacing the unique occurrence of $\hole$ in $C$ with the term $M'$.

We call a program of ground type $\ul{A}$ a \emph{game}.  We call a subset $T\subset\P$ a \emph{team} and a subset $t\subset A$ a \emph{target}.

We now define a predicate $\Tct$ on terms as in Figure \ref{fig:big-step}.  
\begin{figure}
  \begin{mathpar}
    \inferrule*{b\in T \\ \exists a\in S\esuchthat C[\ul{a}]\Tct}{C[S^b]\Tct}
      \and \inferrule*{b \not\in T \\ \forall a\in S\esuchthat C[\ul{a}]\Tct}{C[S^b]\Tct}
      \and \inferrule*{C[M[N/x]]\Tct}{C[(\lambda x.M)N]\Tct}
      \and \inferrule*[right=$\ul{\phi}\in\F$]{C[\phi(a)]\Tct}{C[\ul{\phi}\;\ul{a}]\Tct}
  \end{mathpar}
  \caption{Big-step operational semantics for the language $(\A,\F,\M)$}
  \label{fig:big-step}
\end{figure}
To understand this semantics better, let's look at the small-step semantics defined in Figure \ref{fig:small-step}.
\begin{figure}
  \begin{mathpar}
    \inferrule*[left=move,right=$a\in S$]{ }{S^b\opto \ul{a}}
      \and \inferrule*[left=function]{ }{\ul{\phi}\;\ul{a}\opto\phi(a)}
      \and \inferrule*[left=beta-reduction]{ }{(\lambda x.M)N \opto M[N/x]}
      \and \inferrule*[left=context]{M \opto N}{C[M]\opto C[N]}
  \end{mathpar}
  \caption{Small-step operational semantics for the language $(\A,\F,\M)$}
  \label{fig:small-step}
\end{figure}
A term $M\from T$ now defines a game between team $T$ and the opposing team $\P\setminus T$ as follows: we evaluate the term step by step.  At each step, the proof that $M\opto M'$ must terminate with one of the three rules \rulename{move}, \rulename{function} or \rulename{beta-reduction}.  In the last two cases, there is a unique choice of reduction to make.  In the first case, there are multiple possibilities, one for each value $a\in S$.  

In such a case, if $b\in T$ then team $T$ are allowed to choose which value $a$ to use.  If $b\not\in T$, then the opposing team $\P\setminus T$ are allowed to choose.  Team $T$ wins if the term eventually converges to a value $\ul{a}$, where $a\in t$ and team $\P\setminus T$ wins if the term converges to $\ul{b}$, where $b\not\in t$.  Then the judgement $M\Tct$ precisely says that team $T$ has a strategy to ensure that the term $M$ ends up in $t$.  

\begin{example}
  Coming back to our nondeterministic PCF example, if $M\from\nat$ is a term, then the judgement that $M\teamconverge{\emptyset}{\{n\}}$ says that $M$ \emph{must converge} to $n$.  The judgement that $M\teamconverge{\{I\}}{\{n\}}$ says that $M$ \emph{may converge} to $n$.
\end{example}

We read $M\Tct$ as `Team $T$ can force the term $M$ into the target $t$'.

\begin{definition}[Observational equivalence]
  We define observational equivalence for a specified set $\T\subset\power(\P)$ of `friendly teams' and a specified set $\t \subset \prod_{A\in\A}\power(A)$ of specified targets.

  If $A\in\A$ and $M,M'\from\ul{A}$, we say that $M\equiv_e M'$ ($M$ is \emph{observationally equivalent to $M'$}) if for all teams $T\in\T$ and for all target sets $t\in\t$ we have $M\xrightarrow{T}t(A)$ if and only if $M'\xrightarrow{T}t(A)$.

  For general terms $M,M'$ of the same type, we say that $M\equiv_e M'$ if for all contexts $C$ such that $C[M],C[M']$ have ground type, $C[M]\equiv_e C[M']$.
\end{definition}

\begin{definition}[Observational order]
  Similarly, we say that a term $M$ is \emph{observationally less than or equal to} another term $M'$, and write $M\le_e M'$, if for all $T\in\T$ and for all $t\in\t$, $M\xrightarrow{T}t(A)$ implies $M'\xrightarrow{T}t(A)$.

  For general terms $M,M'$ of the same type, we say that $M\le_e M'$ if for all contexts $C$ such that $C[M],C[M']$ have ground type, $C[M]\le_e C[M']$.
\end{definition}

\begin{example}
  PCF with may equivalence is the case corresponding to the set $\T=\{\{\RN{1}\}\}$ and $\t=\{\bN\}$.
  
  PCF with must equivalence corresponds to $\T=\{\emptyset\}$ and $\t=\{\bN\}$.

  PCF with may-and-must equivalence corresponds to $\T=\{\emptyset, \{\RN{1}\}\}$ and $\t=\{\bN\}$..
\end{example}

\begin{lemma}
  Let $M,M:S$ be such that $M\le_e M'$, and let $F,F':S\to T$ be such that $F\le_e F'$.  
  Then $F M \le_e F' M'$.
\end{lemma}

\subsection{Recursion}

In order to recover the full language PCF, we need to add recursion combinators $\Y_T$ to our language, corresponding to the following small-step reduction:
\[
  \inferrule*[left=recursion]{ }{\Y_T M \opto M ( \Y_T M )}
  \]
giving us the big-step rule
\[
  \inferrule{C[M (\Y_T M)] \Tct}{C[\Y_T M] \Tct}
  \]
This rule introduces for the first time the possibility of \emph{divergence}, or non-termination.  
We will assume that a team $T$ never wants the program to diverge.  
We do not lose anything by making this assumption; indeed, we can model the predicate $M \xrightarrow{T} t \cup \{\bot\}$ (`Team $T$ has a strategy to force the term $M$ into the target $t$ or to make it diverge') as the negation of the predicate $M \xrightarrow{\P\setminus T}\A \setminus t$ (`The opposition to team $T$ has a strategy to force the term $M$ into the complement of the target $t$'): the games we are considering are all \emph{open} in the sense that they terminate after finitely many moves, so exactly one of the two teams has a strategy by the Gale-Stewart theorem.

It turns out that we can also model PCF -- and other languages we have constructed in this section -- as a subset of a larger language that does not involve any special recursion constants, but uses only the function, value and move constants that we have already introduced.  
The advantage of this is that, since function constants are not self-referential, they are much easier to model in a denotational semantics than recursion, which usually requires some order-theoretic properties of the underlying model.  
The only innovation we will need to make on the semantics side is to give denotational semantics for the move constants; this will be covered in Section \ref{sec:denotational-semantics}.

As an illustration of our technique, we show how PCF itself can be modelled inside another language.
First, we introduce a new function constant, $\iter_T\from \nat \to T \to (T \to T) \to T$, corresponding to iteration (realization of natural numbers as Church numerals).  
$\iter_T$ is defined by $\iter_T=\ul{\iota_T}$, where:
\[
  \iota_T(n) = \lambda z.\lambda s.\underbrace{s (s (s \cdots}_{n\text{ times}}z)\cdots))
    \]
In order to model divergence, we add special divergence constants $\Omega_T$ for each type $T$.  
We include no extra rules for these divergence constants; if we end up with $C[\Omega_T]$ for some context $C$, then we consider the term to be `stuck', and to have converged to no value.

Now let $M$ be a general PCF term (possibly involving instances of $\Y_T$ for some types $T$.  Since PCF is a deterministic language, if $M$ converges then it does so in a bounded number of steps $m$.  If we now replace each instance of $\Y_T$ in $M$ with the function
\[
  \lambda N.\iter_T\;\ul{m}\;\Omega_T N
  \]
then we claim that the term converges to the same value.  Indeed, we observe that $\iter_T\;\ul{m}\;\Omega_T N$ is equivalent to the term
\[
  \underbrace{N (N (N \cdots}_{m\text{ times}}\Omega_T)\cdots))
  \]
and is therefore itself equivalent to
\[
  N(\iter_T (\ul{m-1})\Omega_T N)
  \]
The term $\iter_T\;\ul{m}\;\Omega_T N$ therefore has the same behaviour as the term $\Y_T N$, except that the index $m$ decreases by $1$ each time we use the rule.  
Since the reduction of the term $N$ takes $m$ steps anyway, we will never `run out' of iterations.

However, although this allows us to model \emph{individual programs} in PCF, it does not allow us to model functions that may take an unbounded number of recursion steps depending on their argument.  
In particular, we cannot model $\Y_T$ itself using iteration alone.  
In order to do this, we add a nondeterministic oracle $\wn$ to the language, and using may-equivalence as our equivalence relation on terms.  
In our framework, this corresponds to adding a player so that $\P=\{\RN{1}\}$ and then setting $\wn = \mathbb N^{\RN{1}}$.
Then we can model $\Y_T$ as the term
\[
  \lambda N.\iter_T\;\wn\;\Omega_T N
  \]
Because of the may-equivalence, this now has the same operational semantics (within PCF) as our original $\Y_T$: if a PCF term converges, then it converges after $m$ steps for some $m$, and so there is the \emph{possibility} that the oracle $\wn$ will choose a large enough value such that the term must converge.  
So the term may converge to the same value as the original term with $\Y_T$.  
On the other hand, if a PCF term diverges, then there is no number we could replace the $\wn$ with that would cause the term to converge.  
In that case, for every $m$ that the oracle could choose, the term will eventually `run out' and reach the divergence term $\Omega_T$, at which point it will get stuck.

\begin{theorem}
  There is an embedding of the language
  \[
    \text{PCF} = \lambda + \mathbb N + \Y
    \]
  into the language
  \[
    \text{Nondeterministic iterative PCF} = \lambda + \mathbb N + \iter + \Omega + \wn
    \]
  under may-equivalence.  
  That is to say, there is an structurally-inductive map $r$ from PCF terms/contexts to terms/contexts of nondeterministic iterative PCF such that two PCF programs $M$ and $N$ are observationally equivalent if and only if the corresponding programs in nondeterministic iterative PCF are may-equivalent.
\end{theorem}

\begin{proof}
  The mapping $r$ replaces every instance of $\Y_T$ with $(\lambda N.\iter_T\;\wn\;\Omega_T N$).

  Note the following observational equivalence:
  \[
    \Y_T \equiv_e \lambda N.\iter\;\ul{m}\;(\Y_T N)\;N
    \]
  which holds for any $n$.  
  This is because both terms may converge 
\end{proof}

\section{\game{}s}

In this section, we define the notion of a \game, one of our two alternative formulations of our basic intuition of a `game'.

We fix some set $\P$ of players throughout.

\begin{definition}
  Let $A$ be a set.  
  A \emph{\game{} $\Gamma$ with result set $A$} is given by a tuple $(\M_\Gamma,P_\Gamma,J_\Gamma)$ where
  \begin{itemize}
    \item $\M_\Gamma$ is a set of \move{}s.
    \item $P_\Gamma$ is a prefix-closed set of finite sequences of pairs of the form $p\from m$, where $p\in\P$ is a player and $m\in\M_\Gamma$ is a move.  We define $T_\Gamma$, the set of \emph{terminal \play{}}s in $P_\Gamma$ to be the set of all $s\in P_\Gamma$ such that $sa\not\in P_\Gamma$ for any $a$.  
    \item $J_\Gamma\from T_\Gamma\to A$ is a judgement function that says what the result is after a complete sequence of moves.
  \end{itemize}
  such that
  \begin{itemize}
    \item There is always exactly one player whose turn it is.  
      Explicitly, if $sa,sb\in P_\Gamma$, then the moves $a$ and $b$ are made by the same player.
  \end{itemize}
\end{definition}

\begin{remark}
  $\Gamma$ may contain infinitely long chains of sequences of \move{}s.  
  In that case, there is no result value for the \play{}.
\end{remark}

\begin{remark}
  This construction gives rise to a monad $G$ on the category of (possibly large) sets, where a set $A$ is sent to the set $GA$ of games with result set $A$.  
  The natural transformation $GGA\to GA$ is the one that takes a game whose results are games with result set $A$, and forms a game that plays as follows: the players play through the first game; then, if and when they reach a terminal \play{}, they then play through the resulting game to reach a value in $A$.

  We will not make great use of this monad, but it will be implicit in a lot of what we do.  
  As we can model the powerset monad using nondeterministic strategies, so our game semantics will allow us to model this game monad.
\end{remark}

\begin{definition}
  Let $\Gamma$ be a game with result set $A$.  
  Let $T\subset \P$ be a team of players.  
  Then a $T$-strategy $S$ for $\Gamma$ is a prefix-closed subset of $P_\Gamma$ subject to the following rules:
  \begin{itemize}
    \item If $s\in S$ and $sa\in P_\Gamma$ is such that the move $a$ is made by a player \emph{not} in $T$, then $sa\in S$.
    \item If $sa,sb\in S$, and the moves $a,b$ are made by a player in $T$, then $a=b$.
    \item If $s\in S$ and there exists $sa\in P_\Gamma$ such that the move $a$ is made by a player in $T$, then there exists $b$ such that $sb\in P_\Gamma$.
  \end{itemize}
\end{definition}

\section{\game{}-Game Semantics}

\subsection{Arenas}

Our basic game semantics will be the one given in \cite{hoPcf}.  
The semantics we present will be an enrichment of the Hyland-Ong semantics obtained by attaching \game{}-moves on to a strategy.  

\begin{definition}
  An \emph{arena} is a triple $A=(M_A,\lambda_A,\ts_A)$ where
  \begin{itemize}
    \item $M_A$ is a countable set of \emph{moves}.
    \item $\lambda_A\from M_A\to\OP\times\QA$ designates each move as either a \emph{$P$-move} or an \emph{$O$-move} and as either a \emph{question} or an \emph{answer}.  
      We will often split $\lambda_A$ into its two parts
      \begin{gather}
        \lambda_A^{OP} = \pr_1\circ\lambda_A\from M_A\to\OP\\
        \lambda_A^{QA} = \pr_2\circ\lambda_A\from M_A\to\QA
      \end{gather}
    \item $\ts_A$ is an \emph{enabling relation} between $M_A+*$ and $M_A$ satisfying:
      \begin{description}
        \item[Alternation] If $a \ts_A b$ then $\lambda_A^{OP} (a) = \neg(\lambda_A^{OP}(b))$
        \item[Initial moves] If $*\ts_A a$ then $\lambda_A(a) = (O,Q)$ and for all $b\in M_A$, $b\not{\ts_A} a$.
        \item[Answers are enabled by questions] If $a,b\in M_A$ are such that $a \ts_A b$ and $\lambda_A^{QA}(b)=A$ then $\lambda_A^{QA}(a)=Q$.
      \end{description}
      We say that a move $a$ is \emph{initial} if $*\ts_A a$.
  \end{itemize}
\end{definition}

\subsection{Compound arenas}

Let $A,B$ be arenas.  
Then there are two main ways to combine $A$ and $B$ to make a new arena.  
The first forms the \emph{product} $A\times B$ of $A$ and $B$:
\begin{itemize}
  \item $M_{A\times B} = M_A + M_B$.
  \item $\lambda_{A\times B} = [\lambda_A, \lambda_B]$.  
  \item $x\ts_{A\times B} m$ if and only if $x\ts_A m$ or $x\ts_B m$.
\end{itemize}
The second forms the \emph{function space} $A \iimpl B$ from $A$ to $B$:
\begin{itemize}
  \item $M_{A\iimpl B} = M_A + M_B$.
  \item $\lambda_{A\iimpl B} = [(\neg\times\id)\circ\lambda_A,\lambda_B]$.  
  \item $x\ts_{A\iimpl B} m$ if and only if
    \begin{description}
      \item[either] $x\ts_B m$
      \item[or] $x\ne *$ and $x\ts_A m$
      \item[or] $*\ts_B x$ and $*\ts_A m$.
    \end{description}
\end{itemize}

\subsection{\game{}-strategies}

We now give our notion of a strategy, which will add the \game{}-theoretic data on to the usual definition of a strategy.  
We fix a set $\P$ of players.

\begin{definition}
  Let $\M$ be a set of \move{}s, and let $\lambda\from\M\to\P$ be a function saying which player makes each move.  We define a function $\lambda\from (M_A+\M)\to\OP\cup \P$ in the obvious way.  

  Let $A$ be an arena.  
  A \emph{\game{}-play} in $A$ is a sequence
  \[
    s \in (M_A + \M)^*
    \]
  (where we refer to elements of $M_A$ as $A$-moves and elements of $\M$ as \move{}s) together with a justification pointer from each non-initial $A$-move $a$ to an $A$-move $b$ occurring earlier in the sequence than $a$ such that $b\ts_A a$.  
  We refer to the sequence $s\vert_{M_A}$ of all the $A$-moves in $s$ as the \emph{shadow} of $s$.
  Furthermore, we require that $s$ satisfy the following properties:
  \begin{enumerate}[a)]
    \item The first move in $s$ is an initial move in $A$ (and therefore an $O$-question).
    \item If $tab\prefix s$, where $a$ is a $P$-move in $A$, then $b$ is an $O$-move in $A$.
    \item If $tab\prefix s$, where $a$ is an $O$-move in $A$, then $b$ is either a $P$-move in $A$ or a \move{}.
    \item If $tma\prefix s$, where $m$ is a \move{}, then $a$ is either a \move{} or an $O$-move in $A$.
  \end{enumerate}
\end{definition}

\begin{definition}
  A \emph{\game{}-strategy} $\sigma$ for an arena $A$ is a set $M_\sigma$ of moves, a function $\lambda_\sigma\from \M_\sigma\to\P$ and a non-empty prefix-closed set $\sigma$ of \game{}-plays in $A$ satisfying the following rules:
  \begin{enumerate}[a)]
    \item If $s\in\sigma$ and $sa$ is a \game{}-play in $A$ such that $a$ is an $O$-move in $A$, then $sa\in\sigma$.
    \item If $sa,sb\in\sigma$, where $a,b$ are $P$-moves in $A$, then $a=b$.
    \item If $s\in\sigma$ is non-empty and does not end with a $P$-move then there exists some $a\in M_A+\M_\sigma$ such that $sa\in\sigma$.
    \item If $sa,sb\in\sigma$, then $\lambda(a)=\lambda(b)$.
  \end{enumerate}
\end{definition}

\begin{remark}
  The axiom (b) for a strategy might make it look as though we can only model deterministic strategies, but we can in fact model nondeterministic strategies by using \move{}s.  
  For example, the denotation for a nondeterministic oracle $\wn$ might be the strategy with maximal plays
  \[
    q\textsc{n}n
    \]
  for all $n\in\bN$, where $\textsc{n}$ is a \move{} corresponding to the natural number $n$.
\end{remark}

\begin{definition}
  Let $\sigma$ be a strategy for an arena $A$.  
  We write $T_\sigma$, the \emph{trace-set} or \emph{shadow} of $\sigma$, for the set of all shadows of elements of $\sigma$.  
  It is easy to see that $T_\sigma$ is a nondeterministic strategy for $A$ in the usual sense.  
\end{definition}

\subsection{Ordering \game{}-strategies}

\begin{definition}
  Let $T\subset \P$ be a team of players.  
  Let $A$ be an arena and let $\sigma$ be a \game{}-strategy for $A$.  
  Then a \emph{$T$-\strategy{} for $\sigma$}\footnote{Yes, that is a \strategy{} for a strategy.} is a non-empty prefix-closed subset $S$ of $\sigma$ satisfying the following rules:
  \begin{enumerate}[a)]
    \item If $s\in S$ and $sa\in\sigma$ where $a$ is an $O$-move in $A$ or a \move{} made by a player \emph{not} in $T$, then $sa\in S$.  
    \item If $sa,sb\in S$, where $a,b$ are $P$-moves in $A$ or \move{}s made by a player in $T$, then $a=b$.  
    \item If $s\in S$ and there exists some $a\in M_A+\M_\sigma$ such that $sa\in \sigma$ then there exists some $b\in M_A+\M_\sigma$ such that $sb\in S$.
  \end{enumerate}
\end{definition}

\begin{definition}
  As with strategies, if $S$ is a \strategy{} for some \game{}-strategy $\sigma$, we write $T_S$ for the set of all shadows of \game{}-plays in $S$.  

  Once again, it is easy to see that $T_S$ is a strategy for $A$ in the usual sense.  

  We write $D_S$ for the set of positions $s\in T_\sigma$ where there exists $t\in S$ such that for all $t'\in\sigma$ satisfying $t\prefix t'$, $s$ is the shadow of $t'$.  
\end{definition}

We use $T$-\strategy{}s to define an order on \game{}-strategies.  

\begin{definition}
  Let $A$ be an arena, let $\sigma$ be a \game{}-strategy for $A$ and let $T\subset\P$ be a team of players.  
  Given a $T$-\strategy{} $S$ for $\sigma$ and $s\in T_\sigma$ ending with an $O$-move, define
  \[
    R_S^s = \{a\in M_A\suchthat sa\in T_S\}
    \]

  We define
  \[
    R_{\sigma,T}^s = \{R_S^s\suchthat \textrm{$S$ is a $T$-\strategy{} for $\sigma$},\;\textrm{$t\not\in D_S$ for all $t\prefix s$}\}
    \]

  Lastly, if $\sigma,\tau$ are \game{}-strategies for $A$, we say that $\sigma\le_T\tau$ if for all $s\in T_\sigma\cap T_\tau$ we have
  \[
    R_{\sigma,T}^s\le R_{\tau,T}^s
    \]
  where we say $R\le R'$ if for all $A\in R$ there exists $B\in R'$ such that $B\subset A$.  

  If $\T\subset\power(\P)$ is a set of teams, then we write $\sigma\le_{\T}\tau$ if $\sigma\le_T\tau$ for all $T\in\T$.A

  If $\sigma\le_T\tau$ and $\tau\le_T\sigma$, then we say that $\sigma\equiv_T\tau$.  
  Similarly, if $\sigma\le_{\T}\tau$ and $\tau\le_{\T}\sigma$, then we say that $\sigma\equiv_{\T}\tau$.  
\end{definition}

\subsection{Example: one-player games}

In this section we will take $\P=\{\RN{1}\}$, and show that the preorders on strategies correspond to the lower and upper orders defined in \cite{mcCHFiniteND}.

\begin{lemma}
  \label{lemma:guy}
  Let $A$ be an arena and let $\sigma$ be a \game{}-strategy for $A$.  

  i) Let $S$ be a $\{\RN{1}\}$-\strategy{} for $\sigma$.  
  Then $T_S$ is a deterministic (possibly partial) sub-strategy of $T_\sigma$.  

  ii) Let $S$ be an $\emptyset$-\strategy{} for $\sigma$.  
  Then $S=\sigma$ as sets.
\end{lemma}

\begin{proposition}
  Let $A$ be an arena.  
  Given a \game{}-strategy $\sigma$ for $A$, define $D_\sigma$ to be the set of all (finite) $s\in T_\sigma$ where there exists $t\in\sigma$ such that for all $\t'\in\sigma$ satisfying $t\prefix t'$, $s$ is the shadow of $t'$.  

  Now let $\sigma,\tau$ be \game{}-strategies for $A$.  

  i) $\sigma \le_{\{\RN{1}\}} \tau$ if and only if $T_\sigma\subset T_\tau$.  

  ii) $\sigma \le_{\emptyset} \tau$ if and only if ....
\end{proposition}

\begin{proof}
  (i): Suppose that $\sigma\le_{\{\RN{1}\}}\tau$.  
  Let $s\in T_\sigma$ be a $P$ position.  
  If $s=\emptyplay$ then $s\in T_\tau$.  
  Otherwise, $s=s'a$ for some $O$-position $s'$.  
  We may construct a $\{\RN{1}\}$-\strategy{} $S$ for $\sigma$ by
  \[
    S=\{t\in\sigma\suchthat \textrm{for all even-length prefixes $t'\prefix t$, $t'\prefix s$}\}
    \]
  Then $S$ contains $s$ and, moreover, $s'\not\in D_S$.  
  It follows that $\{a\}\in R_{\sigma,\{\RN{1}\}}^{s'}$ and therefore that $\{a\}\in R_{\tau,\{\RN{1}\}}^{s'}$, which means that there is some \strategy{} $S'$ for $\tau$ such that $sa\in T_{S'}$.  
  It follows that $sa\in T_\tau$.  

  Conversely, suppose that $T_\sigma\subset T_\tau$.  
  Let $s\in T_\sigma$ be an $O$-position and let $S$ be a $\{\RN{1}\}$-\strategy{} for $\sigma$ such that $s\not\in D_S$.  
  Then, by Lemma \ref{lemma:guy}, $T_S$ is a deterministic sub-strategy for $T_\sigma$; since $s\not\in D_S$, we have $sa\in T_\sigma$ for some $a$ and so $R_S^s=\{a\}$.  
  Since $T_\sigma\subset T_\tau$, we have $sa\in T_\tau$.  
  As above, we may construct some \strategy{} $S'$ for $\tau$ such that $s\not\in D_{S'}$ and $R_{S'}^s=\{a\}$.  
  It follows that $\sigma\le_{\{\RN{1}\}}\tau$.  

  (ii): Suppose that $\sigma\le_\emptyset\tau$.  
  By Lemma \ref{lemma:guy} there are unique $\emptyset$-\strategy{}s $S_\sigma$ for $\sigma$ and $S_\tau$ for $\tau$, given at the level of sets by $S_\sigma=\sigma$ and $S_\tau=\tau$.  

  Let $s\in T_\tau$ be a $P$-position, and suppose that $s\not\in T_\sigma$.  
  Let $d\prefix s$ be the longest prefix contained in $T_\sigma$.  
  Certainly $d$ is an $O$-position; since $d\ne s$, we have $da\prefix s$ for some $a$.  
  Now if $R_{\tau,\emptyset}^e$ is inhabited, it must have a single element, $R_{S_\tau, \emptyset}^e$, which contains $a$.  
  But since $ea\not\in T_\sigma$, no element of $R_{\sigma,\emptyset}^e$ may contain $a$.  
  The only possibility, then, is that $e'\in D_\sigma$ for some $e'\prefix e\prefix s$.

  Let $d\in D_\tau$; let $d'\prefix d$ be the longest prefix contained in $D_\tau$ and let $e\prefix d'$ be the longest prefix contained in $T_\sigma$.  
  Then $e$ must be an $O$-position, by the definition of a strategy.  

  If $e=d'$, then $R_{\tau,\emptyset}^e=\emptyset$, since $e=d'\in D_\tau = D_{S_\tau}$.  
  Therefore, $R_{\sigma,\emptyset}^e=\emptyset$, which means that $e'\in D_{S_\sigma}=D_\sigma$ for some $e'\prefix e\prefix d$.

  If instead $e\neq d'$, then $ea\in T_\sigma\setminus T_\tau$, from which it follows that some prefix of $ea$ is contained in $D_\sigma$, as above.  

  Conversely, suppose that the conditions on $T_\sigma,D_\sigma,T_\tau,D_\tau$ hold.  
  Let $s\in T_\sigma\cup T_\tau$ be an $O$-position.  
  We have $R_{S_\sigma,\emptyset}^s = \{a\suchthat sa\in T_\sigma\}$ and $R_{S_\tau,\emptyset}^s = \{a\suchthat sa\in T_\tau\}$.  
  Then $R_{\sigma,\emptyset}^s=\{R_{S_\sigma,\emptyset}^s\}$ if $s\in D_\sigma$ and is empty otherwise, and similarly for $\tau$.  
  
  By the first condition, either $e\in D_\sigma$ for some $e\prefix s$ or $R_{S_\tau,\emptyset}^s\prefix R_{S_\sigma,\emptyset}^s$.  
  In the first case, $R_{\sigma,\emptyset}^s=\emptyset$, and so certainly $R_{\sigma,\emptyset}^s\le R_{\tau,\emptyset}^s$.  
  In the second case, by the second condition, $d\not\in D_\tau$ for all $d\prefix s$ and therefore we have $R_{\sigma,\emptyset}^s=R_{S_\sigma,\emptyset}$ and similarly for $\tau$.  
  The claim then follows.
\end{proof}

\subsection{Composition of \game{}-strategies}

Let $A,B,C$ be arenas, let $\sigma$ be a \game{}-strategy for $A\iimpl B$ and let $\tau$ be a \game{}-strategy for $B\iimpl C$.  
We shall construct a strategy $\sigma;\tau$ for $A\iimpl C$, the \emph{composition} of $\sigma$ with $\tau$.  

We first define
\[
  \M_{\sigma;\tau}=\M_\sigma + \M_\tau
  \]

We say that a sequence $\s\in (M_A + M_B + M_C + \M_{\sigma;\tau})^*$ is a \emph{legal interaction} if
\[
  \s\vert_{A,B,\M}\in \M_\sigma
  \]
and
\[
  \s\vert_{B,C,\M}\in M_\tau
  \]
and moreover if the justification pointers in the sequences interact nicely in the usual manner.  
Here, $\s\vert_{A,B,\M}$ is shorthand for $\s\vert_{M_A,M_B,\M_{\sigma;\tau}}$ and similarly for $B,C$.  

Write $\sigma\|\tau$ for the set of legal interactions of sequences between $\sigma$ and $\tau$.  
We then define
\[
  \sigma;\tau = \{\s\vert_{A,C,\M}\suchthat \s\in \sigma\|\tau\}
  \]

\section{Chess}

\begin{example}
  Fix two players B (black) and W (white) and a set of moves $\M$ consisting of all legal chess moves.  
  Then we can model games played on a chess board using the arena given by
  \[
    (\{q,ww,dr,bw\}, \{q\mapsto(O,Q),\;ww,dr,bw\mapsto(P,A)\},\{q\ts ww,dr,bw\}, \{q\})
    \]
  A justified play over the sequence $q.ww$ is a collection of justification pointers $j$ from $ww$ to $q$, each annotated with a sequence of chess moves carried out by one or other of the two players.  
  The game of chess itself is then described by three particular justified plays:
  \begin{itemize}
    \item One over the sequence $q.ww$, where the labels of the justification pointers from $ww$ to $q$ are precisely those sequences of moves leading to a win for white.
    \item One over the sequence $q.dr$, where the labels of the justification pointers from $dr$ to $q$ are precisely those sequences of moves leading to a draw.
    \item One over the sequence $q.bw$, where the labels of the justification pointers from $bw$ to $q$ are precisely those sequences of moves leading to a win for black.
  \end{itemize}
\end{example}


\bibliographystyle{alpha}
\bibliography{../common/phd_bibliography}

\end{document}
