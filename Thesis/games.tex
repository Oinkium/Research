\documentclass{article}

\def\FEWFONTS{1}
\def\THESIS{1}
\input{../common/preamble}
\usepackage{lua-visual-debug}

\begin{document}

\section{A Fully Abstract Game Semantics for Idealized Algol}

To introduce our material, we will go back over some old ground, namely the fully abstract game semantics for Idealized Algol developed by Abramsky and McCusker in \cite{SamsonGuyIAActive}.  
In keeping with the spirit of this thesis, we will aim to use category theoretic methods, and so our proofs of soundness and adequacy will depart from those given by Abramsky and McCusker, and will instead involve coalgebraic ideas developed by Laird in \cite{laird02} and \cite{LairdCofCommCom}.

\subsection{Idealized Algol}

The ground types of Idealized Algol are called $\com$, $\bool$, $\nat$ and $\Var$.  
The first three are data types corresponding to the sets $\bC = \{a\}$, $\bB = \{\true,\false\}$ and $\bN = \{0,1,2,\cdots\}$.
$\com$ takes the role of a command or void type; typically, although the return value of a function $T \to \com$ will not convey any information, the function will have side effects that \emph{do} make a difference.

The type $\Var$ is the type of a variable that holds elements of $\bN$.
It is best understood as corresponding to the following pseudo-Java `interface'.

\begin{lstlisting}[language=Java, morekeywords={nat,com}]
public interface Var
{
  nat read();
  com write(nat value);
}
\end{lstlisting}

We now present the typing rules for the language.  
Here, $\Gamma$ will represent a \emph{context}; i.e., a list $x_1\from T_1,\cdots,x_n\from T_n$ of variable names together with their types.

First, we have the usual rules for the simply typed lambda calculus.

\begin{mathpar}
  \inferrule*{ }{\Gamma,x\from T \ts x \from T}
  \and
  \inferrule*{\Gamma\ts M \from S \to T \\ \Gamma \ts N \from S}{\Gamma\ts MN \from T}
  \and
  \inferrule*{\Gamma,x\from S \ts M \from T}{\Gamma \ts \lambda x^S.M \from S \to T}
\end{mathpar}

We then have rules for each of the base types.  
At type $\com$ we have:
\begin{mathpar}
  \inferrule*{ }{\Gamma\ts\skipp\from\com}
  \and
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma\ts M\from\com \\ \Gamma\ts N \from T}{\Gamma\ts M;N\from T}\,.
\end{mathpar}
Here, $\skipp$ is a generic command with no side-effects that returns the unique element of the singleton set $\bC$.  
$M;N$ represents the sequential composition of $M$ with $N$; i.e., the term that first evaluates $M$, performing any of its side-effects, and then evaluates $N$ and returns the result.

At type $\bool$ we have true/false values and conditionals.
\begin{mathpar}
  \inferrule*{ }{\Gamma\ts\true\from\bool}
  \and
  \inferrule*{ }{\Gamma\ts\false\from\bool}
  \\
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma\ts M \from \bool \\ \Gamma \ts N \from T \\ \Gamma \ts P \from T}{\Gamma\ts \If M \Then N \Else P \from T}
\end{mathpar}

At type $\nat$ we have numerals, arithmetic operators and a conditional that tests whether a number is equal to $0$ or not.
\begin{mathpar}
  \inferrule*{ }{\Gamma\ts n\from\nat}
  \and
  \inferrule*{\Gamma\ts M \from \nat}{\Gamma\ts \suc M \from \nat}
  \and
  \inferrule*{\Gamma\ts M \from \nat}{\Gamma\ts \pred M\from \nat}
  \\
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma\ts M \from \nat \\ \Gamma\ts N \from T \\ \Gamma \ts P \from T}{\Gamma \ts \IfO M \Then N \Else P \from T}
\end{mathpar}

At type $\Var$, we have terms that call the read and write `methods' to dereference the variable or to assign a new value to it.
\begin{mathpar}
  \inferrule*{\Gamma\ts V \from \Var}{\Gamma \ts \oc V \from \nat}
  \and
  \inferrule*{\Gamma\ts V \from \Var \\ \Gamma \ts E \from \nat}{\Gamma \ts V\gets E \from \com}
\end{mathpar}

We also have the ability to create a new variable.
\begin{mathpar}
  \inferrule*{\Gamma,x\from \Var \ts M \from T}{\Gamma\ts \neww_T \lambda x.M\from T}
\end{mathpar}
The idea here is that $M$ is a term that refers to some free variable $x$ of type $\Var$; then $\neww \lambda x.M$ makes $x$ behave like an actual storage cell (so, for instance, the result of the computation $\neww_\nat \lambda x.(x\gets 5);!x$ will be $5$).

We have another way of creating variables, using the $\mkvar$ keyword.  
If we think back to our illustration of the $\Var$ type as an interface, this becomes clearer.  
$\mkvar$ creates a new anonymous instance of the $\Var$ interface, using the `methods' supplied through its arguments.
\begin{mathpar}
  \inferrule*{\Gamma \ts M \from \nat \\ \Gamma \ts N \from \nat \to \com}{\Gamma\ts \mkvar M N \from \Var}
\end{mathpar}

Lastly, we have fixpoint combinators at all types that we use to implement recursion.
\begin{mathpar}
  \inferrule*{\Gamma \ts M \from T \to T}{\Gamma \ts \Y_T M \from T}
\end{mathpar}

\subsection{Games and Strategies}

We adopt the game semantics from \cite{SamsonGuyIAActive}; these are based on the game semantics developed in \cite{hoPcf}, with a modification to make them into a linear category.

\begin{definition}
  An \emph{arena} is a tuple $A=(M_A,\lambda_A,\ts_A)$, where
  \begin{itemize}
    \item $M_A$ is a set of \emph{moves},
    \item $\lambda_A \from M_A \to \OP \times \QA$ is a function that identifies each move as either an \emph{$O$-move} or a \emph{$P$-move}, and as either a \emph{question} or an \emph{answer}, and
    \item $\ts_A$ is a relation between $M_A+\{*\}$ and $M_A$ such that
      \begin{itemize}
        \item if $*\ts_A a$, then $\lambda_A(a)=(O,Q)$, and if $b\ts_A a$ then $b=*$,
        \item if $a\ts_A b$ and $a$ is an answer, then $b$ is a question, and
        \item if $a \ts_A b$ and $a\ne *$, then either $a$ is an $O$-move and $b$ a $P$-move, or the other way round.
      \end{itemize}
  \end{itemize}
  If $*\ts_A a$, then we say that $a$ is an \emph{initial move} in $A$.  
  If $a \ts_A b$, the we say that $a$ \emph{enables} $b$.
\end{definition}

As a shorthand, we write $\lambda_A^{OP}\from M_A \to \OP$ for $\pr_1\circ\lambda_A$ and $\lambda_A^{QA}\from M_A \to \QA$ for $\pr_2\circ\lambda_A$.

\begin{definition}
  A \emph{justified sequence} in an arena $A$ is a finite sequence $s$ of moves together with, for each non-initial move $a$ occurring in $s$, a pointer back to some move $b$ occurring earlier in $s$ such that $b\ts_A a$.
  We say that \emph{$b$ justifies $a$} or that $b$ is the \emph{justifier} of $a$.

  Given such a justified sequence, we define the \emph{$P$-view} $\pv s$ and \emph{$O$-view} $\ov s$ of $s$ inductively as follows.
  \begin{IEEEeqnarray*}{RCL"s}
    \pv{\epsilon} & = & \epsilon & \\
    \pv{sa} & = & \pv{s}a & if $a$ is a $P$-move \\
    \pv{sa} & = & a & if $a$ is initial \\
    \pv{sbta} & = & \pv{s}ba & if $a$ is an $O$-move justified by $b$ \\
    & & & \\
    \ov{\epsilon} & = & \epsilon & \\
    \ov{sa} & = & \ov{s}a & if $a$ is an $O$-move \\
    \ov{sbta} & = & \ov{s}ba & if $a$ is a $P$-move justified by $b$
  \end{IEEEeqnarray*}
  
  A justified sequence $s$ is \emph{well-bracketed} if whenever a question $q$ justifies some answer $a$, then any question $q'$ occurring after $q$ and before $a$ must justify some answer $a'$ occurring between $q'$ and $a$, and moreover $a$ is the only answer justified by $q$.
  We say that a justified sequence $s$ is \emph{alternating} if it alternates between $O$-moves and $P$-moves, and that it is \emph{well-formed} if it is both well-bracketed and alternating.

  We say that a well-formed justified sequence is \emph{visible} if whenever $ta\prefix s$, and $a$ is a $P$-move, then the justifier of $a$ occurs in the $P$-view of $t$, and if whenever $tb\prefix s$, and $b$ is a non-initial $O$-move, then the justifier of $b$ occurs in the $O$-view of $t$.

  We say that a justified sequence $s$ is \emph{legal} if it is well-formed and visible, and write $L_A$ for the set of legal sequences occurring in $A$.
\end{definition}

Note that since every non-initial move in a justified sequence $s$ must be justified by some previous move, then the first move in the sequence must be initial and therefore an $O$-question.  
If $s$ is alternating, this means that $s$ ends with an $O$-move if it has odd length and with a $P$-move if it has even length.  

\begin{definition}
  Given a legal sequence $s\in L_A$, and a move $b$ in $s$, we say that a move $a$ in $s$ is \emph{hereditarily justified by $b$} if there is a chain of justification pointers going back from $a$ to $b$.

  We write $s\vert_b$ for the subsequence of $s$ given by all moves in $s$ that are hereditarily justified by $b$.
  Given a set $I$ of initial moves, we write $s\vert_I$ for the subsequence of $s$ given by all moves that are hereditarily justified by some $b\in I$.

  A \emph{game} is given by a tuple $A=(M_A,\lambda_A,\ts_A,P_A)$ where $(M_A,\lambda_A,\ts_A)$ is an arena and $P_A$ is a non-empty prefix-closed subset of $L_A$ such that if $s\in P_A$ and $I$ is a set of initial moves, then $s\vert_I\in P_A$.
\end{definition}

We shall call an odd-length sequence $s\in P_A$ an \emph{$O$-position} and an even-length sequence a \emph{$P$-position}

\begin{example}[Empty game]
  The \emph{empty game} $I$ is given by the tuple
  \[
    (\emptyset,\emptyset,\emptyset,\{\epsilon\})\,,
    \]
  where $\epsilon$ is the empty sequence.
  \label{ExEmptyGame}
\end{example}

\begin{example}[Data-type games]
  Let $X$ be some set.  
  Then we have a game, which we shall also call $X$, given by:
  \begin{itemize}
    \item $M_X = \{q\} + X$, 
    \item $\lambda_X(q)=(O,Q)$ and $\lambda_X(x)=(P,A)$ for all $x\in X$, 
    \item $q\ts_X x$ for each $x\in X$, and
    \item $P_X = \{\epsilon,q\}\cup\{qx\suchthat x\in X\}$, where the $x$ in $qx$ is justified by $q$.
  \end{itemize}

  In particular, we have games $\bC$, $\bB$ and $\bN$, which we shall use to model the datatypes $\com$, $\bool$ and $\nat$ of Idealized Algol.
\end{example}

\begin{definition}
  Let $A$ be a game.  
  Then a \emph{strategy} for $A$ is a non-empty even-prefix-closed set $\sigma\subset P_A$ of $P$-positions in $A$ such that if $sab,sac\in \sigma$ then $b=c$ and the justifier of $b$ is the justifier of $c$.  
\end{definition}
Here, we have identified a strategy for a game with the set of $P$-positions that can occur when player $P$ plays according to that strategy.  
So the condition we have given is one of \emph{determinism}: in any $O$-position $sa$ that can occur in the strategy, player $P$ must have at most one reply.

Note that there may be $O$-positions for which player $P$ has no reply at all; we use these to model non-terminating computations.

We write $\sigma\from A$ to denote that $\sigma$ is a strategy for the game $A$.

\begin{definition}
  A strategy $\sigma$ for a game $A$ is called \emph{innocent} if player $P$'s moves only depend on the current $P$-view; i.e., if whenever $sab\in\sigma$, $t\in\sigma$ and $ta\in P_A$ such that $\pv{sa}=\pv{ta}$, then we have $tab\in\sigma$.
\end{definition}

\subsection{Connectives on Games}
\label{SecConnectives}

In the \emph{product} $A\times B$ of games $A$ and $B$, player $O$ chooses either $A$ or $B$ on the first move and subsequent play is that game.

\begin{definition}
  Given games $A$,$B$, define a game $A\times B$ by
  \begin{itemize}
    \item $M_{A\times B} = M_A + M_B$,
    \item $\lambda_{A\times B} = [\lambda_A,\lambda_B]$,
    \item $* \ts_{A\times B} a$ if and only if $*\ts_A a$ or $*\ts_B a$ and $a \ts_{A\times B} b$ if and only if $a \ts_A b$ or $a\ts_B b$, and
    \item $P_{A\times B} = \{s\in L_{A\times B} \suchthat \text{$s\vert_A\in P_A$ and $s\vert_B=\epsilon$ or $s\vert_A=\epsilon$ and $s\vert_B\in P_B$}\}$.
  \end{itemize}
  We extend this to arbitrary products $\prod_i A_i$ in the obvious way.
  In particular, the product $1$ of the empty collection is the same as the empty game $I$ defined in Example \ref{ExEmptyGame}.
  \label{DefProduct}
\end{definition}

Here, we have written $s\vert_A$ for the subsequence of $s$ consisting of all moves from $M_A$ and $s\vert_B$ for the subsequence consisting of all moves from $M_B$.

In the \emph{tensor product} $A\tensor B$ of games $A$ and $B$, the games $A$ and $B$ are played in parallel, and player $O$ may switch between games when it is his turn.

\begin{definition}
  Given games $A$,$B$, define a game $A\tensor B$ by
  \begin{itemize}
    \item $M_{A\tensor B} = M_A + M_B$,
    \item $\lambda_{A\tensor B} = [\lambda_A,\lambda_B]$,
    \item $* \ts_{A\tensor B} a$ if and only if $*\ts_A a$ or $*\ts_B a$ and $a \ts_{A\tensor B} b$ if and only if $a \ts_A b$ or $a\ts_B b$, and
    \item $P_{A\tensor B} = \{s\in L_{A\tensor B} \suchthat \text{$s\vert_A\in P_A$ and $s\vert_B\in P_B$}\}$.
  \end{itemize}
\end{definition}

In the \emph{linear implication} $A\implies B$, the game $B$ is played in parallel with a version of $A$ in which the two players' roles have been switched around, and player $P$ may switch between the two games when it is her turn.

\begin{definition}
  Given games $A$,$B$, define a game $A\implies B$ by
  \begin{itemize}
    \item $M_{A\implies B} = M_A + M_B$,
    \item $\lambda_{A\implies B} = [\neg\circ\lambda_A,\lambda_B]$,
    \item $* \ts_{A\implies B} a$ if and only if $*\ts_B a$, and $a \ts_{A\implies B} b$ if and only if $a \ts_A b$ or $a\ts_B b$, or if $a$ is initial in $B$ and $b$ is initial in $a$, and
    \item $P_{A\implies B} = \{s\in L_{A\implies B} \suchthat \text{$s\vert_A\in P_A$ and $s\vert_B\in P_B$}\}$.
  \end{itemize}
\end{definition}

Here, $\neg\from \OP\times\QA \to \OP\times \QA$ is the function that reverses $O$ and $P$, while leaving $\QA$ unchanged.

In the \emph{exponential} of a game $A$, infinitely many copies of $A$ are played in parallel, and player $O$ may switch between copies whenever it is his move.

\begin{definition}
  Given a game $A$, define a game $\oc A$ by
  \begin{itemize}
    \item $M_{\oc A}=M_A$,
    \item $\lambda_{\oc A} = \lambda_A$,
    \item $\ts_{\oc A} = \ts_A$ and
    \item $P_{\oc A} = \{s\in L_{\oc A} \suchthat \text{$s\vert_b\in P_A$ for each initial move $b$ occurring in $s$}\}$.
  \end{itemize}
\end{definition}

Lastly, the \emph{sequoid} $A\sequoid B$ of two games $A$ and $B$ behaves like the tensor product $A\tensor B$, except that the opening move must take place in $A$.

\begin{definition}
  Given games $A,B$, define a game $A\sequoid B$ by
  \begin{itemize}
    \item $M_{A\sequoid B} = M_{A\tensor B}$, 
    \item $\lambda_{A\sequoid B} = \lambda_{A\tensor B}$, 
    \item $\ts_{A\sequoid B} = \ts_{A \tensor B}$ and
    \item $P_{A\sequoid B} = \{s\in P_{A\tensor B}\suchthat\text{$s=\epsilon$ or $s$ begins with a move from $A$}\}$.
  \end{itemize}
\end{definition}

\subsection{Composition of strategies}

\begin{definition}
  Let $A,B,C$ be arenas.  
  An \emph{interaction sequence} between $A,B,C$ is a justified sequence $\s$ of moves drawn from $M_A$, $M_B$ and $M_C$ such that $\s\vert_{A,B}\in L_{A\implies B}$ and $\s\vert_{B,C}\in L_{B\implies C}$.  
  Here, $\s\vert_{A,B}$ is the subsequence of $\s$ consisting of those moves from $\s$ that occur in $A$ or $B$, together with all justification pointers between moves in $A$ and $B$, and $\s\vert_{B,C}$ is defined similarly.

  We write $\Int(A,B,C)$ for the set of all interaction sequences between $A,B,C$.

  Given $\s\in\Int(A,B,C)$, we write $\s\vert_{A,C}$ for the subsequence of $\s$ consisting of those moves from $\s$ that occur in $A$ or $B$.  
  A move $b$ in $\s\vert_{A,C}$ justifies a move $a$ either if $b$ justifies $a$ in either the $A$ or the $C$ components, or if $b$ justifies in $\s$ some initial move $c$ in $B$, which itself justifies $a$.
\end{definition}

\begin{definition}
  Let $A,B,C$ be games, let $\sigma$ be a strategy for $A\implies B$ and let $\tau$ be a strategy for $B\implies C$.  
  We define $\sigma\|\tau$ to be given by the set
  \[
    \{\s\in\Int(A,B,C)\suchthat \text{$\s\vert_{A,B}\in\sigma$ and $\s\vert_{B,C}\in\tau$}\}\,.
    \]
  Then we define the \emph{composition} $\sigma;\tau$ of $\sigma$ and $\tau$ to be given by the set
  \[
    \{\s\vert_{A,C}\suchthat \s\in\sigma\|\tau\}\,.
    \]
\end{definition}

We need some small lemmata and definitions to help us show that this is a strategy.

\begin{lemma}
  We extend the function $\lambda_A^{OP}$ to sequences of moves by
  \begin{itemize}
    \item $\lambda_A^{OP}(\epsilon)=P$ and
    \item $\lambda_A^{OP}(sa)=\lambda_A(a)$.
  \end{itemize}

  If $s\in P_{A\implies B}$, then $\lambda_{A\implies B}^{OP}(s)=(\lambda_A^{OP}(s\vert_A)\Rightarrow \lambda_B^{OP}(s\vert_B))$, where $\Rightarrow$ is the binary operation on $\OP$ defined by
  \[
    \begin{array}{cc|c}
      P & Q & P\Rightarrow Q \\
      \hline
      P & P & P \\
      O & P & P \\
      P & O & O \\
      O & O & P
    \end{array}\,.
    \]
  Moreover, if $\lambda_A^{OP}(s\vert_A)=O$ then $\lambda_A^{OP}(s\vert_B)=O$.
  \label{LemCompositionLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $s$.
  If $s=\epsilon$, then $s\vert_A=s\vert_B=\epsilon$, and so $(\lambda_A^{OP}(s\vert_A)\Rightarrow \lambda_B^{OP}(s\vert_B)) = (P\Rightarrow P) = P = \lambda_{A\implies B}^{OP}(s)$.  

  Suppose then that $s=ta$, and that $\lambda_{A\implies B}^{OP}(t)=O$.  
  This means that $\lambda_A^{OP}(t\vert_A)=P$ and $\lambda_B^{OP}(t\vert_B)=O$.
  Then, whether $a$ is a move in $A$ or a move in $B$, adding it will flip exactly one of these components -- so $\lambda_{A\implies B}(s\vert_A)=O$ and $\lambda_{A\implies B}^{OP}(s\vert_B)=O$ if $a$ is a move in $A$ and $\lambda_{A\implies B}(s\vert_A)=P$ and $\lambda_{A\implies B}^{OP}(s\vert_B)=P$ if $a$ is a move in $C$.

  Suppose instead that $\lambda_{A\implies B}^{OP}(t)=P$.  
  By induction, this means that either $\lambda_A^{OP}(t\vert_A)=P$ and $\lambda_B^{OP}(t\vert_B)=P$ or that $\lambda_A^{OP}(t\vert_A)=O$ and $\lambda_B^{OP}(t\vert_B)=O$.
  In the first case, this means that either $t\vert_A$ is empty or its last move is a $P$-move in $A$ (and therefore an $O$-move in $A\implies B$), and so the move $a$ must take place in $C$, meaning that $\lambda_A^{OP}(s\vert_A)=P$ and $\lambda_B^{OP}(s\vert_B)=O$.  

  Similarly, in the second case, the last move in $t\vert_C$ must be an $O$-move in $B$ (and therefore an $O$-move in $A\implies B$, and so the move $a$ must take place in $A$, meaning that $\lambda_A^{OP}(s\vert_A)=P$ and $\lambda_B^{OP}(s\vert_B)=O$.  
\end{proof}

It follows that

\begin{corollary}[Switching condition]
  Only player $P$ may switch between games in $A\implies B$; i.e., if $tab\in P_{A\implies B}$, and $a$ occurs in $A$ and $b$ in $B$, or if $a$ occurs in $B$ and $b$ in $A$, then $b$ is a $P$-move.
  \label{CorSwitchingCondition}
\end{corollary}
\begin{proof}
  Otherwise, $\lambda_{A\implies B}(t)=O$, so $\lambda_A(t\vert_A)=P$ and $\lambda_B(t\vert_B)=O$.  
  But we must also have $\lambda_{A\implies B}(tab)=O$, so $\lambda_A(tab\vert_A)=P$ and $\lambda_B(tab\vert_B)=O$.  
  But this is a contradiction, since $tab\vert_A$ and $tab\vert_B$ are both one move longer than the plays $t\vert_A$ and $t\vert_B$.
\end{proof}

\begin{definition}[{\cite[\sec 3.1]{Harmer2006InnocentGS}}]
  Given $\s\in \Int(A,B,C)$, we define the \emph{$P$-view} $\pv{\s}$ of $\s$ inductively as follows.
  \begin{IEEEeqnarray*}{RCL?s}
    \pv{\epsilon} & = & \epsilon & \\
    \pv{\s a} & = & \pv{\s}a & if $a$ is a move in $B$, an $O$-move in $A$ or a $P$-move in $C$ \\
    \pv{\s c} & = & c & if $c$ is an initial move of $C$ \\
    \pv{\s b\t a} & = & \pv{\s}ba & if $a$ is a $P$-move of $A$ or an $O$-move of $C$ and is justified by $b$ \\
  \end{IEEEeqnarray*}
\end{definition}

\begin{lemma}
  If $\s\in \Int(A,B,C)$, then $\pv{\s}\vert_{A,C}=\pv{\s\vert_{A,C}}$.
  \label{LemHarmerRestriction}
\end{lemma}
\begin{proof}
  Induction on the length of $\s$.  
  This is clear if $\s=\epsilon$.  
  
  If $a$ is an $O$-move in $A$ or a $P$-move in $C$, then $a$ is a $P$-move in $A\implies C$.  
  We have $\pv{\s a}\vert_{A,C}=\pv{\s}\vert_{A,C}a$, which by the inductive hypothesis is equal to $\pv{\s\vert_{A,C}}a$, which is the same as $\pv{\s a\vert_{A,C}}$.
  If $b$ is a move in $B$, then $\pv{\s b}\vert_{A,C}=\pv{\s}b\vert_{A,C}=\pv{\s}\vert_{A,C}=\pv{\s\vert_{A,C}}=\pv{\s b\vert_{A,C}}$, by the inductive hypothesis.

  If $c$ is initial in $C$, then $\pv{\s c}\vert_{A,C}=c=\pv{\s c\vert_{A,C}}$.

  Suppose $a$ is a $P$-move of $A$ or an $O$-move of $C$ -- so $a$ is an $O$-move in $A\implies C$ -- and suppose that $a$ is justified by $b$ in the sequence $\s b\t a$.  
  Since $a$ cannot be an initial move in $A$, $b$ must occur in the same game as $a$, and in particular must not occur in $B$.
  Then we have $\pv{\s b\t a}\vert_{A,C}=\pv{\s} ba\vert_{A,C}=\pv{\s}\vert_{A,C}ba$, which by the inductive hypothesis is equal to $\pv{\s\vert_{A,C}}ba=\pv{\s ba\vert_{A,C}}$.
\end{proof}

\begin{lemma}[{\cite[\sec 3.1]{Harmer2006InnocentGS}}]
  Let $\s a\in \Int(A,B,C)$ (so, in particular, $\s\vert_{A,B}$ and $\s\vert_{B,C}$ satisfy the visibility condition).  
  If $a$ is a move in $B$, an $O$-move in $A$ or a $P$-move in $C$, then $\pv{\s a}\in \Int(A,B,C)$.
  \label{LemHarmersLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $\s$.  
  If $\s=\epsilon$, then this is clear.  
  Otherwise, suppose that $\s$ is non-empty.

  First, we claim that $\pv{\s}\in\Int(A,B,C)$.  
  If $\s$ ends with a move in $B$, an $O$-move in $A$ or a $P$-move in $C$, then this follows immediately from the inductive hypothesis.  
  Otherwise, suppose that $\s$ ends with a $P$-move in $A$ or an $O$-move in $C$.  
  If this last move is initial, then $\pv{\s}$ is a single move, so the claim is trivial.  
  Otherwise, write $\s=\t p\u r$, where $p$ justifies $r$.  
  By the inductive hypothesis, we have $\pv{\t p}\in \Int(A,B,C)$, and then $\pv{s}=\pv{\t p\u r}=\pv{\t}pr=\pv{\t p}r\in \Int(A,B,C)$.  

  Now, since $a$ is a $P$-move in $A\implies B$ or in $B\implies C$, its predecessor $b$ is an $O$-move and has some justifier $c$ contained in $\pv{\s\vert_X}$, where $X\in\{A\implies B,B\implies C\}$ is that component in which $a$ is a $P$-move.  
  Then this $c$ is preceded by some other $O$-move $b'$, which is necessarily also contained in $\pv{\s}$, and so has some justifier $c'$, contained in $\pv{\s\vert_X}$ by visibility.  
  Continuing in this way until we reach an initial move, we build up the whole of the sequence $\pv{\s\vert_X}$ as a subsequence of $\pv{\s}$.  
  Therefore, the justifier of $a$ must be contained in $\pv{\s}$, and so $\pv{\s a}=\pv{\s}a\in\Int(A,B,C)$.
\end{proof}

\begin{lemma}[$O$-views in the linear implication, {\cite[4.2,4.3]{hoPcf}}]
  Let $A,B$ be games, and let $bs$ be a non-empty play in $A\implies B$ beginning with an initial move $b$ in $B$.

  i) If $bs$ ends with a $P$-move in $B$, then $\ov{bs}_{A\implies B}=\ov{bs\vert_B}_B$.

  ii) If $bs$ ends with a $P$-move in $A$, then $\ov{bs}_{A\implies B} = b\pv{s\vert_A}^A$.
  \label{LemProjectionLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $s$.
  If $s=\epsilon$, then $bs$ ends with an $O$-move in $B$, and we have $\pv{b}^{A\implies B} = b = \pv{b}^{B}$.  

  Otherwise, suppose that $bs$ ends with a $P$-move $c$ in $B$.  
  Let $d$ be the justifier of $c$.  
  Then $d$ must be an $O$-move in $B$.
  Write $bs=tduc$, where $t,u$ are sequences.  
  Then $\ov{tduc}_{A\implies B}=\ov{t}_{A\implies B}dc$ and $\ov{tduc\vert_B}_B=\ov{t\vert_B}_Bdc$.
  By Corollary \ref{CorSwitchingCondition}, $t$ must end with a $P$-move in $B$, or be empty, so by the inductive hypothesis we have $\ov{t}_{A\implies B}=\ov{t\vert_B}_B$.
  Therefore, $\ov{bs}_{A\implies B}=\ov{tduc}_{A\implies B}=\ov{t}_Bdc = \ov{tduc\vert_B}_B=\ov{bs\vert_B}_B$.

  Next, suppose that $bs$ ends with a $P$-move $a$ in $A$.
  Let $c$ be the justifier of $a$.  
  Then $c$ must be an $O$-move in $A$.  
  Write $s=tcua$, where $t,u$ are sequences.  
  Then $\ov{btcua}_{A\implies B}=\ov{bt}_{A\implies B}ca$ and $\pv{tcua\vert_A}^A = \pv{t\vert_A}^Aca$, since the roles are reversed in $A$.
  By Corollary \ref{CorSwitchingCondition}, $t$ must end in a $P$-move in $A$, or be empty, so by the inductive hypothesis we have $\ov{bt}_{A\implies B} = b\pv{t\vert_A}^A$.  
  Therefore, $\ov{bs}_{A\implies B}=\ov{btcua}_{A\implies B}=\ov{bt}_{A\implies B}ca=b\pv{t\vert_A}^Aca=b\pv{tcua\vert_A}^A=b\pv{s\vert_A}^A$.  
\end{proof}

\begin{proposition}
  $\sigma;\tau$ is a strategy for $A\implies C$.  
\end{proposition}
\begin{proof}
  First, we claim that $\s\vert_{A,C}\in P_{A\implies B}$ for any $\s\in \sigma\|\tau$.
  Since we certainly have $\s\vert_{A,C}\vert_A = \s\vert_{A,B}\vert_A\in P_A$ and $\s\vert_{A,C}\vert_C = \s\vert_C = \s\vert_{B,C}\vert_C\in P_C$, it suffices to show that $\s\vert_{A,C}\in L_{A\implies C}$.

  Suppose that $ta\prefix \s\vert_{A,C}$.  We claim that $\lambda_{A\implies C}(t) = \neg\lambda_{A\implies C}(a)$.
  By Lemma \ref{LemCompositionLemma}, we are in one of the following configurations.
  \small
  \[
    \begin{array}{ccc|ccc}
      \lambda_A^{OP}(t\vert_A) & \lambda_B^{OP}(t\vert_B) & \lambda_C^{OP}(t\vert_C) & \lambda_{A\implies B}^{OP}(t\vert_{A,B}) & \lambda_{B\implies C}^{OP}(t\vert_{B,C}) & \lambda_{A\implies C}^{OP}(t\vert_{A,C}) \\
      \hline
      P & P & P & P & P & P \\
      P & P & O & P & O & O \\
      P & O & O & O & P & O \\
      O & O & O & P & P & P 
    \end{array}
    \]
  \normalsize
  In the configuration $PPP$, the move $a$ cannot be a move in $A$, since that would leave $ta\vert_{A\implies B}$ in the configuration $OP$, which is impossible by Lemma \ref{LemCompositionLemma}.  
  Therefore, it must be a move in $C$, and must therefore be an $O$-move in $C$ and hence an $O$-move in $A\implies C$.

  In the configuration $PPO$, once again the move $a$ cannot take place in $A$, since this would leave $ta\vert_{A\implies B}$ in an illegal configuration.  
  Therefore, it must occur in $C$, and must be a $P$-move in $C$ and hence a $P$-move in $A\implies C$.

  In the configuration $POO$, the move $a$ cannot take place in $C$, or it would leave $ta\vert_{B,C}$ in the illegal configuration $OP$, so the move $a$ takes place in $A$.  
  Therefore, it must be an $O$-move in $A$ and hence a $P$-move in $A\implies C$.  

  Lastly, in the configuration $OOO$, the move $a$ cannot occur in $C$, or it would leave $ta\vert_{B,C}$ in the configuration $OP$, and so it must take place in $A$.  
  Therefore, it must be a $P$-move in $A$, and hence an $O$-move in $A\implies C$.

  Having established that $\s\vert_{A,C}$ is alternating, we show that it is well-bracketed.
  Suppose that a question move $q$ in $\s\vert_{A,C}$ justifies some answer move $a$.
  $q$ and $a$ must occur in the same component, since the only case in which a move from one of $A$ and $C$ can justify a move in the other is when both moves are initial, and hence questions.
  Suppose first that $q$ and $a$ both occur in the game $C$.  
  Suppose that some other question move $q'$ occurs between $q$ and $a$ in $\s\vert_{A,C}$.  
  If $q'$ occurs in $C$, then it must be answered by some $a'$ occurring between $q'$ and $a$, since $\s\vert_C$ is a well-bracketed sequence.  
  Otherwise, suppose that $q'$ occurs in $A$.  

  By examining the table above, we see that there must be some move in $B$ occurring between $q$ and $q'$ in $\s$, since moves in $A$ move between configurations $OOO$ and $POO$, while moves in $C$ move us between configurations $PPP$ and $PPO$.
  Let $b$ be the earliest such move.  
  Then $b$ must be a question; indeed, if it is an answer, then it is non-initial and so can only be justified by questions in $B$.  
  But such a question must occur earlier in $\s\vert_{B,C}$ than $q$, which would mean that $q$ was an unanswered question when the move $b$ was played, contradicting well-bracketedness of $\s\vert_{B,C}$.  
  Since $b$ is a question, it must be answered by some $a''$ occurring between $b$ and $a$.  
  Therefore, since $\s\vert_{A,B}$ is well-bracketed, the move $q'$ must be answered by some $a'$ occurring between $a'$ and $a''$ in $\s\vert_{A,B}$, and therefore between $a'$ and $a$ in $\s\vert_{A,C}$.

  The case when $q$ and $a$ both occur in $A$ is similar.  

  Lastly, we need to show that $\s\vert_{A,C}$ satisfies the visibility condition.
  Let $ta\prefix\s\vert_{A,C}$.
  Choose some $\t\prefix\s$ such that $\t\vert_{A,C}=t$.  

  Suppose $a$ is a $P$-move.
  Then by Lemma \ref{LemHarmersLemma}, $\pv{\t a}\in\Int(A,B,C)$.  
  By Lemma \ref{LemHarmerRestriction}, $\pv{t}a=\pv{ta}=\pv{\t a}\vert_{A,C}$, and therefore that the justifier of $a$ must be inside $\pv{t}$.

  Secondly, suppose that $a$ is an $O$-move.
  If $a$ is an $O$-move in $C$, then either it is initial or $t$ ends with some $P$-move in $B$, and therefore $\ov{t}_{A\implies C}=\ov{t\vert_B}_B = \ov{\t\vert_{B,C}}_B$.  
  Therefore, since $t\vert_{B,C}$ satisfies visibility, the justifier of $a$ must lie in $\ov{t}_{A\implies C}$.  
  If $a$ is an $O$-move in $A$, then write $t=cu$ and $\t=c\u$, where $c$ is the starting move in $C$.
  We have $\ov{cua}_{A\implies C}=c\pv{u\vert_A a}^A = \ov{c\u\vert_{A,B}}_{A\implies B}$.  
  Therefore, the justifier of $a$ must lie in $\ov{t}_{A\implies C}$.

  Therefore, $\s\vert_{A,C}\in L_{A\implies C}$, so $\s\vert_{A,C}\in P_{A\implies C}$.

  It is fairly clear that $\sigma;\tau$ is even-prefix closed, since $\sigma$ and $\tau$ are.  
  Indeed, if $\s\vert_{A,C}\in\sigma;\tau$ and $t\prefix\s\vert_{A,C}$, then we may choose some prefix $\t$ of $\s$ such that $t=\t\vert_{A,C}$.  
  Then $\t\vert_{A,B}\prefix\s\vert_{A,B}\in\sigma$ and $\t\vert_{B,C}\prefix\s\vert_{B,C}\in\tau$, so $\t\in\sigma\|\tau$.

  We claim that every sequence in $\sigma;\tau$ has even length.  
  Indeed, if $\s\vert_{A,B}\in\sigma$ and $\s\vert_{B,C}\in\tau$, then both $\s\vert_{A,B}$ and $\s\vert_{B,C}$ must have even length, so must be in configuration $OO$ or $PP$.  
  This means that $\s$ as a whole must be in configuration $OOO$ or $PPP$, and so $\s\vert_{A,C}$ must be in configuration $OO$ or $PP$, so must have even length.

  Lastly, we need to show that $\sigma;\tau$ is deterministic.  
  Suppose that $sab,sac\in\sigma;\tau$, and suppose that $b\ne c$.  
  Suppose that $\s\vert_{A,C}=sab$ and $\t\vert_{A,C}=sac$, for $\s,\t\in\sigma\|\tau$, and let $\u$ be the longest common prefix of $\s,\t$.
  $\s$ and $\t$ are certainly incomparable under the prefix ordering, since $\s\vert_{A,C}$ and $\t\vert_{A,C}$ are, so we have $\u p\prefix \s$ and $\u q\prefix \t$, where $p\ne q$.
  Now $p$ and $q$ cannot be $O$-moves in $A$, $P$-moves in $C$ or moves in $B$, or they would have to be equal by determinism of $\sigma$ and $\tau$.  
  Therefore, they are $P$-moves in $A$ or $O$-moves in $C$, but this contradicts $\s\vert_{A,C}=sab$ and $\t\vert_{A,C}=sac$.

  Therefore, the composition $\sigma;\tau$ is a strategy.  
\end{proof}

We also want to show that the composition of innocent strategies is innocent.
We follow the proof given in \cite{Harmer2006InnocentGS}.  
First, we use a lemma.

\begin{lemma}[{\cite[3.3.3]{Harmer2006InnocentGS}}]
  Let $\s a\in\Int(A,B,C)$.  

  i) If $a$ is a $P$-move of $A$ or an $O$-move of $B$, then $\pv{\s a\vert_{A,B}}=\pv{\pv{\s a}\vert_{A,B}}$.

  ii) If $a$ is a $P$-move of $B$ or an $O$-move of $C$, then $\pv{\s a\vert_{B,C}}=\pv{\pv{\s a}\vert_{B,C}}$.
  \label{LemHarmerProjection}
\end{lemma}
\begin{proof}
  Induction on the length of $\s$.
  We prove (i); the proof of (ii) is exactly the same.  

  If $a$ is a $P$-move of $A$ or an $O$-move of $B$, then it is an $O$-move of $A\implies B$.
  If $a$ is an initial move of $A\implies B$, then we have $\pv{\s\vert_{A,B}a}=a=\pv{a}\vert_{A,B}=\pv{\pv{\s a}}\vert_{A,B}$.  
  Otherwise, write $\s=\t b\u$, where $b$ justifies $a$.  
  Then $\pv{\s a \vert_{A,B}} = \pv{\t\vert_{A,B} b\u\vert_{A,B} a} = \pv{t\vert_{A,B}}ba$, which by the inductive hypothesis is equal to $\pv{\pv{\t}\vert_{A,B}}ba$, which is equal to $\pv{\pv{\t b \u a}\vert_{A,B}} = \pv{\pv{\s a}\vert_{A,B}}$.
\end{proof}

\begin{proposition}
  If $\sigma\from A \implies B$ and $\tau\from B \implies C$ are innocent strategies, then $\sigma;\tau\from A\implies C$ is innocent.
\end{proposition}
\begin{proof}
  Suppose there are $sab,t\in\sigma;\tau$ such that $ta\in P_{A\implies C}$, $\pv{sa}=\pv{ta}$.
  Let $\s' b$ be such that $\s' b\vert_{A,C}=sab$ and choose the minimal prefix $\s\prefix \s'$ such that $\s a\vert_{A,C}=sa$.
  
  Let $\t a$ be such that $\t a\vert_{A,C}=ta$.
  Since $\pv{sa}=\pv{ta}$, we have $\pv{\s a}\vert_{A,C}=\pv{\s a\vert_{A,C}}=\pv{sa}=\pv{ta}=\pv{\t a\vert_{A,C}}=\pv{\t a}\vert_{A,C}$ by Lemma \ref{LemHarmerRestriction}.  
  Let $\u$ be the longest common prefix of $\pv{\s a}$ and $\pv{\t a}$.  
  If $\s a$ and $\t a$ are not equal, then without loss of generality there is some $\u p\prefix \s$, where $\u p\not\prefix \t$.  
  Then, by determinism of $\sigma$ and $\tau$, this $p$ cannot be a $P$-move in either $A\implies B$ or $B\implies C$, so it must be a $P$-move in $A$ or an $O$-move in $C$, and is therefore preceded by another move in $A$ or $C$, which contradicts $\pv{\s a}\vert_{A,C}=\pv{\t a}\vert_{A,C}$.  
  Therefore, $\pv{\s a}=\pv{\t a}$.

  Now write $\s'=\s a b_1 \cdots b_n b$, where each $b_i$ is a move in $B$.  
  We show by induction that $\t a b_1 \cdots b_j\in\sigma\|\tau$.  
  Indeed, if $\t a b_1 \cdots b_{j-1}\in\sigma\|\tau$, then $b_j$ (or $b$) is a $P$-move in either $A\implies B$ or $B\implies C$, and $b_{j-1}$ is an $O$-move in that same component.  
  Write $X$ for the component ($A\implies B$ or $B\implies C$) in which $b_j$ is a $P$-move.
  Repeating the argument above, we see that $\pv{\t a b_1\cdots b_{j-1}} = \pv{\s a b_1\cdots b_{j-1}}$, and so we have that $\pv{\t a b_1\cdots b_{j-1}\vert_X}=\pv{\s a b_1\cdots b_{j-1}\vert_X}$ by Lemma \ref{LemHarmerProjection}.  
  Therefore, by innocence of $\sigma$ (if $X=A\implies B$) or $\tau$ (if $X=B\implies C$), we see that $\t a b_1 \cdots b_j\in \sigma\|\tau$.  
  It follows that $\t a b_1 \cdots b_n b\in\sigma\|\tau$, and therefore that $t a b\in\sigma;\tau$.
\end{proof}

\subsection{Associativity of composition}

In this section, we will prove that composition is associative; i.e., that if $\sigma\from A \implies B$, $\tau\from B\implies C$ and $\upsilon \from C \implies D$ are strategies, then $(\sigma;\tau);\upsilon=\sigma;(\tau;\upsilon)$.  
To do this, if $A,B,C,D$ are arenas, we define the set $\Int(A,B,C,D)$ to be the set of all sequences $\u$ of moves such that $\u\vert_{A,B}\in L_{A\implies B}$, $\u\vert_{B,C}\in L_{B\implies C}$ and $\u\vert_{C,D}\in L_{C \implies D}$.  
Given such a sequence $\u$, we define $\u\vert_{A,D}$ as before; i.e., we take all moves from $\u$ occurring in $A$ and $D$, together with justification pointers within these games, and if an initial move in $A$ is justified by an initial move in $B$, which is justified by an initial move in $C$, which is justified by an initial move in $D$, then we add a justification pointer from that move in $A$ to that move in $D$.

Given strategies $\sigma,\tau,\upsilon$ as above, we define $\sigma\|\tau\|\upsilon$ to be the set of all $\u\in\Int(A,B,C,D)$ such that $\u\vert_{A,B}\in\sigma$, $\u\vert_{B,C}\in\tau$ and $\u\vert_{C,D}\in\upsilon$.
We then claim that:

\begin{lemma}
  \[
    (\sigma;\tau);\upsilon = \{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\} = \sigma;(\tau;\upsilon)\,.
    \]
\end{lemma}
\begin{proof}
  Firstly, if $\u\in\sigma\|\tau\|\upsilon$, then it is clear to see that $\u\vert_{A,B,C}\in\sigma\|\tau$ and that $\u\vert_{B,C,D}\in\tau\|\upsilon$, and therefore that $\{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\}\subset (\sigma;\tau);\upsilon$ and $\{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\}\subset \sigma;(\tau;\upsilon)$. 

  Conversely, suppose that $\t\in(\sigma;\tau)\|\upsilon$, so that $\t\vert_{A,C}\in\sigma;\tau$ and $\t\vert_{C,D}\in\upsilon$, and choose some $\s\in\sigma\|\tau$ such that $\s\vert_{A,C}=\t\vert_{A,C}$.
  We may write 
  \[
    \s=\ccc_1\bbb_1\aaa_1\cdots \ccc_n\bbb_n\aaa_n
    \]
  for some (possibly empty) sequences of moves $\aaa_i$ from $A$, $\bbb_i$ from $B$ and $\ccc_i$ from $C$.  
  We may then write 
  \[
    \t=\ddd_1\ccc_1\aaa_1\cdots\ddd_n\ccc_n\aaa_n
    \]
  (for the same $\aaa_i$, $\ccc_i$), and we can therefore interleave these sequences into the sequence
  \[
    \u = \ddd_1\ccc_1\bbb_1\aaa_1\cdots\ddd_n\ccc_n\bbb_n\aaa_n\,,
    \]
  which is in $\sigma\|\tau\|\upsilon$.
  Then we have $\u\vert_{A,D}=\t\vert_{A,D}$, and it follows that $(\sigma;\tau);\upsilon\subset\{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\}$, and the case for $\sigma;(\tau;\upsilon)$ is identical.
\end{proof}

\subsection{Copycat strategies}
\label{SecCopycat}

\begin{definition}
  Let $A,B$ be games.  
  Then a \emph{subset inclusion} of $A$ into $B$ is a partial injection $i\from M_A\hookrightarrow M_B$ such that
  \begin{itemize}
    \item if $i$ is defined at $a$ and $b$ then $*\ts_A a$ if and only if $*\ts_B i(a)$, and $a\ts_A b$ if and only if $i(a)\ts_B i(b)$;
    \item $i(a)$ is defined for every move $a$ occurring in a play in $P_A$; and
    \item $i_*(s)\in P_B$ for every $s\in P_A$.
  \end{itemize}
  Here, $i_*(s)$ means the function $i$ applied pointwise to the elements of the string $s$.

  If $i$ is a subset incusion of $A$ into $B$, then we get an innocent strategy $\subs_i\from B \implies A$ defined by
  \[
    \subs_i = \{s\in P_{B\implies A}\suchthat\text{for all even-length $t\prefix s$, $t\vert_B=i_*(t\vert_A)$}\}\,.
    \]
  If $P_B=\{i_*(s)\suchthat s\in P_A\}$, then we call it a \emph{structural isomorphism}, and we write $\cc_i$ (`copycat') for $\subs_i$.
\end{definition}

\begin{proposition}
  $\subs_i$ is an innocent strategy.

  Moreover, if $\sigma\from C \implies B$ is a strategy, then
  \[
    \sigma;\subs_i = \{[\id_{M_C},i\inv]_*(s)\suchthat s\in\sigma,\,s\vert_B\in i_*(P_A)\}\,,
    \]
  where $i\inv\from M_B \pfun M_A$ is the canonical partial right-inverse to $i$, and if $\tau \from A \implies D$ is a strategy, then
  \[
    \subs_i;\tau = \{[i,\id_{M_D}]_*(s)\suchthat s\in\tau\}\,.
    \]
  \label{PropCopycat}
\end{proposition}
\begin{proof}
  $\subs_i$ is clearly prefix-closed by definition.  
  Suppose that $sab,sac\in\subs_i$; then $s\vert_A=i_*(s\vert_B)$ and $sab\vert_A=i_*(sab\vert_B)$.  
  It follows that $ab\vert_A=i_*(ab\vert_B)$, so either $a$ is a move in $A$ and $b=i(a)$ or $a$ is a move in $B$ and $a=i(b)$.  
  Since the same applies to $c$, and since $i$ is injective, we have $b=c$.

  This argument also shows that $\subs_i$ is \emph{history-free} -- i.e., that its reply to an $O$-position is entirely determined by the last $O$-move -- and therefore it is certainly innocent.

  Now let $\sigma \from C \implies B$ be a strategy.  
  Suppose that $\s\in\sigma\|\subs_i$.  
  Then $\s\vert_{C,B}\in\sigma$ and $\s\vert_B=i_*(\s\vert_A)$; i.e., $\s\vert_{C,B}=[\id_{M_C},i]_*(\s\vert_{C,A})$, and therefore $\s\vert_{C,A}=[\id_{M_C},i]_*(\s\vert_{C,B})$, where $\s\vert_B\in i_*(P_A)$.

  Conversely, given $s\in\sigma$, where $s\vert_B\in i_*(P_A)$, for each $P$-move $b=i(a)$ in $s$ occurring in the component $B$, insert the move $a$ immediately after it, and for each $O$-move $b'=i(a')$ in $s$ occurring in the component $B$, insert the move $a'$ immediately before it.
  Let these extra moves in $B$ be justified according to the original moves in $A$, and let all initial moves in $B$ be justified by the initial moves in $A$ that occur immediately before them.
  Then the resulting sequence $\s$ is contained in $\sigma\|\subs_i$, and $\s\vert_{A,C}=[\id_{M_C},i\inv]_*(s)$.

  The case for composition in the other direction is similar.
\end{proof}

An easy corollary of this fact is that composition of copycat strategies respects composition of the underlying subset inclusions.

\begin{corollary}
  Let $i$ be a subset inclusion from $A$ to $B$ and let $j$ be a subset inclusion from $B$ to $C$.  
  Then $j\circ i$ is a subset inclusion from $A$ to $C$ and $\cc_{j\circ i}=\subs_j;\subs_i\from C \implies A$.
\end{corollary}

It is also easy to see from Proposition \ref{PropCopycat} that the identity function $\id\from M_A \to M_A$ is a structural isomorphism from $A$ to itself, and that the resulting copycat strategy $\cc_{\id}$ is an identity for composition.  
Combining this with our result for associativity in the previous section, we get that
\begin{theorem}
  The collection of games forms a category $\G$, where the morphisms $A \to B$ are strategies for $A\implies B$, composition is as above and the identity morphisms are the copycat strategies induced from the identity functions on moves.
\end{theorem}

In this setting, Proposition \ref{PropCopycat} tells us that a structural isomorphism gives rise to an isomorphism in $\G$.
\begin{proposition}
  Let $f$ be a structural isomorphism from a game $A$ to a game $B$.  
  Then $\cc_f$ is an isomorphim in $\G$ from $A$ to $B$.
\end{proposition}
\begin{proof}
  The underlying partial injection $f\from M_A \hookrightarrow M_B$ has an inverse partial injection $f\inv\from M_B \to M_A$, inducing a structural isomorphism from $B$ to $A$.  
  Then Proposition \ref{PropCopycat} tells us that $\cc_f$ and $\cc_{f\inv}$ are inverses in $\G$.
\end{proof}

General subset inclusions are not, of course, isomorphisms, but we can still say something category-theoretic about them.

\begin{proposition}
  Let $i$ be a subset inclusion from a game $A$ to a game $B$.  
  Then the strategy $\subs_i$ is an epimorphism from $B$ to $A$.
  \label{PropSubsetInclusionEpic}
\end{proposition}
\begin{proof}
  In fact, it is a split epimorphism: we can define a retract
  \[
    \ret_i = \{s\in P_{A\implies B}\suchthat\text{for all even-length $t\prefix s$, $t\vert_A=i_*(t\vert_B)$}\}\,.
    \]
  The same argument as in Proposition \ref{PropCopycat} tells us that this is indeed a strategy for $A\implies B$.
  Note that although $\subs_i$ is always a total strategy (i.e., if $s\in\subs_i$ and $sa\in P_{B\implies A}$, then there is always $sab\in\subs_i$ for some $b$), the same is not in general true about $\ret_i$.  

  In any case, if $\s\in\ret_i\|\subs_i$, then $\s\vert_{A^L} = i_*(\s\vert_B) = \s\vert_{A^R}$, and the same is true of any even-length substring of $\s$, and so $\s\vert_{A,A}\in\id_A$.  
  Conversely, given any $s\in \id_A$, we can form some $\s\in\ret_i\|\subs_i$ such that $\s\vert_{A,A}=s$ as in Proposition \ref{PropCopycat}.

  We can also prove that $\subs_i$ is an epimorphism directly, which might be useful, for example, in a setting in which non-total strategies such as $\ret_i$ are disallowed.  
  In this setting, let $\sigma,\tau\from A \implies C$ be strategies such that $\subs_i;\sigma=\subs_i;\tau$.  
  Then, by Proposition \ref{PropCopycat}, we know that
  \[
    \{[i,\id_{M_C}]_*(s)\suchthat s\in\sigma\}
    =
    \{[i,\id_{M_C}]_*(s)\suchthat s\in\tau\}\,.
    \]
  Then, since the function $[i,\id_{M_D}]_* \from P_{A\implies C} \to P_{B\implies C}$ is an injection, we deduce that $\sigma=\tau$.
\end{proof}

\subsection{Tree Embeddings}

We can generalize the subset inclusions of the previous section to \emph{tree embeddings}.  
Tree embeddings are similar to subset inclusions, but generated by a function between plays, rather than between moves.  
A consequence of this is that while tree embeddings do give rise to strategies, these strategies are not in general innocent.

\begin{definition}
  Let $A,B$ be games.  
  A \emph{tree embedding} from $A$ to $B$ is a length-preserving function $\phi\from P_A \hookrightarrow P_B$ such that for all sequences $s,t\in P_A$, if $t\prefix s$ then $\phi(t)\prefix\phi(s)$ and such that if $\phi(sb)=\phi(sc)$, where $b,c$ are $P$-moves in $A$, then $b=c$.

  Given a tree embedding $\phi$ from $A$ to $B$, we define a strategy $\tree_\phi\from B \implies A$ by
  \[
    \tree_\phi = \{s\in P_{B\implies A}\suchthat\text{for all even-length $t\prefix s$, $t\vert_B=\phi(t\vert_A)$}\}\,.
    \]
\end{definition}
\begin{example}
  If $i$ is a subset inclusion from $A$ to $B$, then $i_*$ is a tree embedding from $A$ to $B$.
\end{example}

\begin{proposition}
  $\tree_\phi$ is a strategy.  

  If $\phi$ is a tree embedding from $A$ to $B$ and $\psi$ is a tree embedding from $B$ to $C$, then $\psi\circ\phi$ is a tree embedding from $A$ to $C$ and $\tree_{\psi\circ\phi}=\tree_\psi;\tree_\phi$.
  \label{PropTree}
\end{proposition}
\begin{proof}
  $\tree_\phi$ is a prefix-closed subset of $P_{B\implies A}$ by definition.  
  If $sab,sac\in\tree_\phi$, then we have $s\vert_B=\phi(s\vert_A)$ and $sab\vert_B=\phi(sab\vert_A)$.
  Since $\phi$ is length-preserving, $s\vert_A$ and $s\vert_B$ must have the same length, and the same is true of $sab\vert_A$ and $sab\vert_B$.  
  Therefore, either $a$ is a move in $A$ and $s\vert_Bb=\phi(s\vert_Aa)$ or $a$ is a move in $B$ and $s\vert_Ba=\phi(s\vert_Ab)$.  
  The same applies to $c$: so either $s\vert_Bb=\phi(s\vert_Aa)=s\vert_Bc$ or $\phi(s\vert_Ab)=s\vert_Ba=\phi(s\vert_Ac)$.  
  In either case, we have $b=c$.

  Now suppose that $\phi$ is a tree embedding from $A$ to $B$ and that $\psi$ is a tree embedding from $B$ to $C$.  
  Then $\psi\circ\phi$ certainly preserves length and the prefix relation.  
  Let $\s\in\tree_\psi\|\tree_\phi$, and let $t\prefix \s\vert_{C,A}$ have even length.  
  Let $\t$ be a prefix of $\s$ such that $\t\vert_{C,A}=t$.
  Then, by the argument above, $\t\vert_{C,B}$ and $\t\vert_{B,A}$ have even length, and so $\t\vert_C=\psi(\t\vert_B)$ and $\t\vert_B=\phi(\t\vert_A)$.  
  Therefore, $t\vert_C=(\psi\circ\phi)(t\vert_A)$.  
  Since $t$ was arbitrary, this means that $\s\vert_{A,C}\in\tree_{\psi\circ\phi}$.

  Conversely, suppose that $s\in\tree_{\psi\circ\phi}$: so $t\vert_C = \psi(\phi(t\vert_A))$ for all even-length $t\prefix s$.
  By induction on the length of $s$, we build up a sequence $\s(s)\in\tree_\psi\|\tree_\phi$ such that $\s(s)\vert_{C,A}=s$.
  \begin{itemize}
    \item $\s(\epsilon) = \epsilon$.
    \item Given a sequence $sab\in\tree_{\psi\circ\phi}$, we have $s\vert_C=\psi(\phi(s\vert_A))$.  
      By our discussion above, we know that $sab\vert_A$ is one move longer than $s\vert_A$, so $\phi(sab\vert_A)=\phi(s\vert_A)c$ for some move $c$ in $B$, justified by some move in $B$.
      Then we set $\s(sab)=\s(s)acb$, where the justifier of $c$ is as above.
  \end{itemize}
  It is clearly true that $\s(s)\vert_{C,A}=s$ for all sequences $s\in\tree_{\psi\circ\phi}$.  

  We claim that $\s(s)\in\tree_\psi\|\tree_\phi$ for all $s$.  
  This is clearly true for the empty sequence; for $sab$, we have $\s(sab)\vert_{B,A} = \s(s)acb\vert_{B,A}$, where $\phi(sab\vert_A)=\phi(s\vert_A)c$.  

  By induction, $\s(s)\in\psi(\phi(s\vert_A))$, and so for all even-length $t\prefix \s(s)\vert_{B,A}$ we have $t\vert_B=\phi(t\vert_A)$, and for all even-length $u\prefix\s(s)\vert_{C,B}$ we have $u\vert_C=\psi(u\vert_B)$.  
  All we need to show is that $\s(s)acb\vert_B=\phi(\s(s)acb\vert_A)$ and that $\s(s)acb\vert_C=\psi(\s(s)acb\vert_B)$.  
  Indeed, $\phi(\s(s)acb\vert_A)=\phi(sab\vert_A)=\phi(s\vert_A)c=\phi(\s(s)\vert_A)c=\s(s)\vert_Bc=\s(s)acb\vert_V$, and, in addition, we have that $\psi(\s(s)acb\vert_B) = \psi(\s(s)\vert_Bc) = \psi(\phi(\s(s)\vert_A)c) = \psi(\phi(sab\vert_A))=sab\vert_C=\s(s)acb\vert_C$.
\end{proof}

\begin{definition}
  We say that a tree embedding $\phi$ is a \emph{tree isomorphism} if it is a bijection.
\end{definition}

\begin{proposition}
  If $\phi$ is a tree isomorphism from a game $A$ to a game $B$, then $\tree_\phi$ is an isomorphism in $\G$.
\end{proposition}
\begin{proof}
  If $\phi$ is a tree isomorphism, then its inverse $\phi\inv$ is also a tree isomorphism, and Proposition \ref{PropTree} tells us that $\tree_\phi$ and $\tree_{\phi\inv}$ are inverses in $\G$.
\end{proof}

\subsection{$\G$ as a Symmetric Monoidal Category}

We now claim that the tensor product connective $\tensor$ makes $\G$ into a symmetric monoidal closed category, with internal hom given by $\implies$.  

\begin{definition}
  Let $\sigma\from A \implies B$ and $\tau\from C \implies D$ be strategies.  
  We define a strategy $\sigma\tensor\tau\from (A\tensor C) \implies (B \tensor D)$ by
  \[
    \sigma\tensor\tau = \{s\in P_{(A\tensor C)\implies (B\tensor D)}\suchthat s\vert_{A,B}\in\sigma\text{ and }s\vert_{C,D}\in\tau\}\,.
    \]
\end{definition}

To prove that this is a strategy, we prove a lemma analogous to our Lemma \ref{LemCompositionLemma}.  

\begin{lemma}
  Let $s\in P_{A\tensor B}$.  
  Then $\lambda^{OP}_{A\tensor B}(s)=\lambda^{OP}_A(s\vert_A)\wedge\lambda^{OP}_B(s\vert_B)$, where $\wedge$ is the binary operator on $\OP$ given by
  \[
    \begin{array}{cc|c}
      p & q & p\wedge q \\
      \hline
      P & P & P \\
      O & P & O \\
      P & O & O \\
      O & O & O
    \end{array}\,.
    \]
  Moreover, either $\lambda_A^{OP}(s\vert_A)=P$ or $\lambda_B^{OP}(s\vert_B)=P$.
  \label{LemTensorAnalogue}
\end{lemma}
\begin{proof}
  Mutual induction on the length of $s$.  
  This is obvious if $s$ is empty.  
  Suppose that $sa\in P_{A\tensor B}$, where $a$ is an $O$-move.  
  By induction, since $\lambda_{A\tensor B}(s)=P$, we must have $\lambda_{A\tensor B}(s\vert_A)=P$ and $\lambda_{A\tensor B}(s\vert_B)=P$.  
  Therefore, depending on which game $a$ is played in, either $\lambda_A(sa\vert_A)=O$ and $\lambda_B(sa\vert_B)=P$ or $\lambda_A(sa\vert_A)=P$ and $\lambda_B(sa\vert_B)=O$.  

  If $sb\in P_{A\tensor B}$, where $b$ is a $P$-move, then by induction either $\lambda_A(s\vert_A)=O$ and $\lambda_B(s\vert_B)=P$ or $\lambda_A(s\vert_A)=P$ and $\lambda_B(s\vert_B)=O$.  
  In either case, player $P$ must play in whichever game is currently in an $O$-position, returning us to configuration $PP$.
\end{proof}

The above proof gives us the following result analogous to Corollary \ref{CorSwitchingCondition}.

\begin{corollary}[Switching condition for {$\tensor$}]
  Player $O$ switches games in $A\tensor B$; i.e., if $sab\in P_{A\tensor B}$, where $a$ and $b$ take place in different games (i.e., $a$ in $A$ and $b$ in $B$ or $a$ in $B$ and $b$ in $A$), then $b$ is an $O$-move.
\end{corollary}

\begin{proposition}
  $\sigma\tensor\tau$ is a strategy for $(A\tensor C)\implies (B\tensor D)$.
  \label{PropTensorWellDefined}
\end{proposition}
\begin{proof}
  $\sigma\tensor\tau$ is certainly an even-prefix-closed subset of $P_{(A\tensor C)\implies (B\tensor D)}^{\textit{even}}$.  

  Let $s$ be a play of $P_{(A\tensor B)\implies (C\tensor D)}$.  
  We consider the possible configurations of $s$; i.e., the tuples $(\lambda_A(s\vert_A),\lambda_B(s\vert_B),\lambda_C(s\vert_C),\lambda_D(s\vert_D))$.

  By Lemma \ref{LemCompositionLemma} we must avoid the overall configuration $OP$ for the linear implication, and by Lemma \ref{LemTensorAnalogue} we must avoid the configuration $OO$ inside either tensor product, so we end up with the following possibilities.
  \scriptsize
  \[
\arraycolsep=4.8pt\def\arraystretch{1.5}
    \begin{array}{cccc|cc|c}
      \lambda_A(s\vert_A) & \lambda_C(s\vert_C) & \lambda_B(s\vert_B) & \lambda_D(s\vert_D) & \lambda_{A\tensor C}(s\vert_{A,C}) & \lambda_{B\tensor D}(s\vert_{B,C}) & \lambda_{(A\tensor C)\implies (B\tensor D)}(s) \\
      \hline
      P & P & P & P & P & P & P \\
      P & P & P & O & P & O & O \\
      P & P & O & P & P & O & O \\
      P & O & P & O & O & O & P \\
      O & P & O & P & O & O & P \\
      P & O & O & P & O & O & P \\
      O & P & P & O & O & O & P \\
    \end{array}
    \]
  \normalsize
  Now, if $s\in\sigma\tensor\tau$, or an odd-length sequence formed by adding an $O$-move to the end of a sequence in $\sigma\tensor\tau$, then we also know that $s\vert_{A,B}\in\sigma\subset P_{A\implies B}$ and that $s\vert_{C,D}\in\tau\subset P_{C\implies D}$.  
  This means that we can discount the last two configurations in the table above, since one contains the illegal configuration $OP$ in $C\implies D$ and the other contains the illegal configuration $OP$ in $A \implies B$.

  Now suppose that $sab,sac\in\sigma\tensor\tau$.  
  Then $sa$ is an $O$-position in $P_{(A\tensor C)\implies (B\tensor D)}$, and is therefore in configuration $PPPO$ or $PPOP$.  
  By inspecting the table above, we see that if $sa$ is in configuration $PPPO$, then $b$ and $c$ must both occur either in $C$ or in $D$, and that if $sa$ is in configuration $PPOP$, then $b$ and $c$ must both occur either in $A$ or in $B$.  
  In either case, we must have $b=c$, by determinism of $\tau$ (in the first case) or of $\sigma$ (in the second case).
\end{proof}

We need a lemma to prove that the tensor product of two innocent strategies is innocent.

\begin{lemma}
  Let $s\in\sigma\tensor\tau$.  

  i) If $s$ ends with a move in $A$ or $B$, then $\pv{s}^{(A\tensor C)\implies (B\tensor D)}=\pv{s\vert_{A,B}}^{A\implies B}$.

  ii) If $s$ ends with a move in $C$ or $D$, then $\pv{s}^{(A\tensor C)\implies (B\tensor D)}=\pv{s\vert_{C,D}}^{C\implies D}$.
  \label{LemTensorViewLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $s$.  
  We prove (i); (ii) is exactly the same.

  If $a$ is a $P$-move, then we have $\pv{sa}=\pv{s}a$.  
  By our analysis in the proof of Proposition \ref{PropTensorWellDefined}, player $P$ only switches moves between $A$ and $B$, and between $C$ and $D$, so $s$ must end with a move from $A$ or $B$.  
  Therefore, by the inductive hypothesis, $\pv{s}=\pv{s\vert_{A,B}}$.  
  Then $\pv{sa}=\pv{s}a=\pv{s\vert_{A,B}}a=\pv{sa\vert_{A,B}}$.  

  If $a$ is an initial move, then $\pv{sa}=a=\pv{sa\vert_{A,B}}$.

  If $a$ is an $O$-move justified by $b$ in $sbta$, then $\pv{sbta}=\pv{s}ba$.  
  Then $b$ is a $P$-move, so $s$ must end with a move in $A$ or $B$, as before.  
  Therefore, by the inductive hypothesis, $\pv{s}=\pv{s\vert_{A,B}}$.  
  Then $\pv{sbta}=\pv{s}ba=\pv{s\vert_{A,B}}ba=\pv{sbta\vert_{A,B}}$.
\end{proof}

\begin{proposition}
  Let $\sigma\from A \to B$, $\tau\from C \to D$ be innocent strategies.  
  Then $\sigma\tensor\tau$ is innocent.
\end{proposition}
\begin{proof}
  Suppose $sab,t\in\sigma\tensor\tau$ such that $ta\in P_{(A\tensor C)\implies (B\tensor D)}$ and $\pv{sa}=\pv{ta}$.  
  Suppose without loss of generality that $a$ is a move in $A$ or $B$.  
  Then $\pv{sa}=\pv{sa\vert_{A,B}}$ and $\pv{ta}=\pv{ta\vert_{A,B}}$ by Lemma \ref{LemTensorViewLemma}, and therefore $tab\vert_{A,B}\in\sigma$ by innocence of $\sigma$, and so $tab\in\sigma\tensor\tau$.  
\end{proof}

The most important thing we need to prove is that $\tensor$ is a functor.

\begin{proposition}
  Let $\sigma'\from A'' \implies A'$, $\sigma\from A' \implies A$, $\tau'\from B'' \implies B'$ and $\tau \from B' \implies B$ be strategies.  
  Then $(\sigma'\tensor\tau');(\sigma\tensor\tau)=(\sigma';\sigma)\tensor(\tau';\tau)$.

  Moreover, if $A',A,B',B$ are games, $i$ is a subset inclusion from $A$ to $A'$ and $j$ is a structural isomorphism from $B$ to $B'$, then $\subs_i\tensor\subs_j = \subs_{[i,j]}$.
  In particular, if $A$ and $B$ are games, then $\id_A\tensor \id_B=\id_{A\tensor B}$.
  \label{PropTensorProductIsFunctor}
\end{proposition}
\begin{proof}
  First suppose that $s\in(\sigma'\tensor\tau');(\sigma\tensor\tau)$; so $s=\s\vert_{A'',B'',A,B}$, where $\s\in(\sigma'\tensor\tau')\|(\sigma\tensor\tau)$.  
  Then $\s\vert_{A'',A'}\in\sigma'$ and $\s\vert_{A',A}\in\sigma$, so $\s\vert_{A'',A',A}\in\sigma'\|\sigma$ and therefore $s\vert_{A'',A}=\s\vert_{A'',A}\in\sigma';\sigma$.  
  Similarly, $s\vert_{B'',B}\in\tau';\tau$, and therefore $s\in(\sigma';\sigma)\tensor(\tau';\tau)$.

  Conversely, suppose that $s\in(\sigma';\sigma)\tensor (\tau';\tau)$.  
  Choose some $\s\in\sigma'\|\sigma$, $\t\in\tau'\|\tau$ such that $s\vert_{A'',A}=\s\vert_{A'',A}$ and $s\vert_{B'',B}=\s\vert_{B'',B}$.  
  By our analysis, the only time we switch from the $A'',A$-component to the $B'',B$ component in $s$, or \emph{vice versa}, is when player $O$ switches between the games $A$ and $B$.  
  Thus, we may divide $s$ up into blocks, each starting and ending with a move in the outer component $A \tensor B$.  
  This then gives us a way to divide up $\s$ and $\t$ into blocks, such that each block of $\s$ or $\t$ projects on to a block of $s$.  
  Lastly, we can string these blocks together to give us some $\u\in(\sigma'\tensor\tau')\|(\sigma\tensor\tau)$ such that $\u\vert_{A'',B'',A,B}=s$.

  For the second part, let $A',A,B',B$ be games, let $i$ be a structural isomorphism from $A$ to $A'$ and let $j$ be a structural isomorphism from $B$ to $B'$.  
  Suppose that $s\in\subs_i\tensor \subs_j$.  
  Then $s\vert_{A',A}\in\subs_i$ and $s\vert_{B',B}\in\subs_j$ -- so if $u\prefix s\vert_{A,A}$ has even length, then $u\vert_{A'}=i_*(u\vert_A)$, and if $v\prefix s\vert_{B,B}$ has even length, then $v\vert_{B'}=i_*(v\vert_B)$.  
  Suppose that $t\prefix s$ is of even length.  
  Then, since only player $O$ swtiches between the $A',A$-component and the $B',B$-component, both $t\vert_{A',A}$ and $t\vert_{B',B}$ are of even length, it follows that $t\vert_{A',B'}=[i,j]_*(t\vert_{A,B})$.  
  Since $t$ was arbitrary, this means that $s\in \subs_{[i,j]}$.

  Conversely, suppose that $s\in\subs_{[i,j]}$.  
  Then for all even-length $t\prefix s$, $t\vert_{A'}=i_*(t\vert_{A})$ and $t\vert_{B'}=j_*(t\vert_{B})$.  
  Since any play in $\sigma$ or in $\tau$ is itself a play of $\sigma\tensor\tau$, then if $u\prefix s\vert_{A',A}$ has even length, then $u\vert_{A'}=i_*(u\vert_{A})$, and if $v\prefix s\vert_{B',B}$, then $v\vert_{B'}=j_*(v\vert_{B})$.  
  It follows that $s\vert_{A',A}\in \subs_i$ and $s\vert_{B',B}\in\subs_j$, and therefore that $s\in \subs_i\tensor\subs_j$.  
\end{proof}

Now it is fairly clear that if $A,B,C$ are games, then we have structural isomorphisms
\begin{mathpar}
  (A \tensor B) \tensor C \cong A \tensor (B\tensor C)
  \\
  A \cong A \tensor I \and A \cong I \tensor A
  \\
  A \tensor B \cong B \tensor A\,,
\end{mathpar}
induced by the associators, unitors and symmetry of the category of sets with coproduct.
We claim that these are natural transformations.

\begin{proposition}
  The families of morphisms
  \begin{mathpar}
    \cc_{\assoc_{M_A,M_B,M_C}} \from (A \tensor B) \tensor C \to A \tensor (B \tensor C)
    \\
    \cc_{\lunit_{M_A}} \from A \to I \tensor A \and \cc_{\runit_{M_A}} \from A \to A \tensor I
    \\
    \cc_{\sym{M_A,M_B}} \from A \tensor B \to B \tensor A
  \end{mathpar}
  are natural transformations in $\G$.
  \label{PropCoherencesAreNatural}
\end{proposition}
\begin{proof}
  We prove this for the associator; the other cases are similar.

  Let $\sigma\from A' \implies A$, $\tau\from B' \implies B$, $\upsilon\from C' \implies C$ be strategies.  
  By Proposition \ref{PropCopycat}, we have
  \begin{IEEEeqnarray*}{Cl}
    & ((\sigma\tensor\tau)\tensor\upsilon);\cc_{\assoc_{M_{A},M_{B},M_{C}}} \\
    = & \{[\id_{M_{(A'\tensor B')\tensor C'}},\assoc_{M_A,M_B,M_C}]_*(s)\suchthat s\in (\sigma\tensor\tau)\tensor\upsilon\} \\
    = & \left\{[\id_{M_{(A'\tensor B')\tensor C'}},\assoc_{M_A,M_B,M_C}]_*(s) \,\middle|\,\mbox{\pbox{\textwidth}{
      $s\in P_{((A'\tensor B')\tensor C')\implies ((A \tensor B) \tensor C)}$\\
      $s\vert_{A',A}\in\sigma$, $s\vert_{B',B}\in\tau$, $s\vert_{C',C}\in\upsilon$
    }}\right\} \\
    = & \{s\in P_{((A'\tensor B') \tensor C') \implies (A \tensor (B \tensor C))} \suchthat s\vert_{A',A}\in\sigma,s\vert_{B',B}\in\tau,s\vert_{C',C}\in\upsilon\} \\
    = & \left\{[\assoc_{M_{A'},M_{B'},M_{C'}},\id_{M_{A\tensor (B\tensor C)}}]_*(s) \,\middle|\,\mbox{\pbox{\textwidth}{
      $s\in P_{(A'\tensor (B'\tensor C'))\implies (A \tensor (B \tensor C))}$\\
      $s\vert_{A',A}\in\sigma$, $s\vert_{B',B}\in\tau$, $s\vert_{C',C}\in\upsilon$
    }}\right\} \\
    = & \{[\assoc_{M_{A'},M_{B'},M_{C'}},\id_{M_{A\tensor (B\tensor C)}}]_*(s)\suchthat s\in \sigma\tensor (\tau\tensor \upsilon)\} \\
    = & \cc_{\assoc_{M_{A'},M_{B'},M_{C'}}};(\sigma\tensor(\tau\tensor\upsilon))\,.\hspace{1pt plus 1fill} \qedhere
  \end{IEEEeqnarray*}
\end{proof}

Then, by Proposition \ref{PropCopycat} again, these natural transformations satisfy the same coherence diagrams (pentagon, triangles, hexagon etc.) satisfied by the original associators, unitors and symmetry in $(\Set,+)$.  

It follows that $\tensor$ makes $\G$ into a symmetric monoidal category.

\subsection{$\G$ as a Symmetric Monoidal Closed Category}

\begin{definition}
  Let $A,B,C,D$ be games, let $\sigma$ be a strategy for $A\implies B$ and let $\tau$ be a strategy for $C\implies D$.  
  Then we define a strategy $\sigma\implies \tau\from (B\implies C) \implies (A\implies D)$ by
  \[
    \sigma\implies \tau = \{s\in P_{(B\implies C) \implies (A \implies D)}\suchthat \text{$s\vert_{A,B}\in\sigma$, $s\vert_{C,D}\in\tau$}\}\,.
    \]
\end{definition}

\begin{proposition}
  $\sigma\implies\tau$ is a strategy for $(B\implies C) \implies (A \implies D)$.
  \label{PropImpliesWellDefined}
\end{proposition}
\begin{proof}
  $\sigma\implies\tau$ is certainly a prefix-closed subset of $P_{(B\implies C)\implies (A \implies D)}^{\textit{even}}$.
  
  We examine the sign configuration of a play in $(B\implies C)\implies (A\implies D)$, using Lemma \ref{LemCompositionLemma}.  
  Since we must avoid the configuration $OP$ in either $B\implies C$, $A\implies D$ or in $(B\implies C)\implies (A\implies D)$, we arrive at the following list of possibilities.
  \scriptsize
  \[
\arraycolsep=2.7pt\def\arraystretch{1.5}
    \begin{array}{cccc|cc|c}
      \lambda_B^{OP}(s\vert_B) & \lambda_C^{OP}(s\vert_C) & \lambda_A^{OP}(s\vert_A) & \lambda_D^{OP}(s\vert_D) & \lambda_{B\implies C}^{OP}(s\vert_{B,C}) & \lambda_{A\implies D}^{OP}(s\vert_{A,D}) & \lambda_{(B\implies C)\implies (A\implies D)}^{OP}(s) \\
      \hline
      P & O & P & O & O & O & P \\
      P & P & P & O & P & O & O \\
      O & O & P & O & P & O & O \\
      P & P & P & P & P & P & P \\
      O & O & O & O & P & P & P \\
      P & P & O & O & P & P & P \\
      O & O & P & P & P & P & P
    \end{array}
    \]
  \normalsize
  If $s\in\sigma\implies\tau$, then we can immediately discount the last two of these possibilities, since one includes the illegal configuration $OP$ in $A\implies B$, and the other includes the illegal configuration $OP$ in $B\implies D$.

  By examining the remaining possibilities, we arrive at the conclusion that any $O$-position in configuration $PPPO$ constrains player $P$ to play in $C$ (to reach configuration $POPO$) or to play in $D$ (to reach configuration $PPPP$), and that any $O$-position in configuration $OOPO$ constrains player $P$ to play in $A$ (to reach configuration $OOOO$) or to play in $C$ (to reach configuration $POPO$).  

  Now suppose that $sab,sac\in\sigma\implies\tau$.  
  Then, by our above analysis, $b$ and $c$ must either both take place in the $B,A$-component, in which case $b = c$ by determinism of $\sigma$, or both in the $C,D$-component, in which case $b = c$ by determinism of $\tau$.  
\end{proof}

To prove that $\sigma\implies\tau$ is innocent if $\sigma$ and $\tau$ are, we need a lemma analogous to Lemma \ref{LemTensorViewLemma}.

\begin{lemma}
  Let $s\in \sigma\implies \tau$.  

  i) If $s$ ends with a move in $A$ or $B$, then $\pv{s}^{(B\implies C) \implies (A\implies D)} = \pv{s\vert_{A,B}}^{A\implies B}$.  

  ii) If $s$ ends with a move in $C$ or $D$, then $\pv{s}^{(B\implies C) \implies (A\implies D)} = \pv{s\vert_{C,D}}^{C\implies D}$.
  \label{LemImpliesViewLemma}
\end{lemma}
\begin{proof}
  Exactly the same as in Lemma \ref{LemTensorViewLemma}, using the analysis from the proof of Proposition \ref{PropImpliesWellDefined} to show that player $P$ only switches moves between $A$ and $B$, and between $C$ and $D$, in $\sigma\implies\tau$.
\end{proof}

\begin{proposition}
  Let $\sigma\from A \implies B$, $\tau\from C\implies D$ be innocent strategies.  
  Then $\sigma\implies\tau$ is innocent.
\end{proposition}
\begin{proof}
  Suppose $sab,t\in\sigma\implies\tau$ such that $ta\in P_{(B\implies C)\implies (A \implies D)}$ and $\pv{sa}=\pv{ta}$.  
  Suppose without loss of generality that $a$ is a move in $A$ or $B$.  
  Then $\pv{sa}=\pv{sa\vert_{A,B}}$ and $\pv{ta}=\pv{ta\vert_{A,B}}$ by Lemma \ref{LemImpliesViewLemma}, and therefore $tab\vert_{A,B}\in\sigma$ by innocence of $\sigma$, and so $tab\in\sigma\implies\tau$.
\end{proof}

We now need to prove that $\implies$ is a functor $\oppcat\G\times\G\to\G$.

\begin{proposition}
  Let $\sigma'\from A''\implies A'$, $\sigma\from A'\implies A$, $\tau'\from B'' \implies B'$ and $\tau\from B'\implies B$ be strategies.  
  Then $(\sigma\implies\tau');(\sigma'\implies\tau) = (\sigma';\sigma)\implies(\tau';\tau)$.

  Moreover, if $A',A,B',B$ are games, $f$ is a structural isomorphism from $A'$ to $A$ and $g$ is a structural isomorphism from $B'$ to $B$, then $\cc_f\implies\cc_g = \cc_{[f\inv,g]}$.
  In particular, if $A,B$ are games than $\id_A\implies\id_B=\id_{A\implies B}$.
\end{proposition}
\begin{proof}
  As in Proposition \ref{PropTensorProductIsFunctor}.
\end{proof}

Now it is easy to see that the associator $\assoc_{M_A,M_B,M_C}$ is a structural isomorphism from $(A\tensor B) \implies C$ to $A\implies (B\implies C)$, so it induces a copycat isomorphism $\Lambda_{A,B,C}=\cc_{\assoc_{M_A,M_B,M_C}} \from (A\tensor B) \implies C \to A \implies (B\implies C)$.

\begin{proposition}
  $\Lambda_{A,B,C}$ is natural in $A,B,C$.
\end{proposition}
\begin{proof}
  The same argument as in Proposition \ref{PropCoherencesAreNatural}.
\end{proof}

We have proved the following.

\begin{theorem}
  $\G$ is a symmetric monoidal closed category, with tensor product given by $\tensor$ and internal hom given by $\implies$.
\end{theorem}

\subsection{Products in $\G$}

\begin{proposition}
  Given some family $A_i$ of games, the game $\prod_i A_i$, as defined in Definition \ref{DefProduct}, is the category-theoretic product of the $A_i$.
  \label{PropProductOfGames}
\end{proposition}
\begin{proof}
  We have natural injections $\inj_j \from M_{A_j} \hookrightarrow M_{\prod_i A_i}$ giving rise to subset inclusions.  
  Then our projections are given by the morphisms 
  \[
    \pr_j \coloneqq \subs_{\inj_j}\from \prod_i A_i \to A_j\,.
    \]
  Now suppose we have some game $B$, and strategies $\sigma_i \from B \implies A_i$ for each $i$.
  Define a strategy
  \[
    \langle \sigma_i \rangle = \bigcup_i [\id_{M_B},\inj_i]_*(\sigma_i)\,.
    \]
  We claim that this is indeed a strategy for $B \implies \prod_i A_i$.
  Indeed, it is certainly a prefix-closed subset of $P_{C\implies\prod_i A_i}$.

  Moreover, if $sab,sac\in\langle \sigma_i \rangle$, then there is some unique $j$ such that $a$ comes from a move in $A_j$, and therefore $sab,sac$ are both plays in $\sigma_j$, so $b=c$.

  Next, we claim that $\langle\sigma_i\rangle;\pr_j = \sigma_j$.  
  Indeed, we have
  \begin{IEEEeqnarray*}{rCl?u}
    \langle\sigma_i\rangle;\pr_j & = & \langle\sigma_i\rangle;\subs_{\inj_j} \\
    & = & \{[\id_{M_B},\inj_j\inv]_*(s)\suchthat s\in\langle\sigma_i\rangle,\,s\vert_{\prod_iAi}\in(\inj_j)_*(P_{A_j})\} & \textit{Prop. \ref{PropCopycat}} \\
    & = & \sigma_j\,.
  \end{IEEEeqnarray*}
  Lastly, suppose $\tau\from B\implies\prod_iA_i$ is a strategy such that $\tau;\pr_j=\sigma_j$ for each $j$.
  We claim that $\tau=\langle\sigma_i\rangle$.
  Indeed, by the argument above, we must have
  \[
    \{[\id_{M_B},\inj_j\inv]_*(s)\suchthat s\in\tau,\,s\vert_{\prod_iA_i}\in(\inj_j)_*(P_{A_j})\} = \sigma_j
    \]
  for each $j$.
  Suppose that $s\in\tau$.  
  Then $s\vert_{\prod_iA_i}\in(\inj_j)_*(P_{A_j})$ for some $j$, by the definition of $\prod_iA_i$.  
  Therefore, $s\in[\id_{M_B},\inj_j]_*(\sigma_j)$.  

  Conversely, let $t\in \sigma_j$.  
  By the above equation, we know that there is some $s\in\tau$ such that $s\vert_{\prod_iA_i}\in(\inj_j)_*(P_{A_j})$ and $[\id_{M_B},\inj_j\inv]_*(s)=t$.  
  It follows that $[\id_{M_B},\inj_j]_*(t)=s\in\tau$.
\end{proof}

An examination of the definitions tells us that
\begin{proposition}
  Let $A_i,B$ be games and let $\phi_i$ be tree embeddings from $A_i$ to $B$.  
  Then $\langle \tree_{\phi_i} \rangle = \tree_\phi$, where $\phi$ is the tree embeddings from $\prod_iA_i$ to $B$ given by
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      \phi_i(s\vert_{A_i}) & \text{if $s$ starts with a move from $A_i$}
    \end{cases}
    \]
  \label{PropProductOfTreeEmbeddings}
\end{proposition}
\begin{proof}
  The only thing we really need to check is that this is indeed a tree embedding.  
  Let $sb,sc$ be positions in $\prod_iA_i$, where $b,c$ are $P$-moves.
  Then $sb,sc$ must start with the same move, so if $\phi(sb)=\phi(sc)$ then we have $\phi_i(sb)=\phi_i(sc)$ for some $i$ and therefore $b=c$.
\end{proof}

Note that $\langle\sigma_i\rangle$ is not in general innocent, even if all the $\sigma_i$ are, and there is no version of Proposition \ref{PropProductOfTreeEmbeddings} that works for subset inclusion strategies.
Of course, since a subset inclusion is a special case of a tree embedding, then $\langle \subs_i\rangle$ is always a tree embedding strategy.

\subsection{Sequoidal categories}

We have now given the category-theoretic properties of all the connectives from Section \ref{SecConnectives}, with the exception of the sequoid $\sequoid$ and the exponential $\oc$.

We would like to say that $\blank\sequoid\blank$ is a functor from $\G \times \G \to \G$, as is the case with the tensor product $\blank\tensor\blank$.  
However, this does not quite work: given strategies $\sigma\from A \implies B$ and $\tau\from C \implies D$, we may not get a well-formed strategy for $(A \sequoid C) \implies (B \sequoid D)$ by `playing according to $\sigma$ in $A$ and $B$ and according to $\tau$ in $C$ and $D$'.  
The reason is that the constraint that player $O$ plays in $B$ before $D$ is not strong enough to force player $P$ to play in $A$ before $C$; indeed, suppose that $\sigma$ tells player $P$ to respond to an initial move in $B$ with another move in $B$.  
Suppose that player $O$ then decides to make a move in $D$.  
If $\tau$ tells player $P$ to respond to this move in $D$ with a move in $C$, then she will be stuck, unable to play this move because no move has yet been played in $A$.

We can fix this problem by imposing some constraints on the strategies $\sigma$ and $\tau$.  
The problem occurs when player $O$'s initial move in $B$ is not reflected by an initial move by player $P$ in $A$; therefore, if $\sigma$ is such that player $P$ always responds to the initial move in $B$ with a move in $A$, then we can form a strategy $\sigma\sequoid\tau$ for $(A\sequoid C)\implies (B\sequoid D)$.  
Moreover, this strategy $\sigma\sequoid\tau$ will inherit this property that the first move on the right is always replied to by a move on the left.

\begin{definition}
  Let $A,B$ be games.  
  A \emph{strict morphism} from $A$ to $B$ is a strategy $\sigma$ for $A\implies B$ such that any player $P$ response to an opening move in $B$ is a move in $A$; i.e., such that if $b$ is an initial $O$-move in $B$ and $ba\in\sigma$, then $a$ is a move in $A$.
\end{definition}

We will call such a $\sigma$ a \emph{strict strategy} for $A\implies B$, although this is a slight abuse of language, since the definition depends on the constituent games $A$ and $B$, which may not be recoverable from $A\implies B$.

It is clear that the composition of strict morphisms is again a strict morphism , as is any morphism of the form $\subs_i$, and so we get a wide subcategory $\G_s$ of $\G$ whose objects are games and where the morphisms are the strict strategies.
We then have a natural inclusion functor $J\from \G_s\to \G$.  

\begin{definition}
  Given games $A,B,C,D$, a strict morphism $\sigma\from A \implies B$ and a strategy $\tau\from C\implies D$, we define a strict morphism $\sigma\sequoid\tau\from (A \sequoid C)\implies (B \sequoid D)$ by
  \[
    \sigma\sequoid\tau = \{s\in P_{(A\sequoid C)\implies (B\sequoid D)}\suchthat s\vert_{A,B}\in\sigma,\,s\vert_{C,D}\in\tau\}\,.
    \]
  \label{DefSequoidOfStrategies}
\end{definition}

\begin{proposition}
  $\sigma\sequoid\tau$ is a strategy.  
\end{proposition}
\begin{proof}
  $\sigma\sequoid\tau$ is certainly a prefix-closed subset of $P_{(A\sequoid C)\implies (B\sequoid D)}$.  
  Moreover, if $sab,sac\in\sigma\sequoid\tau$, then $sab,sac\in\sigma\tensor\tau$, so $b=c$.  
\end{proof}

Of course, $P_{A\sequoid B}$ is a subset of $P_{A\tensor B}$, which means that the identity function $M_A + M_B \to M_A + M_B$ gives us a subset inclusion from $A \sequoid B$ to $A \tensor B$, and hence a strategy $\subs_{\id_{M_A+M_B}}$ for $A\tensor B \implies A \sequoid B$, which we shall refer to as $\wk_{A,B}$.  

\begin{proposition}
  Let $A,B,C,D$ be games, let $\sigma\from A \implies B$ be a strict strategy and let $\tau\from C \implies D$ be a strategy.  
  Then the following diagram commutes.
  \[
    \begin{tikzcd}
      A \tensor C \arrow[r, "\sigma\tensor\tau"] \arrow[d, "{\wk_{A,C}}"']
        & B \tensor D \arrow[d, "{\wk_{B,D}}"] \\
      A \sequoid C \arrow[r, "\sigma\sequoid\tau"]
        & B \sequoid D
    \end{tikzcd}
    \]
  \label{PropWkCommutativeDiagram}
\end{proposition}
\begin{proof}
  By Proposition \ref{PropCopycat} and the definition of $\wk$, we know that
  \begin{IEEEeqnarray*}{rCl}
    \sigma\tensor\tau;\wk_{B,D} & = & \{s\in \sigma\tensor\tau,\,s\vert_{B,D}\in P_{B\sequoid D}\}
    \\
    \wk_{A,C};\sigma\sequoid\tau & = & \sigma\sequoid\tau\,,
  \end{IEEEeqnarray*}
  as sets of plays.

  Now we know that $\sigma\sequoid\tau = \{s\in\sigma\tensor\tau\suchthat s\in P_{(A\sequoid C)\implies (B\sequoid D)}\}$, so it suffices to show that if $s\in\sigma\tensor\tau$ is such that $s\vert_{B,D}\in P_{B\sequoid D}$ then $s\in P_{(A\sequoid C)\implies (B\sequoid D)}$.

  Indeed, if $s\vert_{B,D}\in P_{B\sequoid D}$ then $s$ begins with an initial $O$-move in $B$.  
  Then, \emph{since $\sigma$ is strict}, the next move in $s$ must be a move in $A$, and therefore $s\vert_{A,C}$ begins with a move in $A$.
  Since we also have $s\vert_{A,C}\in P_{A\tensor C}$, we must have that $s\vert_{A,C}\in P_{A\sequoid C}$.
\end{proof}
\begin{remark}
  This is the main place where we have used the assumption that $\sigma$ is a strict strategy: if we drop the strictness requirement from Definitionk \ref{DefSequoidOfStrategies}, then we get a valid (if nonsensical) strategy that has a partiality (`gives up') if playing according to $\sigma$ and $\tau$ would lead to it creating an invalid play.  
  But such a strategy would not satisfy the conclusion of Proposition \ref{PropWkCommutativeDiagram}, since $\sigma\tensor\tau;\wk_{B,D}$ would contain these extra plays where $\wk_{A,C};\sigma\sequoid\tau$ had `given up'.
\end{remark}
\begin{remark}
  Of course, we would \emph{like} to restate Proposition \ref{PropWkCommutativeDiagram} by saying that $\wk$ is some sort of natural transformation, but that doesn't make sense until we've shown that $\blank\sequoid\blank$ is a functor.
\end{remark}

\begin{proposition}
  If we have strict strategies $\sigma'\from A'' \implies A'$ and $\sigma\from A' \implies A$, and strategies $\tau' \from B'' \implies B'$ and $\tau \from B' \implies B$, then we have
  \[
    (\sigma'\sequoid\tau');(\sigma\sequoid\tau) = (\sigma';\sigma)\sequoid(\tau';\tau)\,.
    \]
  If $A',A,B',B$ are games, $i$ is a subset inclusion from $A$ into $A'$ and $j$ is a subset inclusion from $B$ into $B'$, then
  \[
    \subs_i\sequoid\subs_j = \subs_{[i,j]}\from A'\sequoid B' \implies A \sequoid B\,.
    \]
  In particular, if $A,B$ are games, then $\id_A\sequoid\id_B=\id_{A\sequoid B}$.
  \label{PropSequoidIsFunctor}
\end{proposition}
\begin{proof}
  Let $A'',A',A,B'',B',B$ and $\sigma',\sigma,\tau',\tau$ be as above.  

  We have
  \begin{IEEEeqnarray*}{rCl?u}
    \wk_{A'',B''};(\sigma'\sequoid\tau');(\sigma\sequoid\tau) & = & (\sigma'\tensor\tau');\wk_{A',B'};(\sigma\sequoid\tau) & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
    & = & (\sigma'\tensor\tau');(\sigma\tensor\tau);\wk_{A,B} & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
    & = & ((\sigma';\sigma)\tensor(\tau';\tau));\wk_{A,B} & \textit{Prop. \ref{PropTensorProductIsFunctor}} \\
    & = & \wk_{A'',B''};((\sigma';\sigma)\sequoid(\tau';\tau))\,. & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
  \end{IEEEeqnarray*}
  By Proposition \ref{PropSubsetInclusionEpic}, $\wk_{A'',B''}$ is an epimorphism, and therefore we have that
  \[
    (\sigma'\sequoid\tau');(\sigma\sequoid\tau) = (\sigma';\sigma)\sequoid(\tau';\tau)\,.
    \]

  Now let $A',A,B',B$ be games, let $i$ be a subset inclusion from $A$ into $A'$ and let $j$ be a subset inclusion from $B$ into $B'$.  
  Then, since subset inclusion strategies are automatically strict, we have
  \begin{IEEEeqnarray*}{rCl?u}
    \wk_{A',B'};(\subs_i\sequoid\subs_j) & = & (\subs_i\tensor\subs_j);\wk_{A,B} & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
    & = & \subs_{[i,j]};\wk_{A,B} & \textit{Prop. \ref{PropTensorProductIsFunctor}} \\
    & = & \subs_{[i,j]} & \textit{Prop. \ref{PropCopycat}} \\
    & = & \wk_{A',B'};\subs_{[i,j]}\,. & \textit{Prop. \ref{PropCopycat}} \\
  \end{IEEEeqnarray*}
  As before, we know from Proposition \ref{PropSubsetInclusionEpic} that $\wk_{A',B'}$ is an epimorphism, and so
  \[
    \subs_i\sequoid\subs_j = \subs_{[i,j]}\,.\qedhere
    \]
\end{proof}

Proposition \ref{PropSequoidIsFunctor} tells us that $\blank\sequoid\blank$ is a functor $\G_s\times\G\to \G$.  
As before, write $J$ for the inclusion functor $\G_s\hookrightarrow\G$.
Then we can restate Proposition \ref{PropWkCommutativeDiagram} in a more \emph{natural} way.

\begin{proposition}
  $\wk_{A,B}$ is a natural transformation $JA \tensor B \to J(A \sequoid B)$.
  \label{PropWkNatural}
\end{proposition}

We have some additional structure on the $\tensor$ and $\sequoid$ operators.  
By inspecting the definitions that if $A,X,Y$ are games then the associator $\assoc_{M_A,M_X,M_Y}$ and unitor $\runit_{M_A}$ in $(\Set,+)$ give rise to structural isomorphisms
\begin{mathpar}
  (A \sequoid X) \sequoid Y \cong A \sequoid (X \tensor Y)
  \and
  A \cong A \sequoid I\,.
\end{mathpar}
Indeed, in the first case, both games are the game in which $A$, $X$ and $Y$ are played in parallel, but where the first move must take place in $A$.  
In the second case, we have $A\sequoid I=A\tensor I$, because there are no moves in $I$ anyway, and the copycat morphism induced from the right unitor in $(\Set,+)$ is the same strategy as the right unitor $A \toisom A \tensor I$.

We formalize the structure we have uncovered so far in the concept of a \emph{sequoidal category}.

\begin{definition}
  A \emph{sequoidal category} $\C$ is given by
  \begin{itemize}
    \item a monoidal category $(\C,\tensor, I)$ (with coherences $\assoc,\lunit,\runit$);
    \item a (strong) right action of $\C$ on a category $\C_s$; i.e., a functor $\blank\sequoid\blank\from\C_s\times\C\to\C_s$ together with natural isomorphisms
      \begin{mathpar}
        \passoc_{a,x,y}\from (a \sequoid x) \sequoid y \toisom a \sequoid (x \tensor y)
        \and
        \run_a \from a \toisom a \sequoid I
      \end{mathpar}
      that make the diagrams
      \begin{mathpar}
        \begin{tikzcd}[column sep=36pt]
          ((a \sequoid x) \sequoid y) \sequoid z \arrow[r, "{\passoc_{a,x,y}\sequoid z}"] \arrow[d, "{\passoc_{a\sequoid x,y,z}}"' description]
            & (a \sequoid (x \tensor y)) \sequoid z \arrow[r, "{\passoc_{a,x\tensor y,z}}"]
              & a \sequoid ((x\tensor y) \tensor z)  \arrow[dl, "{a \sequoid \assoc_{x,y,z}}"] \\
          (a \sequoid x) \sequoid (y \tensor z) \arrow[r, "{\passoc_{a,x,(y\tensor z)}}"]
            & a \sequoid (x \tensor (y \tensor z))
              &
        \end{tikzcd}
        \and
        \begin{tikzcd}
          a \sequoid x \arrow[r, "{a \sequoid \lunit_x}"] \arrow[d, "\run_a \sequoid x"']
            & a \sequoid (I \tensor x) \\
          (a \sequoid I) \sequoid x \arrow[ur, "{\passoc_{a,I,x}}"']
            &
        \end{tikzcd}
        \and
        \begin{tikzcd}
          a \sequoid x \arrow[r, "{a \sequoid \runit_x}"] \arrow[d, "\run_{a \sequoid x}"']
            & a \sequoid (x \tensor I) \\
          (a \sequoid x) \sequoid I \arrow[ur, "{\passoc_{a,x,I}}"']
            &
        \end{tikzcd}
      \end{mathpar}
      commute; and
    \item a lax morphism of actions from $\blank\sequoid\blank$ to the right tensor multiplication action $\blank\tensor\blank$ of $\C$ on itself; i.e., a functor $J\from \C_s \to \C$ and a natural transformation $\wk_{a,x} \from Ja \tensor x \to J(a \sequoid x)$ that makes the following diagrams commute.
      \begin{mathpar}
        \begin{tikzcd}[column sep=30pt]
          (Ja \tensor x) \tensor y \arrow[r, "{\wk_{a,x}\tensor y}"] \arrow[d, "{\assoc_{Ja,x,y}}"'] & J(a \sequoid x) \tensor y \arrow[r, "{\wk_{a\sequoid x,y}}"]
              & J((a \sequoid x) \sequoid y) \arrow[dl, "{J\passoc_{a,x,y}}"] \\
          Ja \tensor (x \tensor y) \arrow[r, "{\wk_{a,x\tensor y}}"]
            & J(a \sequoid (x \tensor y))
              &
        \end{tikzcd}
        \and
        \begin{tikzcd}
          Ja \arrow[r, "J\run_a"] \arrow[d, "\runit_{Ja}"']
            & J(a \sequoid I) \\
          Ja \tensor I \arrow[ur, "{\wk_{a,I}}"']
            &
        \end{tikzcd}
      \end{mathpar}
  \end{itemize}
  \label{DefSequoidalCategory}
\end{definition}
\begin{remark}
  The definitions of \emph{lax action} can be found at the start of Section \ref{SecParametricMonads}, whie that of an \emph{oplax morphism of actions} is found at Definition \ref{DefOplaxMorphismOfActions}.  
  The definitions we have used are similar: a \emph{strong action} is a lax action in which the coherences (called $m$ and $e$ in Section \ref{SecParametricMonads} and $\passoc$ and $\run$ here) are isomorphims.  
  A \emph{lax morphism of actions} is defined in the same way as an oplax morphism, except that the coherence (called $\mu$ in Definition \ref{DefOplaxMorphismOfActions} and $\wk$ here) goes in the opposite direction.
\end{remark}

\begin{proposition}
  The monoidal category $\G$, together with the category $\G_s$, the natural transformations
  \begin{mathpar}
    \passoc_{A,X,Y} = \cc_{\assoc_{M_A,M_X,M_Y}} \from (A \sequoid X) \sequoid Y \toisom A \sequoid (X \tensor Y)
    \and
    \run_A = \cc_{\runit_{M_A}} \from A \toisom A \sequoid I\,,
  \end{mathpar}
  the inclusion functor $J\from \G_s \to G$ and the natural transformation
  \begin{mathpar}
    \wk_{A,X}=\subs_{j} \from JA \tensor X = A \tensor X \to A \sequoid X = J(A \sequoid X)
  \end{mathpar}
  form a sequoidal category.
\end{proposition}
\begin{proof}
  We have shown most of this already; all that remains is to show that $\passoc$ and $\run$ are natural transformations and that the five diagrams in Definition \ref{DefSequoidalCategory} commute.  

  Let us start with the diagrams.  
  By Proposition \ref{PropCopycat}, commutativity of these diagrams follows from commutativity of the diagrams formed from the corresponding subset inclusion functions in $\Set$.  
  For example, to show that the first diagram commutes in $\G$, we must show that the following diagram commutes in $\Set$.
  \scriptsize
  \[
    \begin{tikzcd}[column sep=19pt, row sep=30pt]
      ((M_A + M_X) + M_Y) + M_Z \arrow[r, "{[\assoc_{M_A,M_X,M_Y},\id_{M_Z}]}" yshift=3pt] \arrow[d, "{\assoc_{M_A+M_X,M_Y,Z}}" description]
        & (M_A + (M_X + M_Y)) + M_Z \arrow[r, "{\assoc_{M_A,M_X+M_Y,M_Z}}" yshift=3pt]
          & M_A + ((M_X + M_Y) + M_Z) \arrow[dl, "{[\id_{M_A},\assoc_{M_X,M_Y,M_Z}]}"] \\
      (M_A + M_X) + (M_Y + M_Z) \arrow[r, "{\assoc_{M_A,M_X,M_Y+M_Z}}" yshift=3pt]
        & M_A + (M_X + (M_Y + M_Z))
          &
    \end{tikzcd}
    \]
  \normalsize
  This diagram is, of course, none other than the pentagram diagram for the coproduct $+$ in $\Set$.  
  Similarly, the second and third diagrams in Definition \ref{DefSequoidalCategory} reduce in this case to the triangle diagrams for the coproduct $+$ in $\Set$.

  For the fourth diagram in Definition \ref{DefSequoidalCategory}, since $\wk$ is a subset inclusion strategy induced from an identity map, Proposition \ref{PropCopycat} tells us that both arms of the diagram are the strategy induced by the subset inclusion $\assoc_{M_A,M_X,M_Y}\from (M_A + M_X) + M_Y \to M_A + (M_X + M_Y)$ from $(A \tensor X) \tensor Y$ to $A \sequoid (X \tensor Y)$.
  Similarly, both arms of the last diagram in Definition \ref{DefSequoidalCategory} are the strategies induced by the subset inclusion $\runit_{M_A} \from M_A \to M_A + \emptyset$ from $A$ to $A \sequoid I$.

  It now remains only to show that $\passoc$ and $\run$ are natural transformations.  
  For $\passoc$, suppose that $A',X',Y',A,X,Y$ are games, that $\sigma\from A'\implies A$ is a strict strategy and that $\tau\from B'\implies B,\upsilon\from C'\implies C$ are strategies.  
  Then we need to show that the following diagram commutes.
  \[
    \begin{tikzcd}[column sep=50pt]
      (A' \sequoid X') \sequoid Y' \arrow[r, "{\passoc_{A',X',Y'}}"] \arrow[d, "(\sigma\sequoid\tau)\sequoid\upsilon"']
        & A' \sequoid (X' \tensor Y') \arrow[d, "\sigma\sequoid (\tau\tensor\upsilon)"] \\
      (A \sequoid X) \sequoid Y \arrow[r, "{\passoc_{A,X,Y}}"]
        & A \sequoid (X \tensor Y)
    \end{tikzcd}
    \]
  Indeed, we have
  \begin{IEEEeqnarray*}{rCl?u}
    && (\wk_{A',X'}\tensor Y');\wk_{A'\sequoid X',Y'};\passoc_{A',X',Y'};(\sigma\sequoid(\tau\tensor\upsilon)) \\
    & = & \assoc_{A',X',Y'};\wk_{A',X'\tensor Y'};(\sigma\sequoid(\tau\tensor\upsilon)) & (see above) \\
    & = & \assoc_{A',X',Y'};(\sigma\tensor(\tau\tensor\upsilon));\wk_{A,X\tensor Y} & \textit{Prop. \ref{PropWkNatural}} \\
    & = & ((\sigma\tensor\tau)\tensor\upsilon);\assoc_{A,X,Y};\wk_{A,X\tensor Y} & \textit{Prop. \ref{PropCoherencesAreNatural}} \\
    & = & ((\sigma\tensor\tau)\tensor\upsilon);(\wk_{A,X}\tensor Y);\wk_{A\sequoid X,Y};\passoc_{A,X,Y} & (see above) \\
    & = & (\wk_{A',X'}\tensor Y');((\sigma\sequoid\tau)\tensor\upsilon);\wk_{A\sequoid X,Y};\passoc_{A,X,Y} & \textit{Prop. \ref{PropWkNatural}} \\
    & = & (\wk_{A',X'}\tensor Y');\wk_{A'\sequoid X',Y'};((\sigma\sequoid\tau)\sequoid\upsilon);\passoc_{A,X,Y}\,. & \textit{Prop. \ref{PropWkNatural}}
  \end{IEEEeqnarray*}
  Now observe that $\wk_{A',X'}\tensor Y=\subs_{[\id_{M_{A'}+M_{X'}},\id_{M_{Y'}}]}$ by Proposition \ref{PropTensorProductIsFunctor}, so it is an epimorphism by Proposition \ref{PropSubsetInclusionEpic}.  
  Proposition \ref{PropSubsetInclusionEpic} also tells us that $\wk_{A'\sequoid X',Y'}$ is an epimorphism.  
  Therefore, we have
  \[
    \passoc_{A',X',Y'};(\sigma\sequoid(\tau\tensor\upsilon)) = ((\sigma\sequoid\tau)\sequoid\upsilon);\passoc_{A,X,Y}
    \]
  for any $A',X',Y',A,X,Y,\sigma,\tau,\upsilon$ as above.  
  It follows that $\passoc$ is a natural transformation.

  The proof that $\run$ is a natural transformation is similar.  
  Let $A',A$ be games and let $\sigma\from A'\implies A$ be a strict strategy.  
  We need to show that the following diagram commutes.
  \[
    \begin{tikzcd}
      A' \arrow[r, "\run_{A'}"] \arrow[d, "\sigma"']
        & A' \sequoid I \arrow[d, "\sigma\sequoid I"] \\
      A \arrow[r, "\run_A"]
        & A \sequoid I
    \end{tikzcd}
    \]
  Indeed, we have
  \begin{IEEEeqnarray*}{rCl?u}
    \run_{A'};(\sigma\sequoid I) & = & \runit_{A'};\wk_{A',I};(\sigma\tensor I) & (see above) \\
    & = & \runit_{A'};(\sigma\tensor I);\wk_{A,I} & \textit{Prop. \ref{PropWkNatural}} \\
    & = & \sigma;\runit_A;\wk_{A,I} & \textit{Prop. \ref{PropCoherencesAreNatural}} \\
    & = & \sigma;\run_A\,. & (see above)
  \end{IEEEeqnarray*}

  Therefore, $\run$ is a natural transformation, which completes our check of the criteria required by Definition \ref{DefSequoidalCategory}.
\end{proof}

\subsection{Sequoidally decomposable categories}

We will now consider some important additional category-theoretic properties of the sequoid operator on games that do not follow from the fact that $\G$ is a sequoidal category.

\begin{definition}[\cite{martinsthesis}]
  Let $\C$ be a sequoidal category such that $C_s$ has arbitrary products (including a terminal object $1$).
  We say that $\C$ is \emph{distributive} if whenever $a_i$ is a collection of objects of $\C'$ and $x$ is an object of $\C$, the morphism
  \[
    \dec_{(a_i),x} = \langle \pr_i\sequoid x \rangle \from \prod_ia_i \sequoid x \to \prod_i (a_i \sequoid x)
    \]
  is an isomorphism.
\end{definition}
\begin{remark}
  In particular, taking $(a_i)$ to be the empty collection, the morphism $\lun_x = () \from 1 \sequoid x \to 1$ is an isomorphism.
\end{remark}

\begin{proposition}
  $\G$ is a distributive sequoidal category.
\end{proposition}
\begin{proof}
  Let $(A_i),X$ be games.
  By Proposition \ref{PropProductOfTreeEmbeddings}, the morphism $\langle \pr_i\sequoid X\rangle$ is given by the tree embedding $\phi\from P_{\prod_iA_i\sequoid X}\to P_{\prod_i(A_i\sequoid X)}$ defined as follows.
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      [\inj_{A_j},\inj_{X^j}]_*(s) & \text{if $s$ begins with a move in $A_j$}
    \end{cases}
    \]
  When we say $[\inj_{A_j},\inj_{X^j}]_*(s)$, we have considered $s$ as a sequence in $(M_{A_j} + X)^*$.

  We claim that $\phi$ is a bijection.  
  Indeed, it is certainly injective.
  Then, if we have a non-empty sequence $s\in P_{\prod_i(A_i \sequoid X)}$, then $s$ must start with a move in some $A_j$, and must thereafter take place in the games $A_j$ and $X^j$.  
  Then $s=\phi([\inj_{A_j},\inj_X]_*(s))$, where we have considered $s$ as a sequence in $(M_{A_j} + M_{X^j})^*$.

  Therefore, $\phi$ is a tree isomorphism, so $\dec_{(A_i),X} = \tree_\phi$ is an isomorphism by Proposition \ref{PropTree}.
\end{proof}

We can get a distributivity result in the other direction, but this one is not as strong, since the morphism we get is only a monomorphism, not an isomorphism.
\begin{definition}
  Let $\C$ be a distributive sequoidal category.  
  We say that $\C$ is \emph{strongly distributive} if whenever $A,B,C$ are objects of $\C_s$, the morphism
  \[
    \langle A \sequoid J(\pr_1),A \sequoid J(\pr_2)\rangle \from A \sequoid J(B \times C) \to (A \sequoid JB) \times (A \sequoid JC)
    \]
  is a monomorphism.
\end{definition}

\begin{proposition}
  $\G$ is a strongly distributive sequoidal category.
\end{proposition}
\begin{proof}
  Let $\sigma,\tau\from D\implies (A \sequoid (B \times C))$ be strategies and suppose that 
  \[
    \sigma;\langle A\sequoid\pr_1,A\sequoid\pr_2\rangle=\tau;\langle A\sequoid \pr_1,A\sequoid \pr_2\rangle\,.
    \]
  Let $s\in\sigma$.
  Without loss of generality, suppose that $s\vert_{B\times C}\in P_B$.  
  Then we have
  \[
    [\id_{M_D},\inj_{M_{A^L}},\inj_{M_B},\bot]_*(s)\in\sigma;\langle A\sequoid\pr_1,A\sequoid\pr_2\rangle=\tau;\langle A\sequoid \pr_1,A\sequoid \pr_2\rangle\,.
    \]
  It follows that $s\in\tau$.  
  Since $s$ was arbitrary, we get $\sigma\subset\tau$.  
  By an identical argument, we get that $\tau\subset\sigma$, and therefore that $\sigma=\tau$.
\end{proof}

\begin{definition}
  A sequoidal category $\C$ is \emph{inclusive} if $\C_s$ is a full-on-objects subcategory of $\C$ containing $\wk$ and all isomorphisms of $\G$, and the functor $J$ is the inclusion functor.
\end{definition}
In such a situation, we will sometimes drop the mention of the functor $J$.

\begin{proposition}
  $\G$ is an inclusive sequoidal category.
\end{proposition}
\begin{proof}
  The only thing we really need to check is that isomorphisms in $\G$ are always strict strategies.  
  Indeed, if $\sigma$ is a strategy for $A \implies B$ and $\tau$ a strategy for $B \implies A$ such that $\sigma;\tau=\id_A$, then for any opening move $a$ in $A$ on the right of $\tau$ there is some $\s\in\int(A,B,A)$ such that $\s\vert_{A,A}=aa$, and therefore the reply to $a$ in $\tau$ must take place in $B$.
\end{proof}

An important fact about the sequoid operator for games is that it gives us a way to decompose the tensor product as
\[
  A \tensor B \cong (A \sequoid B) \times (B \sequoid A)\,.
  \]
Informally, this is because both sides allow player $O$ to start either in $A$ or in $B$, and thereafter to continue in that game.

\begin{definition}
  Let $\C$ be a distributive inclusive sequoidal category, where $\C$ is a symmetric monoidal category.
  We say that $\C$ is \emph{decomposable} if the morphisms
  \begin{mathpar}
    \dec_{a,b}=\langle \wk_{a,Jb},\sym_{Ja,Jb};\wk_{b,Ja} \rangle \from Ja \tensor Jb \to (a \sequoid Jb) \times (b \sequoid Ja)
    \and
    () \from I \to 1
  \end{mathpar}
  are isomorphisms in $\C_s$.
\end{definition}

\begin{proposition}
  Let $\C$ be a decomposable sequoidal category and suppose that $a_1,\cdots,a_n$ is a list of objects of $\C_s$.  
  Then we have an isomorphism
  \[
    a_1 \tensor \cdots \tensor a_n \cong \prod_{i=1}^n (a_i \sequoid (a_1 \tensor \cdots \tensor a_{i-1} \tensor a_{i+1} \tensor \cdots \tensor a_n))\,.
    \]
  \label{PropDecSeq}
\end{proposition}
\begin{proof}
  Induction on $n$.  
  If $n=0$, then we have the isomorphism $() \from I \to 1$.  
  More generally, we have
  \begin{IEEEeqnarray*}{Cl}
    & a_1 \tensor \cdots \tensor a_{n+1}\\
    \cong & (a_1 \tensor \cdots \tensor a_n) \tensor a_{n+1} \\
    \xrightarrow{\dec} & (a_1 \tensor \cdots \tensor a_n) \sequoid a_{n+1} \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \cong & \left(\prod_{i=1}^n\left(a_i \sequoid \Tensor_{j\ne i}^{j\le n} a_j\right)\right) \sequoid a_{n+1} \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \xrightarrow{\dist\times\id} & \prod_{i=1}^n\left(\left(a_i \sequoid \Tensor_{j\ne i}^{j\le n} a_j \right) \sequoid a_{n+1}\right) \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \xrightarrow{\langle\passoc\rangle\times\id} & \prod_{i=1}^n \left(a_i \sequoid \left(\Tensor_{j\ne i}^{j\le n} a_j \tensor a_{n+1}\right)\right) \times a_{n+1} \sequoid (a_1\tensor \cdots \tensor a_n) \\
    \cong & \prod_{i=1}^{n+1} \left(a_i \times \Tensor_{j\ne i}^{j\le n+1} a_j\right) \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \cong & \prod_{i=1}^{n+1} (a_i \sequoid (a_1 \tensor \cdots \tensor a_{i-1} \tensor a_{i+1} \tensor \cdots \tensor a_{n+1}))\,,
  \end{IEEEeqnarray*}
  where each of the arrows is an isomorphism.
\end{proof}

The specific isomorphism in Proposition \ref{PropDecSeq} is rather complicated at the moment, but we can simplify it.

\begin{definition}
  Given objects $a_1,\cdots,a_n$ of a monoidal category, we write $\sym_i^n$ for the unique symmetric coherence isomorphism
  \[
    a_1 \tensor \cdots \tensor a_n \cong a_i \tensor a_1 \cdots \tensor a_{i-1} \tensor a_{i+1} \tensor a_n\,.
    \]
\end{definition}

\begin{proposition}
  The isomorphism in the proof of Proposition \ref{PropDecSeq} is given by
  \[
    \dec_{(a_i)}^n = \langle \sym_i^{n};\wk_{a_i,a_1\tensor\cdots\tensor a_{i-1}\tensor a_{i+1}\tensor \cdots\tensor a_n}\rangle\,.
    \]
  \label{PropDecSeqFormula}
\end{proposition}
\begin{proof}
  Induction on $n$.
  We will make use of the coherence theorem for symmetric monoidal categories \cite[\sec 11]{WorkingMathematician} to allow us to elide associators.  
  The base case is obviously true, because $()\from I \to 1$ is the unique morphism between these objects.  
  Otherwise, we observe that the morphism into $\prod_{i=1}^{n+1} \left(a_i \sequoid \Tensor_{j\ne i}^{j\le n+1} a_j\right)$ is given component-wise by morphisms $a_1 \tensor \cdots \tensor a_{n+1} \to a_i \sequoid \Tensor_{j\ne i}^{j\le n+1}$ for each $i=1,\cdots,n+1$; we need to check that each of these components is equal to $\sym_i^{n+1};\wk_{a_i,\Tensor_{j\ne i}a_j}$.

  If $i\le n$, then the $i$-th component of the morphism in the proof of Proposition \ref{PropDecSeq} is given by the composite thick dashed arrows in Figure \ref{FigDecSeqFormula}, and is therefore equal to the composite of the solid arrows, which is $\sym_i^{n+1};\wk_{a_i,\Tensor_{j\ne i}a_j}$ as desired.  
  The $n+1$-th component of the morphism in the proof of Proposition \ref{PropDecSeq} is given by the composite
  \small
  \[
    \Tensor_{j=1}^{n+1}a_j \to \Tensor_{j=1}^n a_j \tensor a_{n+1} \xrightarrow{\sym_{\Tensor_{j=1}^na_j,a_{n+1}}} a_{n+1} \tensor \Tensor_{j=1}^n a_j \xrightarrow{\wk_{a_{n+1},\Tensor_{j=1}^n a_j}} a_{n+1} \sequoid \Tensor_{j=1}^n a_j\,,
    \]
  \normalsize
  and then we use the fact that the leftmost two morphisms in this composite compose to give us $\sym_{n+1}^{n+1}$.
  \begin{SidewaysFigure}
    \[
      \begin{tikzcd}[ampersand replacement=\&, column sep=10pt, row sep=30pt]
        \Tensor_{j=1}^{n+1}a_j \arrow[r, thick, dashed] \arrow[dd, "\sym_i^{n+1}"']
          \& \Tensor_{j=1}^n a_j \tensor a_{n+1} \arrow[r, "{\wk_{\Tensor_{j=1}^na_j,a_{n+1}}}", thick, dashed] \arrow[d, "\sym_i^n\tensor a_{n+1}" description, dotted]
            \&[45pt] \Tensor_{j=1}^n a_j \sequoid a_{n+1} \arrow[d, "\sym_i^n\sequoid a_{n+1}", thick, dashed]
              \&[34pt] \\
        %
          \& \left(a_i \tensor \Tensor_{j\ne i}^{j\le n} a_j\right)\tensor a_{n+1} \arrow[r, "{\wk_{a_i\tensor\Tensor_{j\ne i}^{j\le n} a_j,a_{n+1}}}" xshift=-10pt, dotted] \arrow[d, "{\assoc_{a_i,\Tensor_{j\ne i}^{j\le n}a_j,a_{n+1}}}" description, dotted] \arrow[dr, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n}a_j}\tensor a_{n+1}}" description, dotted]
            \& |[alias=Z]| \left(a_i \tensor \Tensor_{j\ne i}^{j\le n} a_j\right)\sequoid a_{n+1} \arrow[dr, from=Z.east, bend left=25, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n}a_j}\sequoid a_{n+1}}", thick, dashed]
              \& \\
        a_i \tensor \Tensor_{j\ne i}^{j\le n+1} a_j \arrow[ddrrr, bend right=15, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n+1}a_j}}"']
          \& a_i \tensor \left(\tensor_{j\ne i}^{j\le n}a_j \tensor a_{n+1}\right) \arrow[l, dotted] \arrow[drr, to=Y.west, bend right=10, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n}a_j\tensor a_{n+1}}}" description, dotted]
            \& \left(a_i \sequoid \Tensor_{j\ne i}^{j\le n}\right)\tensor a_{n+1} \arrow[r, "{\wk_{a_i\sequoid \Tensor_{j\ne i}^{j\le n},a_{n+1}}}" xshift=-10pt, dotted]
              \& \left(a_i \sequoid \Tensor_{j\ne i}^{j\le n} a_j\right) \sequoid a_{n+1} \arrow[d, "{\passoc_{a_i,\Tensor_{j\ne i}^{j\le n}a_j,a_{n+1}}}", thick, dashed] \\
        %
          \&
            \&
              \& |[alias=Y]| a_i \sequoid \left(\Tensor_{j\ne i}^{j\le n} a_j \tensor a_{n+1}\right) \arrow[d, thick, dashed] \\
        %
          \&
            \&
              \& a_i \sequoid \Tensor_{j\ne i}^{j\le n+1}a_j
      \end{tikzcd}
      \]
    \caption[Diagram used in the proof of Proposition \ref{PropDecSeqFormula}]{Diagram used in the proof of Proposition \ref{PropDecSeqFormula}.  
    The pentagon at the heart of the diagram is the coherence diagram for $\passoc$ and $\wk$ from Definition \ref{DefSequoidalCategory}.}
    \label{FigDecSeqFormula}
  \end{SidewaysFigure}
\end{proof}

\begin{proposition}
  $\G$ is a decomposable sequoidal category.
\end{proposition}
\begin{proof}
  Let $A,B$ be games.  
  By Proposition \ref{PropProductOfTreeEmbeddings}, the strategy 
  \[
    \langle \wk_{A,B},\sym_{A,B};\wk_{A,B}\rangle
    \]
  is given by the tree embedding $\phi$ from $(A \sequoid B) \times (B \sequoid A)$ to $A \tensor B)$ given by
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      s\vert_{A \sequoid B} & \text{if $s$ takes place entirely within $A\sequoid B$} \\
      s\vert_{B \sequoid A} & \text{if $s$ takes place entirely within $B\sequoid A$}
    \end{cases}\,.
    \]
  We claim that this tree embedding is a bijection.  
  Indeed, it is certainly injective.
  Now let $s\in P_{A\tensor B}$ be a non-empty play.  
  Then, if $s$ begins with a move in $A$, we have $s=\phi((\inj_{A\sequoid B})_*(s))$, and if $s$ begins with a move in $B$, we have $s=\phi((\inj_{B\sequoid A})_*(s)$.  
  Therefore, $\phi$ is a tree isomorphism, so $\dec_{A,B}=\tree_\phi$ is an isomorphism in $\G$.

  Lastly, we have $I=1$ in $\G$, and the unique morphism $I\to 1$ is the identity.
\end{proof}

\subsection{A Formula for the Exponential}

\begin{definition}
  Let $\C$ be a symmetric monoidal category.  
  Given objects $A_1,\cdots,A_n$ of $\C$ and a permutation $\pi\in \S_n$, there is a unique canonical symmetry isomorphism
  \[
    \sym^\pi \from A_1 \tensor \cdots \tensor A_n \toisom A_{\pi(1)} \tensor \cdots \tensor A_{\pi(n)}\,.
    \]
  Given an object $A$ of $\C$, an \emph{$n$-th symmetrized tensor power} of $A$ is an equalizer $(A^n,\eq^n)$ for the diagram given by all morphisms of the form
  \[
    \sym_\pi \from A ^{\tensor n} \to A ^{\tensor n}\,.
    \]
  We say that the symmetrized tensor power $A^n$ \emph{commutes with the tensor product} if $(B\tensor A^n,B\tensor \eq_n)$ is an equalizer for the diagram given by morphisms of the form
  \[
    B\tensor\sym_\pi \from B\tensor A ^{\tensor n} \to B\tensor A ^{\tensor n}\,.
    \]
\end{definition}

\begin{proposition}[\cite{CalcoPaper}]
  Let $\C$ be an inclusive, strongly distributive, decomposable sequoidal category.  
  Then $\C$ has all symmetrized tensor powers.
\end{proposition}
\begin{proof}
  Let $A$ be an object of $\C$ (equivalently, an object of $\C_s$).  
  We inductively define objects $A^{\sequoid n}$ by
  \begin{itemize}
    \item $A^{\sequoid 0} = I$; and
    \item $A^{\sequoid (n+1)}=J(A\sequoid A^{\sequoid n})$.
  \end{itemize}
  We claim that $A^{\sequoid n}$ is a symmetrized tensor power of $A$.

  Given $n$, we inductively define a morphism $\wk^n\from A^{\tensor n} \to A^{\sequoid n}$, where $\wk^0=\id_I$, and $\wk^{n+1}$ is given by the composite
  \[
    A^{\tensor (n+1)} \to A \tensor A^{\tensor n} \xrightarrow{A \tensor \wk^n} A \tensor A^{\sequoid n} \xrightarrow{\wk_{A,A^{\sequoid n}}} A \sequoid A^{\sequoid n}\,.
    \]
  We show by induction on $n$ that if $B$ is an object of $\C$ and $k\ge 0$ then the composite
  \scriptsize
  \begin{mathpar}
    B\tensor (A \sequoid\blank)^kA^{\tensor n}
    \xrightarrow{\langle B\tensor(A \sequoid\blank)^k \sym^\pi \rangle}
    (B\tensor(A \sequoid\blank)^kA^{\tensor n})^{n!}
    \xrightarrow{(B\tensor(A\sequoid\blank)^k\wk^n)^{n!}}
    (B\tensor A^{\sequoid (k+n)})^{n!}
  \end{mathpar}
  \normalsize
  (i.e., the morphism $\langle B\tensor(A\sequoid\blank)^k(\sym^\pi;\wk^n)\rangle$) is a monomorphism.
  In particular, taking $k=0$, we will have shown that $\langle B\tensor (\sym^\pi;\wk^n)\rangle$ is a monomorphism.

  The hypothesis is clearly true for $n=0$; otherwise, we have a composite
  \begin{mathpar}
    B\tensor (A\sequoid\blank)^kA^{\tensor (n+1)}
    \xrightarrow{B\tensor (A\sequoid\blank)^k\langle \sym^{n+1}_i;\wk_{A,A^{\tensor n}}\rangle}
    B\tensor (A \sequoid\blank)^k(A\sequoid A^{\tensor n})^{n+1}
    \xrightarrow{\langle B\tensor (A\sequoid\blank)^k;\pr_i\rangle}
    (B\tensor(A \sequoid\blank)^{k+1} A^{\tensor n})^{n+1}
    \to
    (B\tensor A ^{\sequoid (k + n + 1)})^{(n+1)!}\,,
  \end{mathpar}
  where the last arrow is the tensor product of $B$ with the $(n+1)$-th power of the composite given by
  \footnotesize
  \[
    (A \sequoid\blank)^{k+1}A^{\tensor n}
    \xrightarrow{\langle (A \sequoid \blank)^{k+1}\sym^\sigma\rangle}
    ((A \sequoid\blank)^{k+1}A^{\tensor n})^{n!}
    \xrightarrow{((A \sequoid\blank)^{k+1}\wk^n)^{n!}}
    (A^{\sequoid (k+n+1)})^{n!}\,,
    \]
  \normalsize
  which is a monomorphism by the induction hypothesis.
  Then the previous composite is the composite of monomorphisms (by our assumptions on $\C$), and is therefore itself a monomorphism.  
  Now this composite may be written as
  \[
    \langle B\tensor(A\sequoid\blank)^k(\sym_i^{n+1};\wk_{A,A^{\tensor n}};(A\sequoid\sym^\sigma);(A\sequoid\wk^n)) \rangle\,,
    \]
  which, since $\wk$ is a natural transformation, is equal to
  \[
    \langle B\tensor(A \sequoid\blank)^k(\sym_i^{n+1};(A\tensor\sym^\sigma);(A\tensor\wk^n);\wk_{A,A^{\sequoid n}})\rangle\,,
    \]
  where $\sigma$ ranges over the permutations in $\S_n$.
  Moreover, by the definition of $\wk^n$, this is equal to
  \[
    \langle B\tensor(A \sequoid\blank)^k(\sym_i^{n+1};(A \tensor \sym^\sigma);\wk^{n+1}\rangle\,.
    \]

  Now, given $i\in\{1,\cdots n+1\}$ and $\sigma\in\S_n$, there is a unique permutation $\pi\in\S_{n+1}$ such that $\sym_i^{n+1};(A\tensor\sym^\sigma=\sym^\pi)$; moreover, this defines a bijection from $\{1,\cdots,n+1\}\times\S_n \to \S_{n+1}$.  
  Therefore (after choosing an appropriate enumeration of our permutations), we see that this composite is in fact equal to
  \[
    \langle B\tensor(A \sequoid\blank)^k (\sym^\pi;\wk^{n+1})\rangle\,.
    \]
  Therefore, $\langle B\tensor(A \sequoid\blank)^k(\sym^\pi;\wk^{n+1})\rangle$ is a monomorphism as desired, completing the induction.

  Next, we define morphisms $\eq_n\from A^{\sequoid n} \to A^{\tensor n}$ inductively, where $\eq_0=\id$ and $\eq_{n+1}$ is defined by the following composite
  \[
    A^{\sequoid (n+1)} = A\sequoid A^{\sequoid n} \xrightarrow{\langle (A\sequoid \eq_n)_1^n\rangle} (A \sequoid A^{\tensor n})^n \cong A^{\tensor (n+1)}\,,
    \]
  where the final isomorphism is as in Propositions \ref{PropDecSeq} and \ref{PropDecSeqFormula}.

  First, we show inductively that $\eq_n;\sym^\pi;\wk^n=\id_{A^{\sequoid n}}$ for all permutations $\pi$ of $S_n$.
  This is certainly true for $n=0$; otherwise, let $\pi\in \S_{n+1}$ be a permutation.  
  Let $j=\pi\inv(1)$ be the element sent to $1$ by $\pi$ and let $\sigma$ be the permutation of $1,\cdots,n$ such that applying $\sigma$ to the elements $2,\cdots,n+1$ and composing with $\pi$ gives us the $j$-cycle $(1\,\dots\,j)$.  
  Then we have
  \[
    \sym_j^{n+1};(A\tensor\sym^\sigma) = \sym^\pi\,.
    \]
  Now we get
  \begin{IEEEeqnarray*}{Cl}
    & \eq_{n+1};\sym^\pi;\wk^{n+1} \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\sym^\pi;(A \tensor \wk^n);\wk_{A,A^{\sequoid n}} \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\sym_j^{n+1};(A\tensor\sym^\sigma);(A \tensor \wk^n);\wk_{A,A^{\sequoid n}} \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\sym_j^{n+1};\wk_{A,A^{\tensor n}};(A \sequoid \sym^\sigma);(A \sequoid \wk^n) \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\langle \sym_i^{n+1};\wk_{A,A^{\tensor n}}\rangle;\pr_j;(A \sequoid \sym^\sigma);(A \sequoid \wk^n) \\
    = & A \sequoid (\eq_n;\sym^\sigma;\wk^n)\,,
  \end{IEEEeqnarray*}
  which is equal to the identity on $A^{\sequoid (n+1)}$ by the induction hypothesis.

  Now let $\rho$ be a permutation in $\S_n$.  
  We claim that $\eq_n=\eq_n;\sym^{\rho}$.  

  Indeed, we have
  \begin{IEEEeqnarray*}{rCl}
    \eq_n;\langle \sym^{\pi} ; \wk^n \rangle
    & = & \langle \eq_n;\sym^{\pi};\wk^n \rangle \\
    & = & \langle \id \rangle \\
    & = & \langle \eq_n;\sym^{\rho\pi};\wk^n \rangle \\
    & = & \eq_n;\sym^{\rho};\langle \sym^\pi ; \wk^n \rangle\,.
  \end{IEEEeqnarray*}
  Since $\langle \sym^\pi;\wk^n\rangle$ is a monomorphism, this means that $\eq_n=\eq_n;\sym^{\rho}$, as desired.
  Therefore, $\eq_n$ equalizes the morphisms $\eq_n$.  
  We claim that it is an equalizer, and that this equalizer is preserved by the tensor product.

  Indeed, let $B,C$ be objects of $\C$, and let $f \from C \to B \tensor A^{\tensor n}$ be a morphism such that $f=f;(B\tensor\sym^{\pi})$ for all $\pi\in\S_n$.

  Let $\tilde f = f;(B \tensor \wk^n)\from C \to B \tensor A^{\sequoid n}$.  
  We claim that $\tilde f;(B\tensor\eq_n)=f$; indeed, we have
  \begin{IEEEeqnarray*}{rCl}
    \tilde f;(B \tensor\eq_n);\langle B\tensor(\sym^\pi;\wk^n)\rangle 
    & = & \langle f;(B \tensor (\wk^n;\eq_n;\sym^\pi;\wk^n)) \rangle \\
    & = & \langle f;(B\tensor \wk^n)\rangle \\
    & = & f;\langle B \tensor (\sym^\pi;\wk^n)\rangle\,.
  \end{IEEEeqnarray*}
  Therefore, since $\langle B \tensor (\sym^\pi;\wk^n)\rangle$ is a monomorphism, we know that $\tilde f;(B\tensor \eq_n)=f$.

  Now suppose that $h\from C \to B \tensor A^{\sequoid n}$ is such that $h;(B\tensor eq_n)=f$.  
  We claim that $h=\tilde f$.  
  Indeed, we have 
  \[
    \tilde f = f;(B \tensor \wk^n) = h;(B \tensor \eq_n);(B \tensor \wk^n) = h\,.
    \]
  Therefore, $(B\tensor A^{\sequoid n},B\tensor \eq_n)$ is an equalizer of the arrows $B\tensor \sym^\pi\from B \tensor A^{\tensor n} \to B \tensor A^{\tensor n}$, as desired.
\end{proof}

We are interested in symmetrized tensor powers because of an important result of \Mellies, Tabareau and Tasson.
Suppose $\C$ is a monoidal category, and that $\C$ has symmetrized tensor powers that commute with the tensor product.  
Given $n$, we have a morphism
\[
  ()\tensor A^{\tensor n} \from A^{\tensor (n+1)} \to A^{\tensor n}\,;
  \]
then, if $A^n$ and $A^{n+1}$ are the $n$-th and $n+1$-th symmetrized tensor powers of $A$, and $\eq_{n+1},\eq$ the corresponding equalization, for any $\pi\in\S_n$ we have a commutative diagram
\[
  \begin{tikzcd}[column sep=50pt]
    B \tensor A^{n+1} \arrow[r, "B\tensor\eq_{n+1}"]
      & B \tensor A^{\tensor (n+1)} \arrow[r, "B\tensor()\tensor A^{\tensor n}"] \arrow[d, "\sym^{\pi'}"']
        & B \tensor A^{\tensor n} \arrow[d, "\sym^\pi"] \\
    %
      & B \tensor A^{\tensor (n+1)} \arrow[r, "B \tensor()\tensor A^{\tensor n}"]
        & B \tensor A^{\tensor n}
  \end{tikzcd}\,,
  \]
where $\pi'$ is the permutation of $1,\cdots,n+1$ that fixes $1$ and applies $\pi$ to the remaining elements $2,\cdots,n+1$.

This means that for each $\pi\in \S_n$ we have
\begin{IEEEeqnarray*}{rCl}
  (B\tensor\eq_{n+1});(B\tensor ()\tensor A^{\tensor n})
  & = & (B \tensor\eq_{n+1});(B\tensor \sym^{\pi'});(B\tensor ()\tensor A^{\tensor n}) \\
  & = & (B\tensor\eq_{n+1});(B\tensor()\tensor A^{\tensor n});(B\tensor \sym^\pi)\,,
\end{IEEEeqnarray*}
and that there is therefore an induced morphism
\[
  B\tensor A^{n+1} \to B \tensor A^n\,,
  \]
by the universal property of the equalizer.

\begin{theorem}[\cite{MelliesCofCommCom}]
  Let $\C$ be a monoidal category in which the monoidal unit is a terminal object.
  Suppose that $\C$ has symmetrized tensor powers that commute with the tensor product.  

  Then, for any objects $A,B$ of $\C$, there is a natural sequence
  \[
    B \leftarrow B\tensor A \leftarrow B\tensor A^2 \leftarrow B \tensor A^3 \leftarrow \cdots\,.
    \]
  In particular, there is a sequence
  \[
    I \leftarrow A \leftarrow A^2 \leftarrow A^3 \leftarrow \cdots\,.
    \]
  Suppose that this sequence has a limit $\oc A$, and that $B\tensor \oc A$ is the limit of the first sequence for all $B$.  
  Then $\oc A$ has the structure of the cofree commutative comonoid on $A$.
\end{theorem}

\bibliographystyle{alpha2}
\bibliography{../common/phd_bibliography}

\end{document}
