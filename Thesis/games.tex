\documentclass[11pt]{report}

\def\FEWFONTS{1}
\def\THESIS{1}
\input{../common/preamble}
\usepackage{lua-visual-debug}

\begin{document}

\chapter{A Fully Abstract Game Semantics for Idealized Algol}

To introduce our material, we will go back over some old ground, namely the fully abstract game semantics for Idealized Algol developed by Abramsky and McCusker in \cite{SamsonGuyIAActive}.  
In keeping with the spirit of this thesis, we will aim to use category theoretic methods, and so our proofs of soundness and adequacy will depart from those given by Abramsky and McCusker, and will instead involve coalgebraic ideas developed by Laird in \cite{laird02} and \cite{LairdCofCommCom}.

\section{Idealized Algol}

The ground types of Idealized Algol are called $\com$, $\bool$, $\nat$ and $\Var$.  
The first three are data types corresponding to the sets $\bC = \{a\}$, $\bB = \{\true,\false\}$ and $\bN = \{0,1,2,\cdots\}$.
$\com$ takes the role of a command or void type; typically, although the return value of a function $T \to \com$ will not convey any information, the function will have side effects that \emph{do} make a difference.

The type $\Var$ is the type of a variable that holds elements of $\bN$.
It is best understood as corresponding to the following pseudo-Java `interface'.

\begin{minipage}{\linewidth}
\begin{lstlisting}[language=Java, morekeywords={nat,com}]
public interface Var
{
  nat read();
  com write(nat value);
}
\end{lstlisting}
\end{minipage}

We now present the typing rules for the language.  
Here, $\Gamma$ will represent a \emph{context}; i.e., a list $x_1\from T_1,\cdots,x_n\from T_n$ of variable names together with their types.

First, we have the usual rules for the simply typed lambda calculus.

\begin{mathpar}
  \inferrule*{ }{\Gamma,x\from T \ts x \from T}
  \and
  \inferrule*{\Gamma\ts M \from S \to T \\ \Gamma \ts N \from S}{\Gamma\ts MN \from T}
  \and
  \inferrule*{\Gamma,x\from S \ts M \from T}{\Gamma \ts \lambda x^S.M \from S \to T}
\end{mathpar}

We then have rules for each of the base types.  
At type $\com$ we have:
\begin{mathpar}
  \inferrule*{ }{\Gamma\ts\skipp\from\com}
  \and
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma\ts M\from\com \\ \Gamma\ts N \from T}{\Gamma\ts M;N\from T}\,.
\end{mathpar}
Here, $\skipp$ is a generic command with no side-effects that returns the unique element of the singleton set $\bC$.  
$M;N$ represents the sequential composition of $M$ with $N$; i.e., the term that first evaluates $M$, performing any of its side-effects, and then evaluates $N$ and returns the result.

At type $\bool$ we have true/false values and conditionals.
\begin{mathpar}
  \inferrule*{ }{\Gamma\ts\true\from\bool}
  \and
  \inferrule*{ }{\Gamma\ts\false\from\bool}
  \\
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma\ts M \from \bool \\ \Gamma \ts N \from T \\ \Gamma \ts P \from T}{\Gamma\ts \If M \Then N \Else P \from T}
\end{mathpar}

At type $\nat$ we have numerals, arithmetic operators and a conditional that tests whether a number is equal to $0$ or not.
\begin{mathpar}
  \inferrule*{ }{\Gamma\ts n\from\nat}
  \and
  \inferrule*{\Gamma\ts M \from \nat}{\Gamma\ts \suc M \from \nat}
  \and
  \inferrule*{\Gamma\ts M \from \nat}{\Gamma\ts \pred M\from \nat}
  \\
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma\ts M \from \nat \\ \Gamma\ts N \from T \\ \Gamma \ts P \from T}{\Gamma \ts \IfO M \Then N \Else P \from T}
\end{mathpar}

At type $\Var$, we have terms that call the read and write `methods' to dereference the variable or to assign a new value to it.
\begin{mathpar}
  \inferrule*{\Gamma\ts V \from \Var}{\Gamma \ts \oc V \from \nat}
  \and
  \inferrule*{\Gamma\ts V \from \Var \\ \Gamma \ts E \from \nat}{\Gamma \ts V\gets E \from \com}
\end{mathpar}

We also have the ability to create a new variable.
\begin{mathpar}
  \inferrule*[right={$T\in\{\com,\bool,\nat\}$}]{\Gamma,x\from \Var \ts M \from T}{\Gamma\ts \neww_T \lambda x.M\from T}
\end{mathpar}
The idea here is that if $M$ is a term that refers to some free variable $x$ of type $\Var$; then $\neww \lambda x.M$ makes $x$ behave like an actual storage cell (so, for instance, the result of the computation $\neww_\nat \lambda x.(x\gets 5);!x$ will be $5$).

We have another way of creating variables, using the $\mkvar$ keyword.  
If we think back to our illustration of the $\Var$ type as an interface, this becomes clearer.  
$\mkvar$ creates a new anonymous instance of the $\Var$ interface, using the `methods' supplied through its arguments.
\begin{mathpar}
  \inferrule*{\Gamma \ts M \from \nat \\ \Gamma \ts N \from \nat \to \com}{\Gamma\ts \mkvar M N \from \Var}
\end{mathpar}

Lastly, we have fixpoint combinators at all types that we use to implement recursion.
\begin{mathpar}
  \inferrule*{\Gamma \ts M \from T \to T}{\Gamma \ts \Y_T M \from T}
\end{mathpar}

\section{Games and Strategies}

We adopt the game semantics from \cite{SamsonGuyIAActive}; these are based on the game semantics developed in \cite{hoPcf}, with a modification to make them into a linear category.

\begin{definition}
  An \emph{arena} is a tuple $A=(M_A,\lambda_A,\ts_A)$, where
  \begin{itemize}
    \item $M_A$ is a set of \emph{moves},
    \item $\lambda_A \from M_A \to \OP \times \QA$ is a function that identifies each move as either an \emph{$O$-move} or a \emph{$P$-move}, and as either a \emph{question} or an \emph{answer}, and
    \item $\ts_A$ is a relation between $M_A+\{*\}$ and $M_A$ such that
      \begin{itemize}
        \item if $*\ts_A a$, then $\lambda_A(a)=(O,Q)$, and if $b\ts_A a$ then $b=*$,
        \item if $a\ts_A b$ and $a$ is an answer, then $b$ is a question, and
        \item if $a \ts_A b$ and $a\ne *$, then either $a$ is an $O$-move and $b$ a $P$-move, or the other way round.
      \end{itemize}
  \end{itemize}
  If $*\ts_A a$, then we say that $a$ is an \emph{initial move} in $A$.  
  If $a \ts_A b$, the we say that $a$ \emph{enables} $b$.
\end{definition}

As a shorthand, we write $\lambda_A^{OP}\from M_A \to \OP$ for $\pr_1\circ\lambda_A$ and $\lambda_A^{QA}\from M_A \to \QA$ for $\pr_2\circ\lambda_A$.

\begin{definition}
  A \emph{justified sequence} in an arena $A$ is a finite sequence $s$ of moves together with, for each non-initial move $a$ occurring in $s$, a pointer back to some move $b$ occurring earlier in $s$ such that $b\ts_A a$.
  We say that \emph{$b$ justifies $a$} or that $b$ is the \emph{justifier} of $a$.

  Given such a justified sequence, we define the \emph{$P$-view} $\pv s$ and \emph{$O$-view} $\ov s$ of $s$ inductively as follows.
  \begin{IEEEeqnarray*}{RCL"s}
    \pv{\epsilon} & = & \epsilon & \\
    \pv{sa} & = & \pv{s}a & if $a$ is a $P$-move \\
    \pv{sa} & = & a & if $a$ is initial \\
    \pv{sbta} & = & \pv{s}ba & if $a$ is an $O$-move justified by $b$ \\
    & & & \\
    \ov{\epsilon} & = & \epsilon & \\
    \ov{sa} & = & \ov{s}a & if $a$ is an $O$-move \\
    \ov{sbta} & = & \ov{s}ba & if $a$ is a $P$-move justified by $b$
  \end{IEEEeqnarray*}
  
  A justified sequence $s$ is \emph{well-bracketed} if whenever a question $q$ justifies some answer $a$, then any question $q'$ occurring after $q$ and before $a$ must justify some answer $a'$ occurring between $q'$ and $a$, and moreover $a$ is the only answer justified by $q$.
  We say that a justified sequence $s$ is \emph{alternating} if it alternates between $O$-moves and $P$-moves, and that it is \emph{well-formed} if it is both well-bracketed and alternating.

  We say that a well-formed justified sequence is \emph{visible} if whenever $ta\prefix s$, and $a$ is a $P$-move, then the justifier of $a$ occurs in the $P$-view of $t$, and if whenever $tb\prefix s$, and $b$ is a non-initial $O$-move, then the justifier of $b$ occurs in the $O$-view of $t$.

  We say that a justified sequence $s$ is \emph{legal} if it is well-formed and visible, and write $L_A$ for the set of legal sequences occurring in $A$.
\end{definition}

Note that since every non-initial move in a justified sequence $s$ must be justified by some previous move, then the first move in the sequence must be initial and therefore an $O$-question.  
If $s$ is alternating, this means that $s$ ends with an $O$-move if it has odd length and with a $P$-move if it has even length.  

\begin{definition}
  Given a legal sequence $s\in L_A$, and a move $b$ in $s$, we say that a move $a$ in $s$ is \emph{hereditarily justified by $b$} if there is a chain of justification pointers going back from $a$ to $b$.

  We write $s\vert_b$ for the subsequence of $s$ given by all moves in $s$ that are hereditarily justified by $b$.
  Given a set $I$ of initial moves, we write $s\vert_I$ for the subsequence of $s$ given by all moves that are hereditarily justified by some $b\in I$.

  A \emph{game} is given by a tuple $A=(M_A,\lambda_A,\ts_A,P_A)$ where $(M_A,\lambda_A,\ts_A)$ is an arena and $P_A$ is a non-empty prefix-closed subset of $L_A$ such that if $s\in P_A$ and $I$ is a set of initial moves, then $s\vert_I\in P_A$.
\end{definition}

We shall call an odd-length sequence $s\in P_A$ an \emph{$O$-position} and an even-length sequence a \emph{$P$-position}

\begin{example}[Empty game]
  The \emph{empty game} $I$ is given by the tuple
  \[
    (\emptyset,\emptyset,\emptyset,\{\epsilon\})\,,
    \]
  where $\epsilon$ is the empty sequence.
  \label{ExEmptyGame}
\end{example}

\begin{example}[Data-type games]
  Let $X$ be some set.  
  Then we have a game, which we shall also call $X$, given by:
  \begin{itemize}
    \item $M_X = \{q\} + X$, 
    \item $\lambda_X(q)=(O,Q)$ and $\lambda_X(x)=(P,A)$ for all $x\in X$, 
    \item $q\ts_X x$ for each $x\in X$, and
    \item $P_X = \{\epsilon,q\}\cup\{qx\suchthat x\in X\}$, where the $x$ in $qx$ is justified by $q$.
  \end{itemize}

  In particular, we have games $\bC$, $\bB$ and $\bN$, which we shall use to model the datatypes $\com$, $\bool$ and $\nat$ of Idealized Algol.
\end{example}

\begin{definition}
  Let $A$ be a game.  
  Then a \emph{strategy} for $A$ is a non-empty even-prefix-closed set $\sigma\subset P_A$ of $P$-positions in $A$ such that if $sab,sac\in \sigma$ then $b=c$ and the justifier of $b$ is the justifier of $c$.  
\end{definition}
Here, we have identified a strategy for a game with the set of $P$-positions that can occur when player $P$ plays according to that strategy.  
So the condition we have given is one of \emph{determinism}: in any $O$-position $sa$ that can occur in the strategy, player $P$ must have at most one reply.

Note that there may be $O$-positions for which player $P$ has no reply at all; we use these to model non-terminating computations.

We write $\sigma\from A$ to denote that $\sigma$ is a strategy for the game $A$.

\begin{definition}
  A strategy $\sigma$ for a game $A$ is called \emph{innocent} if player $P$'s moves only depend on the current $P$-view; i.e., if whenever $sab\in\sigma$, $t\in\sigma$ and $ta\in P_A$ such that $\pv{sa}=\pv{ta}$, then we have $tab\in\sigma$.
\end{definition}

\section{Connectives on Games}
\label{SecConnectives}

In the \emph{product} $A\times B$ of games $A$ and $B$, player $O$ chooses either $A$ or $B$ on the first move and subsequent play is that game.

\begin{definition}
  Given games $A$,$B$, define a game $A\times B$ by
  \begin{itemize}
    \item $M_{A\times B} = M_A + M_B$,
    \item $\lambda_{A\times B} = [\lambda_A,\lambda_B]$,
    \item $* \ts_{A\times B} a$ if and only if $*\ts_A a$ or $*\ts_B a$ and $a \ts_{A\times B} b$ if and only if $a \ts_A b$ or $a\ts_B b$, and
    \item $P_{A\times B} = \{s\in L_{A\times B} \suchthat \text{$s\vert_A\in P_A$ \& $s\vert_B=\epsilon$ or $s\vert_A=\epsilon$ \& $s\vert_B\in P_B$}\}$.
  \end{itemize}
  We extend this to arbitrary products $\prod_i A_i$ in the obvious way.
  In particular, the product $1$ of the empty collection is the same as the empty game $I$ defined in Example \ref{ExEmptyGame}.
  \label{DefProduct}
\end{definition}

Here, we have written $s\vert_A$ for the subsequence of $s$ consisting of all moves from $M_A$ and $s\vert_B$ for the subsequence consisting of all moves from $M_B$.

In the \emph{tensor product} $A\tensor B$ of games $A$ and $B$, the games $A$ and $B$ are played in parallel, and player $O$ may switch between games when it is his turn.

\begin{definition}
  Given games $A$,$B$, define a game $A\tensor B$ by
  \begin{itemize}
    \item $M_{A\tensor B} = M_A + M_B$,
    \item $\lambda_{A\tensor B} = [\lambda_A,\lambda_B]$,
    \item $* \ts_{A\tensor B} a$ if and only if $*\ts_A a$ or $*\ts_B a$ and $a \ts_{A\tensor B} b$ if and only if $a \ts_A b$ or $a\ts_B b$, and
    \item $P_{A\tensor B} = \{s\in L_{A\tensor B} \suchthat \text{$s\vert_A\in P_A$ and $s\vert_B\in P_B$}\}$.
  \end{itemize}
\end{definition}

In the \emph{linear implication} $A\implies B$, the game $B$ is played in parallel with a version of $A$ in which the two players' roles have been switched around, and player $P$ may switch between the two games when it is her turn.

\begin{definition}
  Given games $A$,$B$, define a game $A\implies B$ by
  \begin{itemize}
    \item $M_{A\implies B} = M_A + M_B$,
    \item $\lambda_{A\implies B} = [\neg\circ\lambda_A,\lambda_B]$,
    \item $* \ts_{A\implies B} a$ if and only if $*\ts_B a$, and $a \ts_{A\implies B} b$ if and only if $a \ts_A b$ or $a\ts_B b$, or if $a$ is initial in $B$ and $b$ is initial in $a$, and
    \item $P_{A\implies B} = \{s\in L_{A\implies B} \suchthat \text{$s\vert_A\in P_A$ and $s\vert_B\in P_B$}\}$.
  \end{itemize}
\end{definition}

Here, $\neg\from \OP\times\QA \to \OP\times \QA$ is the function that reverses $O$ and $P$, while leaving $\QA$ unchanged.

In the \emph{exponential} of a game $A$, infinitely many copies of $A$ are played in parallel, and player $O$ may switch between copies whenever it is his move.

\begin{definition}
  Given a game $A$, define a game $\oc A$ by
  \begin{itemize}
    \item $M_{\oc A}=M_A$,
    \item $\lambda_{\oc A} = \lambda_A$,
    \item $\ts_{\oc A} = \ts_A$ and
    \item $P_{\oc A} = \{s\in L_{\oc A} \suchthat \text{$s\vert_b\in P_A$ for each initial move $b$ occurring in $s$}\}$.
  \end{itemize}
\end{definition}

Lastly, the \emph{sequoid} $A\sequoid B$ of two games $A$ and $B$ behaves like the tensor product $A\tensor B$, except that the opening move must take place in $A$.

\begin{definition}
  Given games $A,B$, define a game $A\sequoid B$ by
  \begin{itemize}
    \item $M_{A\sequoid B} = M_{A\tensor B}$, 
    \item $\lambda_{A\sequoid B} = \lambda_{A\tensor B}$, 
    \item $\ts_{A\sequoid B} = \ts_{A \tensor B}$ and
    \item $P_{A\sequoid B} = \{s\in P_{A\tensor B}\suchthat\text{$s=\epsilon$ or $s$ begins with a move from $A$}\}$.
  \end{itemize}
\end{definition}

\section{Composition of strategies}

\begin{definition}
  Let $A,B,C$ be arenas.  
  An \emph{interaction sequence} between $A,B,C$ is a justified sequence $\s$ of moves drawn from $M_A$, $M_B$ and $M_C$ such that $\s\vert_{A,B}\in L_{A\implies B}$ and $\s\vert_{B,C}\in L_{B\implies C}$.  
  Here, $\s\vert_{A,B}$ is the subsequence of $\s$ consisting of those moves from $\s$ that occur in $A$ or $B$, together with all justification pointers between moves in $A$ and $B$, and $\s\vert_{B,C}$ is defined similarly.

  We write $\Int(A,B,C)$ for the set of all interaction sequences between $A,B,C$.

  Given $\s\in\Int(A,B,C)$, we write $\s\vert_{A,C}$ for the subsequence of $\s$ consisting of those moves from $\s$ that occur in $A$ or $B$.  
  A move $b$ in $\s\vert_{A,C}$ justifies a move $a$ either if $b$ justifies $a$ in either the $A$ or the $C$ components, or if $b$ justifies in $\s$ some initial move $c$ in $B$, which itself justifies $a$.
\end{definition}

\begin{definition}
  Let $A,B,C$ be games, let $\sigma$ be a strategy for $A\implies B$ and let $\tau$ be a strategy for $B\implies C$.  
  We define $\sigma\|\tau$ to be given by the set
  \[
    \{\s\in\Int(A,B,C)\suchthat \text{$\s\vert_{A,B}\in\sigma$ and $\s\vert_{B,C}\in\tau$}\}\,.
    \]
  Then we define the \emph{composition} $\sigma;\tau$ of $\sigma$ and $\tau$ to be given by the set
  \[
    \{\s\vert_{A,C}\suchthat \s\in\sigma\|\tau\}\,.
    \]
\end{definition}

We need some small lemmata and definitions to help us show that this is a strategy.

\begin{lemma}
  We extend the function $\lambda_A^{OP}$ to sequences of moves by
  \begin{itemize}
    \item $\lambda_A^{OP}(\epsilon)=P$ and
    \item $\lambda_A^{OP}(sa)=\lambda_A(a)$.
  \end{itemize}

  If $s\in P_{A\implies B}$, then $\lambda_{A\implies B}^{OP}(s)=(\lambda_A^{OP}(s\vert_A)\Rightarrow \lambda_B^{OP}(s\vert_B))$, where $\Rightarrow$ is the binary operation on $\OP$ defined by
  \[
    \begin{array}{cc|c}
      P & Q & P\Rightarrow Q \\
      \hline
      P & P & P \\
      O & P & P \\
      P & O & O \\
      O & O & P
    \end{array}\,.
    \]
  Moreover, if $\lambda_A^{OP}(s\vert_A)=O$ then $\lambda_A^{OP}(s\vert_B)=O$.
  \label{LemCompositionLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $s$.
  If $s=\epsilon$, then $s\vert_A=s\vert_B=\epsilon$, and so $(\lambda_A^{OP}(s\vert_A)\Rightarrow \lambda_B^{OP}(s\vert_B)) = (P\Rightarrow P) = P = \lambda_{A\implies B}^{OP}(s)$.  

  Suppose then that $s=ta$, and that $\lambda_{A\implies B}^{OP}(t)=O$.  
  This means that $\lambda_A^{OP}(t\vert_A)=P$ and $\lambda_B^{OP}(t\vert_B)=O$.
  Then, whether $a$ is a move in $A$ or a move in $B$, adding it will flip exactly one of these components -- so $\lambda_{A\implies B}(s\vert_A)=O$ and $\lambda_{A\implies B}^{OP}(s\vert_B)=O$ if $a$ is a move in $A$ and $\lambda_{A\implies B}(s\vert_A)=P$ and $\lambda_{A\implies B}^{OP}(s\vert_B)=P$ if $a$ is a move in $C$.

  Suppose instead that $\lambda_{A\implies B}^{OP}(t)=P$.  
  By induction, this means that either $\lambda_A^{OP}(t\vert_A)=P$ and $\lambda_B^{OP}(t\vert_B)=P$ or that $\lambda_A^{OP}(t\vert_A)=O$ and $\lambda_B^{OP}(t\vert_B)=O$.
  In the first case, this means that either $t\vert_A$ is empty or its last move is a $P$-move in $A$ (and therefore an $O$-move in $A\implies B$), and so the move $a$ must take place in $C$, meaning that $\lambda_A^{OP}(s\vert_A)=P$ and $\lambda_B^{OP}(s\vert_B)=O$.  

  Similarly, in the second case, the last move in $t\vert_C$ must be an $O$-move in $B$ (and therefore an $O$-move in $A\implies B$, and so the move $a$ must take place in $A$, meaning that $\lambda_A^{OP}(s\vert_A)=P$ and $\lambda_B^{OP}(s\vert_B)=O$.  
\end{proof}

It follows that

\begin{corollary}[Switching condition]
  Only player $P$ may switch between games in $A\implies B$; i.e., if $tab\in P_{A\implies B}$, and $a$ occurs in $A$ and $b$ in $B$, or if $a$ occurs in $B$ and $b$ in $A$, then $b$ is a $P$-move.
  \label{CorSwitchingCondition}
\end{corollary}
\begin{proof}
  Otherwise, $\lambda_{A\implies B}(t)=O$, so $\lambda_A(t\vert_A)=P$ and $\lambda_B(t\vert_B)=O$.  
  But we must also have $\lambda_{A\implies B}(tab)=O$, so $\lambda_A(tab\vert_A)=P$ and $\lambda_B(tab\vert_B)=O$.  
  But this is a contradiction, since $tab\vert_A$ and $tab\vert_B$ are both one move longer than the plays $t\vert_A$ and $t\vert_B$.
\end{proof}

\begin{definition}[{\cite[\sec 3.1]{Harmer2006InnocentGS}}]
  Given $\s\in \Int(A,B,C)$, we define the \emph{$P$-view} $\pv{\s}$ of $\s$ inductively as follows.
  \begin{IEEEeqnarray*}{RCL?s}
    \pv{\epsilon} & = & \epsilon & \\
    \pv{\s a} & = & \pv{\s}a & if $a$ is a move in $B$, an $O$-move in $A$ or a $P$-move in $C$ \\
    \pv{\s c} & = & c & if $c$ is an initial move of $C$ \\
    \pv{\s b\t a} & = & \pv{\s}ba & \parbox[t][][t]{200pt}{if $a$ is a $P$-move of $A$ or an $O$-move of $C$ and is justified by $b$} \\
  \end{IEEEeqnarray*}
\end{definition}

\begin{lemma}
  If $\s\in \Int(A,B,C)$, then $\pv{\s}\vert_{A,C}=\pv{\s\vert_{A,C}}$.
  \label{LemHarmerRestriction}
\end{lemma}
\begin{proof}
  Induction on the length of $\s$.  
  This is clear if $\s=\epsilon$.  
  
  If $a$ is an $O$-move in $A$ or a $P$-move in $C$, then $a$ is a $P$-move in $A\implies C$.  
  We have $\pv{\s a}\vert_{A,C}=\pv{\s}\vert_{A,C}a$, which by the inductive hypothesis is equal to $\pv{\s\vert_{A,C}}a$, which is the same as $\pv{\s a\vert_{A,C}}$.
  If $b$ is a move in $B$, then $\pv{\s b}\vert_{A,C}=\pv{\s}b\vert_{A,C}=\pv{\s}\vert_{A,C}=\pv{\s\vert_{A,C}}=\pv{\s b\vert_{A,C}}$, by the inductive hypothesis.

  If $c$ is initial in $C$, then $\pv{\s c}\vert_{A,C}=c=\pv{\s c\vert_{A,C}}$.

  Suppose $a$ is a $P$-move of $A$ or an $O$-move of $C$ -- so $a$ is an $O$-move in $A\implies C$ -- and suppose that $a$ is justified by $b$ in the sequence $\s b\t a$.  
  Since $a$ cannot be an initial move in $A$, $b$ must occur in the same game as $a$, and in particular must not occur in $B$.
  Then we have $\pv{\s b\t a}\vert_{A,C}=\pv{\s} ba\vert_{A,C}=\pv{\s}\vert_{A,C}ba$, which by the inductive hypothesis is equal to $\pv{\s\vert_{A,C}}ba=\pv{\s ba\vert_{A,C}}$.
\end{proof}

\begin{lemma}[{\cite[\sec 3.1]{Harmer2006InnocentGS}}]
  Let $\s a\in \Int(A,B,C)$ (so, in particular, $\s\vert_{A,B}$ and $\s\vert_{B,C}$ satisfy the visibility condition).  
  If $a$ is a move in $B$, an $O$-move in $A$ or a $P$-move in $C$, then $\pv{\s a}\in \Int(A,B,C)$.
  \label{LemHarmersLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $\s$.  
  If $\s=\epsilon$, then this is clear.  
  Otherwise, suppose that $\s$ is non-empty.

  First, we claim that $\pv{\s}\in\Int(A,B,C)$.  
  If $\s$ ends with a move in $B$, an $O$-move in $A$ or a $P$-move in $C$, then this follows immediately from the inductive hypothesis.  
  Otherwise, suppose that $\s$ ends with a $P$-move in $A$ or an $O$-move in $C$.  
  If this last move is initial, then $\pv{\s}$ is a single move, so the claim is trivial.  
  Otherwise, write $\s=\t p\u r$, where $p$ justifies $r$.  
  By the inductive hypothesis, we have $\pv{\t p}\in \Int(A,B,C)$, and then $\pv{s}=\pv{\t p\u r}=\pv{\t}pr=\pv{\t p}r\in \Int(A,B,C)$.  

  Now, since $a$ is a $P$-move in $A\implies B$ or in $B\implies C$, its predecessor $b$ is an $O$-move and has some justifier $c$ contained in $\pv{\s\vert_X}$, where $X\in\{A\implies B,B\implies C\}$ is that component in which $a$ is a $P$-move.  
  Then this $c$ is preceded by some other $O$-move $b'$, which is necessarily also contained in $\pv{\s}$, and so has some justifier $c'$, contained in $\pv{\s\vert_X}$ by visibility.  
  Continuing in this way until we reach an initial move, we build up the whole of the sequence $\pv{\s\vert_X}$ as a subsequence of $\pv{\s}$.  
  Therefore, the justifier of $a$ must be contained in $\pv{\s}$, and so $\pv{\s a}=\pv{\s}a\in\Int(A,B,C)$.
\end{proof}

\begin{lemma}[$O$-views in the linear implication, {\cite[4.2,4.3]{hoPcf}}]
  Let $A,B$ be games, and let $bs$ be a non-empty play in $A\implies B$ beginning with an initial move $b$ in $B$.

  i) If $bs$ ends with a $P$-move in $B$, then $\ov{bs}_{A\implies B}=\ov{bs\vert_B}_B$.

  ii) If $bs$ ends with a $P$-move in $A$, then $\ov{bs}_{A\implies B} = b\pv{s\vert_A}^A$.
  \label{LemProjectionLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $s$.
  If $s=\epsilon$, then $bs$ ends with an $O$-move in $B$, and we have $\pv{b}^{A\implies B} = b = \pv{b}^{B}$.  

  Otherwise, suppose that $bs$ ends with a $P$-move $c$ in $B$.  
  Let $d$ be the justifier of $c$.  
  Then $d$ must be an $O$-move in $B$.
  Write $bs=tduc$, where $t,u$ are sequences.  
  Then $\ov{tduc}_{A\implies B}=\ov{t}_{A\implies B}dc$ and $\ov{tduc\vert_B}_B=\ov{t\vert_B}_Bdc$.
  By Corollary \ref{CorSwitchingCondition}, $t$ must end with a $P$-move in $B$, or be empty, so by the inductive hypothesis we have $\ov{t}_{A\implies B}=\ov{t\vert_B}_B$.
  Therefore, $\ov{bs}_{A\implies B}=\ov{tduc}_{A\implies B}=\ov{t}_Bdc = \ov{tduc\vert_B}_B=\ov{bs\vert_B}_B$.

  Next, suppose that $bs$ ends with a $P$-move $a$ in $A$.
  Let $c$ be the justifier of $a$.  
  Then $c$ must be an $O$-move in $A$.  
  Write $s=tcua$, where $t,u$ are sequences.  
  Then $\ov{btcua}_{A\implies B}=\ov{bt}_{A\implies B}ca$ and $\pv{tcua\vert_A}^A = \pv{t\vert_A}^Aca$, since the roles are reversed in $A$.
  By Corollary \ref{CorSwitchingCondition}, $t$ must end in a $P$-move in $A$, or be empty, so by the inductive hypothesis we have $\ov{bt}_{A\implies B} = b\pv{t\vert_A}^A$.  
  Therefore, $\ov{bs}_{A\implies B}=\ov{btcua}_{A\implies B}=\ov{bt}_{A\implies B}ca=b\pv{t\vert_A}^Aca=b\pv{tcua\vert_A}^A=b\pv{s\vert_A}^A$.  
\end{proof}

\begin{proposition}
  $\sigma;\tau$ is a strategy for $A\implies C$.  
\end{proposition}
\begin{proof}
  First, we claim that $\s\vert_{A,C}\in P_{A\implies B}$ for any $\s\in \sigma\|\tau$.
  Since we certainly have $\s\vert_{A,C}\vert_A = \s\vert_{A,B}\vert_A\in P_A$ and $\s\vert_{A,C}\vert_C = \s\vert_C = \s\vert_{B,C}\vert_C\in P_C$, it suffices to show that $\s\vert_{A,C}\in L_{A\implies C}$.

  Suppose that $ta\prefix \s\vert_{A,C}$.  We claim that $\lambda_{A\implies C}(t) = \neg\lambda_{A\implies C}(a)$.
  By Lemma \ref{LemCompositionLemma}, we are in one of the following configurations.
  \small
  \[
    \begin{array}{ccc|ccc}
      \lambda_A^{OP}(t\vert_A) & \lambda_B^{OP}(t\vert_B) & \lambda_C^{OP}(t\vert_C) & \lambda_{A\implies B}^{OP}(t\vert_{A,B}) & \lambda_{B\implies C}^{OP}(t\vert_{B,C}) & \lambda_{A\implies C}^{OP}(t\vert_{A,C}) \\
      \hline
      P & P & P & P & P & P \\
      P & P & O & P & O & O \\
      P & O & O & O & P & O \\
      O & O & O & P & P & P 
    \end{array}
    \]
  \normalsize
  In the configuration $PPP$, the move $a$ cannot be a move in $A$, since that would leave $ta\vert_{A\implies B}$ in the configuration $OP$, which is impossible by Lemma \ref{LemCompositionLemma}.  
  Therefore, it must be a move in $C$, and must therefore be an $O$-move in $C$ and hence an $O$-move in $A\implies C$.

  In the configuration $PPO$, once again the move $a$ cannot take place in $A$, since this would leave $ta\vert_{A\implies B}$ in an illegal configuration.  
  Therefore, it must occur in $C$, and must be a $P$-move in $C$ and hence a $P$-move in $A\implies C$.

  In the configuration $POO$, the move $a$ cannot take place in $C$, or it would leave $ta\vert_{B,C}$ in the illegal configuration $OP$, so the move $a$ takes place in $A$.  
  Therefore, it must be an $O$-move in $A$ and hence a $P$-move in $A\implies C$.  

  Lastly, in the configuration $OOO$, the move $a$ cannot occur in $C$, or it would leave $ta\vert_{B,C}$ in the configuration $OP$, and so it must take place in $A$.  
  Therefore, it must be a $P$-move in $A$, and hence an $O$-move in $A\implies C$.

  Having established that $\s\vert_{A,C}$ is alternating, we now show that it is well-bracketed.
  Suppose that a question move $q$ in $\s\vert_{A,C}$ justifies some answer move $a$.
  $q$ and $a$ must occur in the same component, since the only case in which a move from one of $A$ and $C$ can justify a move in the other is when both moves are initial, and hence questions.
  Suppose first that $q$ and $a$ both occur in the game $C$.  
  Suppose that some other question move $q'$ occurs between $q$ and $a$ in $\s\vert_{A,C}$.  
  If $q'$ occurs in $C$, then it must be answered by some $a'$ occurring between $q'$ and $a$, since $\s\vert_C$ is a well-bracketed sequence.  
  Otherwise, suppose that $q'$ occurs in $A$.  

  By examining the table above, we see that there must be some move in $B$ occurring between $q$ and $q'$ in $\s$, since moves in $A$ move between configurations $OOO$ and $POO$, while moves in $C$ move us between configurations $PPP$ and $PPO$.
  Let $b$ be the earliest such move.  
  Then $b$ must be a question; indeed, if it is an answer, then it is non-initial and so can only be justified by questions in $B$.  
  But such a question must occur earlier in $\s\vert_{B,C}$ than $q$, which would mean that $q$ was an unanswered question when the move $b$ was played, contradicting well-bracketedness of $\s\vert_{B,C}$.  
  Since $b$ is a question, it must be answered by some $a''$ occurring between $b$ and $a$.  
  Therefore, since $\s\vert_{A,B}$ is well-bracketed, the move $q'$ must be answered by some $a'$ occurring between $a'$ and $a''$ in $\s\vert_{A,B}$, and therefore between $a'$ and $a$ in $\s\vert_{A,C}$.

  The case when $q$ and $a$ both occur in $A$ is similar.  

  Lastly, we need to show that $\s\vert_{A,C}$ satisfies the visibility condition.
  Let $ta\prefix\s\vert_{A,C}$.
  Choose some $\t\prefix\s$ such that $\t\vert_{A,C}=t$.  

  Suppose $a$ is a $P$-move.
  Then by Lemma \ref{LemHarmersLemma}, $\pv{\t a}\in\Int(A,B,C)$.  
  By Lemma \ref{LemHarmerRestriction}, $\pv{t}a=\pv{ta}=\pv{\t a}\vert_{A,C}$, and therefore that the justifier of $a$ must be inside $\pv{t}$.

  Secondly, suppose that $a$ is an $O$-move.
  If $a$ is an $O$-move in $C$, then either it is initial or $t$ ends with some $P$-move in $B$, and therefore $\ov{t}_{A\implies C}=\ov{t\vert_B}_B = \ov{\t\vert_{B,C}}_B$.  
  Therefore, since $t\vert_{B,C}$ satisfies visibility, the justifier of $a$ must lie in $\ov{t}_{A\implies C}$.  
  If $a$ is an $O$-move in $A$, then write $t=cu$ and $\t=c\u$, where $c$ is the starting move in $C$.
  We have $\ov{cua}_{A\implies C}=c\pv{u\vert_A a}^A = \ov{c\u\vert_{A,B}}_{A\implies B}$.  
  Therefore, the justifier of $a$ must lie in $\ov{t}_{A\implies C}$.

  Therefore, $\s\vert_{A,C}\in L_{A\implies C}$, so $\s\vert_{A,C}\in P_{A\implies C}$.

  It is fairly clear that $\sigma;\tau$ is even-prefix closed, since $\sigma$ and $\tau$ are.  
  Indeed, if $\s\vert_{A,C}\in\sigma;\tau$ and $t\prefix\s\vert_{A,C}$, then we may choose some prefix $\t$ of $\s$ such that $t=\t\vert_{A,C}$.  
  Then $\t\vert_{A,B}\prefix\s\vert_{A,B}\in\sigma$ and $\t\vert_{B,C}\prefix\s\vert_{B,C}\in\tau$, so $\t\in\sigma\|\tau$.

  We claim that every sequence in $\sigma;\tau$ has even length.  
  Indeed, if $\s\vert_{A,B}\in\sigma$ and $\s\vert_{B,C}\in\tau$, then both $\s\vert_{A,B}$ and $\s\vert_{B,C}$ must have even length, so must be in configuration $OO$ or $PP$.  
  This means that $\s$ as a whole must be in configuration $OOO$ or $PPP$, and so $\s\vert_{A,C}$ must be in configuration $OO$ or $PP$, so must have even length.

  Lastly, we need to show that $\sigma;\tau$ is deterministic.  
  Suppose that $sab,sac\in\sigma;\tau$, and suppose that $b\ne c$.  
  Suppose that $\s\vert_{A,C}=sab$ and $\t\vert_{A,C}=sac$, for $\s,\t\in\sigma\|\tau$, and let $\u$ be the longest common prefix of $\s,\t$.
  $\s$ and $\t$ are certainly incomparable under the prefix ordering, since $\s\vert_{A,C}$ and $\t\vert_{A,C}$ are, so we have $\u p\prefix \s$ and $\u q\prefix \t$, where $p\ne q$.
  Now $p$ and $q$ cannot be $O$-moves in $A$, $P$-moves in $C$ or moves in $B$, or they would have to be equal by determinism of $\sigma$ and $\tau$.  
  Therefore, they are $P$-moves in $A$ or $O$-moves in $C$, but this contradicts $\s\vert_{A,C}=sab$ and $\t\vert_{A,C}=sac$.

  Therefore, the composition $\sigma;\tau$ is a strategy.  
\end{proof}

We also want to show that the composition of innocent strategies is innocent.
We follow the proof given in \cite{Harmer2006InnocentGS}.  
First, we use a lemma.

\begin{lemma}[{\cite[3.3.3]{Harmer2006InnocentGS}}]
  Let $\s a\in\Int(A,B,C)$.  

  i) If $a$ is a $P$-move of $A$ or an $O$-move of $B$, then $\pv{\s a\vert_{A,B}}=\pv{\pv{\s a}\vert_{A,B}}$.

  ii) If $a$ is a $P$-move of $B$ or an $O$-move of $C$, then $\pv{\s a\vert_{B,C}}=\pv{\pv{\s a}\vert_{B,C}}$.
  \label{LemHarmerProjection}
\end{lemma}
\begin{proof}
  Induction on the length of $\s$.
  We prove (i); the proof of (ii) is exactly the same.  

  If $a$ is a $P$-move of $A$ or an $O$-move of $B$, then it is an $O$-move of $A\implies B$.
  If $a$ is an initial move of $A\implies B$, then we have $\pv{\s\vert_{A,B}a}=a=\pv{a}\vert_{A,B}=\pv{\pv{\s a}}\vert_{A,B}$.  
  Otherwise, write $\s=\t b\u$, where $b$ justifies $a$.  
  Then $\pv{\s a \vert_{A,B}} = \pv{\t\vert_{A,B} b\u\vert_{A,B} a} = \pv{t\vert_{A,B}}ba$, which by the inductive hypothesis is equal to $\pv{\pv{\t}\vert_{A,B}}ba$, which is equal to $\pv{\pv{\t b \u a}\vert_{A,B}} = \pv{\pv{\s a}\vert_{A,B}}$.
\end{proof}

\begin{proposition}
  If $\sigma\from A \implies B$ and $\tau\from B \implies C$ are innocent strategies, then $\sigma;\tau\from A\implies C$ is innocent.
\end{proposition}
\begin{proof}
  Suppose there are $sab,t\in\sigma;\tau$ such that $ta\in P_{A\implies C}$, $\pv{sa}=\pv{ta}$.
  Let $\s' b$ be such that $\s' b\vert_{A,C}=sab$ and choose the minimal prefix $\s\prefix \s'$ such that $\s a\vert_{A,C}=sa$.
  
  Let $\t a$ be such that $\t a\vert_{A,C}=ta$.
  Since $\pv{sa}=\pv{ta}$, we have $\pv{\s a}\vert_{A,C}=\pv{\s a\vert_{A,C}}=\pv{sa}=\pv{ta}=\pv{\t a\vert_{A,C}}=\pv{\t a}\vert_{A,C}$ by Lemma \ref{LemHarmerRestriction}.  
  Let $\u$ be the longest common prefix of $\pv{\s a}$ and $\pv{\t a}$.  
  If $\s a$ and $\t a$ are not equal, then without loss of generality there is some $\u p\prefix \s$, where $\u p\not\prefix \t$.  
  Then, by determinism of $\sigma$ and $\tau$, this $p$ cannot be a $P$-move in either $A\implies B$ or $B\implies C$, so it must be a $P$-move in $A$ or an $O$-move in $C$, and is therefore preceded by another move in $A$ or $C$, which contradicts $\pv{\s a}\vert_{A,C}=\pv{\t a}\vert_{A,C}$.  
  Therefore, $\pv{\s a}=\pv{\t a}$.

  Now write $\s'=\s a b_1 \cdots b_n b$, where each $b_i$ is a move in $B$.  
  We show by induction that $\t a b_1 \cdots b_j\in\sigma\|\tau$.  
  Indeed, if $\t a b_1 \cdots b_{j-1}\in\sigma\|\tau$, then $b_j$ (or $b$) is a $P$-move in either $A\implies B$ or $B\implies C$, and $b_{j-1}$ is an $O$-move in that same component.  
  Write $X$ for the component ($A\implies B$ or $B\implies C$) in which $b_j$ is a $P$-move.
  Repeating the argument above, we see that $\pv{\t a b_1\cdots b_{j-1}} = \pv{\s a b_1\cdots b_{j-1}}$, and so we have that $\pv{\t a b_1\cdots b_{j-1}\vert_X}=\pv{\s a b_1\cdots b_{j-1}\vert_X}$ by Lemma \ref{LemHarmerProjection}.  
  Therefore, by innocence of $\sigma$ (if $X=A\implies B$) or $\tau$ (if $X=B\implies C$), we see that $\t a b_1 \cdots b_j\in \sigma\|\tau$.  
  It follows that $\t a b_1 \cdots b_n b\in\sigma\|\tau$, and therefore that $t a b\in\sigma;\tau$.
\end{proof}

\section{Associativity of composition}

In this section, we shall prove that composition of strategies is associative; i.e., that if $\sigma\from A \implies B$, $\tau\from B\implies C$ and $\upsilon \from C \implies D$ are strategies, then $(\sigma;\tau);\upsilon=\sigma;(\tau;\upsilon)$.  
To do this, if $A,B,C,D$ are arenas, we define the set $\Int(A,B,C,D)$ to be the set of all sequences $\u$ of moves such that $\u\vert_{A,B}\in L_{A\implies B}$, $\u\vert_{B,C}\in L_{B\implies C}$ and $\u\vert_{C,D}\in L_{C \implies D}$.  
Given such a sequence $\u$, we define $\u\vert_{A,D}$ as before; i.e., we take all moves from $\u$ occurring in $A$ and $D$, together with justification pointers within these games, and if an initial move in $A$ is justified by an initial move in $B$, which is justified by an initial move in $C$, which is justified by an initial move in $D$, then we add a justification pointer from that move in $A$ to that move in $D$.

Given strategies $\sigma,\tau,\upsilon$ as above, we define $\sigma\|\tau\|\upsilon$ to be the set of all $\u\in\Int(A,B,C,D)$ such that $\u\vert_{A,B}\in\sigma$, $\u\vert_{B,C}\in\tau$ and $\u\vert_{C,D}\in\upsilon$.
We then claim that:

\begin{lemma}
  \[
    (\sigma;\tau);\upsilon = \{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\} = \sigma;(\tau;\upsilon)\,.
    \]
\end{lemma}
\begin{proof}
  Firstly, if $\u\in\sigma\|\tau\|\upsilon$, then it is clear to see that $\u\vert_{A,B,C}\in\sigma\|\tau$ and that $\u\vert_{B,C,D}\in\tau\|\upsilon$, and therefore that $\{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\}\subset (\sigma;\tau);\upsilon$ and $\{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\}\subset \sigma;(\tau;\upsilon)$. 

  Conversely, suppose that $\t\in(\sigma;\tau)\|\upsilon$, so that $\t\vert_{A,C}\in\sigma;\tau$ and $\t\vert_{C,D}\in\upsilon$, and choose some $\s\in\sigma\|\tau$ such that $\s\vert_{A,C}=\t\vert_{A,C}$.
  We may write 
  \[
    \s=\ccc_1\bbb_1\aaa_1\cdots \ccc_n\bbb_n\aaa_n
    \]
  for some (possibly empty) sequences of moves $\aaa_i$ from $A$, $\bbb_i$ from $B$ and $\ccc_i$ from $C$.  
  We may then write 
  \[
    \t=\ddd_1\ccc_1\aaa_1\cdots\ddd_n\ccc_n\aaa_n
    \]
  (for the same $\aaa_i$, $\ccc_i$), and we can therefore interleave these sequences into the sequence
  \[
    \u = \ddd_1\ccc_1\bbb_1\aaa_1\cdots\ddd_n\ccc_n\bbb_n\aaa_n\,,
    \]
  which is in $\sigma\|\tau\|\upsilon$.
  Then we have $\u\vert_{A,D}=\t\vert_{A,D}$, and it follows that $(\sigma;\tau);\upsilon\subset\{\u\vert_{A,C}\suchthat \u\in\sigma\|\tau\|\upsilon\}$, and the case for $\sigma;(\tau;\upsilon)$ is identical.
\end{proof}

\section{Copycat strategies}
\label{SecCopycat}

\begin{definition}
  Let $A,B$ be games.  
  Then a \emph{subset inclusion} of $A$ into $B$ is a partial injection $i\from M_A\hookrightarrow M_B$ such that
  \begin{itemize}
    \item if $i$ is defined at $a$ and $b$ then $*\ts_A a$ if and only if $*\ts_B i(a)$, and $a\ts_A b$ if and only if $i(a)\ts_B i(b)$;
    \item $i(a)$ is defined for every move $a$ occurring in a play in $P_A$; and
    \item $i_*(s)\in P_B$ for every $s\in P_A$.
  \end{itemize}
  Here, $i_*(s)$ means the function $i$ applied pointwise to the elements of the string $s$.

  If $i$ is a subset incusion of $A$ into $B$, then we get an innocent strategy $\subs_i\from B \implies A$ defined by
  \[
    \subs_i = \{s\in P_{B\implies A}\suchthat\text{for all even-length $t\prefix s$, $t\vert_B=i_*(t\vert_A)$}\}\,.
    \]
  If $P_B=\{i_*(s)\suchthat s\in P_A\}$, then we call it a \emph{structural isomorphism}, and we write $\cc_i$ (`copycat') for $\subs_i$.
\end{definition}

\begin{proposition}
  $\subs_i$ is an innocent strategy.

  Moreover, if $\sigma\from C \implies B$ is a strategy, then
  \[
    \sigma;\subs_i = \{[\id_{M_C},i\inv]_*(s)\suchthat s\in\sigma,\,s\vert_B\in i_*(P_A)\}\,,
    \]
  where $i\inv\from M_B \pfun M_A$ is the canonical partial right-inverse to $i$, and if $\tau \from A \implies D$ is a strategy, then
  \[
    \subs_i;\tau = \{[i,\id_{M_D}]_*(s)\suchthat s\in\tau\}\,.
    \]
  \label{PropCopycat}
\end{proposition}
\begin{proof}
  $\subs_i$ is clearly prefix-closed by definition.  
  Suppose that $sab,sac\in\subs_i$; then $s\vert_A=i_*(s\vert_B)$ and $sab\vert_A=i_*(sab\vert_B)$.  
  It follows that $ab\vert_A=i_*(ab\vert_B)$, so either $a$ is a move in $A$ and $b=i(a)$ or $a$ is a move in $B$ and $a=i(b)$.  
  Since the same applies to $c$, and since $i$ is injective, we have $b=c$.

  This argument also shows that $\subs_i$ is \emph{history-free} -- i.e., that its reply to an $O$-position is entirely determined by the last $O$-move -- and therefore it is certainly innocent.

  Now let $\sigma \from C \implies B$ be a strategy.  
  Suppose that $\s\in\sigma\|\subs_i$.  
  Then $\s\vert_{C,B}\in\sigma$ and $\s\vert_B=i_*(\s\vert_A)$; i.e., $\s\vert_{C,B}=[\id_{M_C},i]_*(\s\vert_{C,A})$, and therefore $\s\vert_{C,A}=[\id_{M_C},i]_*(\s\vert_{C,B})$, where $\s\vert_B\in i_*(P_A)$.

  Conversely, given $s\in\sigma$, where $s\vert_B\in i_*(P_A)$, for each $P$-move $b=i(a)$ in $s$ occurring in the component $B$, insert the move $a$ immediately after it, and for each $O$-move $b'=i(a')$ in $s$ occurring in the component $B$, insert the move $a'$ immediately before it.
  Let these extra moves in $B$ be justified according to the original moves in $A$, and let all initial moves in $B$ be justified by the initial moves in $A$ that occur immediately before them.
  Then the resulting sequence $\s$ is contained in $\sigma\|\subs_i$, and $\s\vert_{A,C}=[\id_{M_C},i\inv]_*(s)$.

  The case for composition in the other direction is similar.
\end{proof}

An easy corollary of this fact is that composition of copycat strategies respects composition of the underlying subset inclusions.

\begin{corollary}
  Let $i$ be a subset inclusion from $A$ to $B$ and let $j$ be a subset inclusion from $B$ to $C$.  
  Then $j\circ i$ is a subset inclusion from $A$ to $C$ and $\cc_{j\circ i}=\subs_j;\subs_i\from C \implies A$.
\end{corollary}

It is also easy to see from Proposition \ref{PropCopycat} that the identity function $\id\from M_A \to M_A$ is a structural isomorphism from $A$ to itself, and that the resulting copycat strategy $\cc_{\id}$ is an identity for composition.  
Combining this with our result for associativity in the previous chapter, we get that
\begin{theorem}
  The collection of games forms a category $\G$, where the morphisms $A \to B$ are strategies for $A\implies B$, composition is as above and the identity morphisms are the copycat strategies induced from the identity functions on moves.
\end{theorem}

In this setting, Proposition \ref{PropCopycat} tells us that a structural isomorphism gives rise to an isomorphism in $\G$.
\begin{proposition}
  Let $f$ be a structural isomorphism from a game $A$ to a game $B$.  
  Then $\cc_f$ is an isomorphim in $\G$ from $A$ to $B$.
\end{proposition}
\begin{proof}
  The underlying partial injection $f\from M_A \hookrightarrow M_B$ has an inverse partial injection $f\inv\from M_B \to M_A$, inducing a structural isomorphism from $B$ to $A$.  
  Then Proposition \ref{PropCopycat} tells us that $\cc_f$ and $\cc_{f\inv}$ are inverses in $\G$.
\end{proof}

General subset inclusions are not, of course, isomorphisms, but we can still say something category-theoretic about them.

\begin{proposition}
  Let $i$ be a subset inclusion from a game $A$ to a game $B$.  
  Then the strategy $\subs_i$ is an epimorphism from $B$ to $A$.
  \label{PropSubsetInclusionEpic}
\end{proposition}
\begin{proof}
  In fact, it is a split epimorphism: we can define a retract
  \[
    \ret_i = \{s\in P_{A\implies B}\suchthat\text{for all even-length $t\prefix s$, $t\vert_A=i_*(t\vert_B)$}\}\,.
    \]
  The same argument as in Proposition \ref{PropCopycat} tells us that this is indeed a strategy for $A\implies B$.
  Note that although $\subs_i$ is always a total strategy (i.e., if $s\in\subs_i$ and $sa\in P_{B\implies A}$, then there is always $sab\in\subs_i$ for some $b$), the same is not in general true about $\ret_i$.  

  In any case, if $\s\in\ret_i\|\subs_i$, then $\s\vert_{A^L} = i_*(\s\vert_B) = \s\vert_{A^R}$, and the same is true of any even-length substring of $\s$, and so $\s\vert_{A,A}\in\id_A$.  
  Conversely, given any $s\in \id_A$, we can form some $\s\in\ret_i\|\subs_i$ such that $\s\vert_{A,A}=s$ as in Proposition \ref{PropCopycat}.

  We can also prove that $\subs_i$ is an epimorphism directly, which might be useful, for example, in a setting in which non-total strategies such as $\ret_i$ are disallowed.  
  In this setting, let $\sigma,\tau\from A \implies C$ be strategies such that $\subs_i;\sigma=\subs_i;\tau$.  
  Then, by Proposition \ref{PropCopycat}, we know that
  \[
    \{[i,\id_{M_C}]_*(s)\suchthat s\in\sigma\}
    =
    \{[i,\id_{M_C}]_*(s)\suchthat s\in\tau\}\,.
    \]
  Then, since the function $[i,\id_{M_D}]_* \from P_{A\implies C} \to P_{B\implies C}$ is an injection, we deduce that $\sigma=\tau$.
\end{proof}

\section{$\G$ as a Symmetric Monoidal Category}

We now claim that the tensor product connective $\tensor$ makes $\G$ into a symmetric monoidal closed category, with internal hom given by $\implies$.  

\begin{definition}
  Let $\sigma\from A \implies B$ and $\tau\from C \implies D$ be strategies.  
  We define a strategy $\sigma\tensor\tau\from (A\tensor C) \implies (B \tensor D)$ by
  \[
    \sigma\tensor\tau = \{s\in P_{(A\tensor C)\implies (B\tensor D)}\suchthat s\vert_{A,B}\in\sigma\text{ and }s\vert_{C,D}\in\tau\}\,.
    \]
\end{definition}

To prove that this is a strategy, we prove a lemma analogous to our Lemma \ref{LemCompositionLemma}.  

\begin{lemma}
  Let $s\in P_{A\tensor B}$.  
  Then $\lambda^{OP}_{A\tensor B}(s)=\lambda^{OP}_A(s\vert_A)\wedge\lambda^{OP}_B(s\vert_B)$, where $\wedge$ is the binary operator on $\OP$ given by
  \[
    \begin{array}{cc|c}
      p & q & p\wedge q \\
      \hline
      P & P & P \\
      O & P & O \\
      P & O & O \\
      O & O & O
    \end{array}\,.
    \]
  Moreover, either $\lambda_A^{OP}(s\vert_A)=P$ or $\lambda_B^{OP}(s\vert_B)=P$.
  \label{LemTensorAnalogue}
\end{lemma}
\begin{proof}
  Mutual induction on the length of $s$.  
  This is obvious if $s$ is empty.  
  Suppose that $sa\in P_{A\tensor B}$, where $a$ is an $O$-move.  
  By induction, since $\lambda_{A\tensor B}(s)=P$, we must have $\lambda_{A\tensor B}(s\vert_A)=P$ and $\lambda_{A\tensor B}(s\vert_B)=P$.  
  Therefore, depending on which game $a$ is played in, either $\lambda_A(sa\vert_A)=O$ and $\lambda_B(sa\vert_B)=P$ or $\lambda_A(sa\vert_A)=P$ and $\lambda_B(sa\vert_B)=O$.  

  If $sb\in P_{A\tensor B}$, where $b$ is a $P$-move, then by induction either $\lambda_A(s\vert_A)=O$ and $\lambda_B(s\vert_B)=P$ or $\lambda_A(s\vert_A)=P$ and $\lambda_B(s\vert_B)=O$.  
  In either case, player $P$ must play in whichever game is currently in an $O$-position, returning us to configuration $PP$.
\end{proof}

The above proof gives us the following result, which is analogous to Corollary \ref{CorSwitchingCondition}.

\begin{corollary}[Switching condition for {$\tensor$}]
  Player $O$ switches games in $A\tensor B$; i.e., if $sab\in P_{A\tensor B}$, where $a$ and $b$ take place in different games (i.e., $a$ in $A$ and $b$ in $B$ or $a$ in $B$ and $b$ in $A$), then $b$ is an $O$-move.
\end{corollary}

\begin{proposition}
  $\sigma\tensor\tau$ is a strategy for $(A\tensor C)\implies (B\tensor D)$.
  \label{PropTensorWellDefined}
\end{proposition}
\begin{proof}
  $\sigma\tensor\tau$ is certainly an even-prefix-closed subset of $P_{(A\tensor C)\implies (B\tensor D)}^{\textit{even}}$.  

  Let $s$ be a play of $P_{(A\tensor B)\implies (C\tensor D)}$.  
  We consider the possible configurations of $s$; i.e., the tuples $(\lambda_A(s\vert_A),\lambda_B(s\vert_B),\lambda_C(s\vert_C),\lambda_D(s\vert_D))$.

  By Lemma \ref{LemCompositionLemma} we must avoid the overall configuration $OP$ for the linear implication, and by Lemma \ref{LemTensorAnalogue} we must avoid the configuration $OO$ inside either tensor product, so we end up with the following possibilities.
  \scriptsize
  \[
\arraycolsep=4.8pt\def\arraystretch{1.5}
    \begin{array}{cccc|cc|c}
      \lambda_A(s\vert_A) & \lambda_C(s\vert_C) & \lambda_B(s\vert_B) & \lambda_D(s\vert_D) & \lambda_{A\tensor C}(s\vert_{A,C}) & \lambda_{B\tensor D}(s\vert_{B,C}) & \lambda_{(A\tensor C)\implies (B\tensor D)}(s) \\
      \hline
      P & P & P & P & P & P & P \\
      P & P & P & O & P & O & O \\
      P & P & O & P & P & O & O \\
      P & O & P & O & O & O & P \\
      O & P & O & P & O & O & P \\
      P & O & O & P & O & O & P \\
      O & P & P & O & O & O & P \\
    \end{array}
    \]
  \normalsize
  Now, if $s\in\sigma\tensor\tau$, or an odd-length sequence formed by adding an $O$-move to the end of a sequence in $\sigma\tensor\tau$, then we also know that $s\vert_{A,B}\in\sigma\subset P_{A\implies B}$ and that $s\vert_{C,D}\in\tau\subset P_{C\implies D}$.  
  This means that we can discount the last two configurations in the table above, since one contains the illegal configuration $OP$ in $C\implies D$ and the other contains the illegal configuration $OP$ in $A \implies B$.

  Now suppose that $sab,sac\in\sigma\tensor\tau$.  
  Then $sa$ is an $O$-position in $(A\tensor C)\implies (B\tensor D)$, and is therefore in configuration $PPPO$ or $PPOP$.  
  By inspecting the table above, we see that if $sa$ is in configuration $PPPO$, then $b$ and $c$ must both occur either in $C$ or in $D$, and that if $sa$ is in configuration $PPOP$, then $b$ and $c$ must both occur either in $A$ or in $B$.  
  In either case, we must have $b=c$, by determinism of $\tau$ (in the first case) or of $\sigma$ (in the second case).
\end{proof}

We need a lemma to prove that the tensor product of two innocent strategies is innocent.

\begin{lemma}
  Let $s\in\sigma\tensor\tau$.  

  i) If $s$ ends with a move in $A$ or $B$, then $\pv{s}^{(A\tensor C)\implies (B\tensor D)}=\pv{s\vert_{A,B}}^{A\implies B}$.

  ii) If $s$ ends with a move in $C$ or $D$, then $\pv{s}^{(A\tensor C)\implies (B\tensor D)}=\pv{s\vert_{C,D}}^{C\implies D}$.
  \label{LemTensorViewLemma}
\end{lemma}
\begin{proof}
  Induction on the length of $s$.  
  We prove (i); (ii) is exactly the same.

  If $a$ is a $P$-move, then we have $\pv{sa}=\pv{s}a$.  
  By our analysis in the proof of Proposition \ref{PropTensorWellDefined}, player $P$ only switches moves between $A$ and $B$, and between $C$ and $D$, so $s$ must end with a move from $A$ or $B$.  
  Therefore, by the inductive hypothesis, $\pv{s}=\pv{s\vert_{A,B}}$.  
  Then $\pv{sa}=\pv{s}a=\pv{s\vert_{A,B}}a=\pv{sa\vert_{A,B}}$.  

  If $a$ is an initial move, then $\pv{sa}=a=\pv{sa\vert_{A,B}}$.

  If $a$ is an $O$-move justified by $b$ in $sbta$, then $\pv{sbta}=\pv{s}ba$.  
  Then $b$ is a $P$-move, so $s$ must end with a move in $A$ or $B$, as before.  
  Therefore, by the inductive hypothesis, $\pv{s}=\pv{s\vert_{A,B}}$.  
  Then $\pv{sbta}=\pv{s}ba=\pv{s\vert_{A,B}}ba=\pv{sbta\vert_{A,B}}$.
\end{proof}

\begin{proposition}
  Let $\sigma\from A \to B$, $\tau\from C \to D$ be innocent strategies.  
  Then $\sigma\tensor\tau$ is innocent.
  \label{PropTensorInnocent}
\end{proposition}
\begin{proof}
  Suppose $sab,t\in\sigma\tensor\tau$ such that $ta\in P_{(A\tensor C)\implies (B\tensor D)}$ and $\pv{sa}=\pv{ta}$.  
  Suppose without loss of generality that $a$ is a move in $A$ or $B$.  
  Then $\pv{sa}=\pv{sa\vert_{A,B}}$ and $\pv{ta}=\pv{ta\vert_{A,B}}$ by Lemma \ref{LemTensorViewLemma}, and therefore $tab\vert_{A,B}\in\sigma$ by innocence of $\sigma$, and so $tab\in\sigma\tensor\tau$.  
\end{proof}

The most important thing we need to prove is that $\tensor$ is a functor.

\begin{proposition}
  Let $\sigma'\from A'' \implies A'$, $\sigma\from A' \implies A$, $\tau'\from B'' \implies B'$ and $\tau \from B' \implies B$ be strategies.  
  Then $(\sigma'\tensor\tau');(\sigma\tensor\tau)=(\sigma';\sigma)\tensor(\tau';\tau)$.

  Moreover, if $A',A,B',B$ are games, $i$ is a subset inclusion from $A$ to $A'$ and $j$ is a structural isomorphism from $B$ to $B'$, then $\subs_i\tensor\subs_j = \subs_{[i,j]}$.
  In particular, if $A$ and $B$ are games, then $\id_A\tensor \id_B=\id_{A\tensor B}$.
  \label{PropTensorProductIsFunctor}
\end{proposition}
\begin{proof}
  First suppose that $s\in(\sigma'\tensor\tau');(\sigma\tensor\tau)$; so $s=\s\vert_{A'',B'',A,B}$, where $\s\in(\sigma'\tensor\tau')\|(\sigma\tensor\tau)$.  
  Then $\s\vert_{A'',A'}\in\sigma'$ and $\s\vert_{A',A}\in\sigma$, so $\s\vert_{A'',A',A}\in\sigma'\|\sigma$ and therefore $s\vert_{A'',A}=\s\vert_{A'',A}\in\sigma';\sigma$.  
  Similarly, $s\vert_{B'',B}\in\tau';\tau$, and therefore $s\in(\sigma';\sigma)\tensor(\tau';\tau)$.

  Conversely, suppose that $s\in(\sigma';\sigma)\tensor (\tau';\tau)$.  
  Choose some $\s\in\sigma'\|\sigma$, $\t\in\tau'\|\tau$ such that $s\vert_{A'',A}=\s\vert_{A'',A}$ and $s\vert_{B'',B}=\s\vert_{B'',B}$.  
  By our analysis, the only time we switch from the $A'',A$-component to the $B'',B$ component in $s$, or \emph{vice versa}, is when player $O$ switches between the games $A$ and $B$.  
  Thus, we may divide $s$ up into blocks, each starting and ending with a move in the outer component $A \tensor B$.  
  This then gives us a way to divide up $\s$ and $\t$ into blocks, such that each block of $\s$ or $\t$ projects on to a block of $s$.  
  Lastly, we can string these blocks together to give us some $\u\in(\sigma'\tensor\tau')\|(\sigma\tensor\tau)$ such that $\u\vert_{A'',B'',A,B}=s$.

  For the second part, let $A',A,B',B$ be games, let $i$ be a structural isomorphism from $A$ to $A'$ and let $j$ be a structural isomorphism from $B$ to $B'$.  
  Suppose that $s\in\subs_i\tensor \subs_j$.  
  Then $s\vert_{A',A}\in\subs_i$ and $s\vert_{B',B}\in\subs_j$ -- so if $u\prefix s\vert_{A,A}$ has even length, then $u\vert_{A'}=i_*(u\vert_A)$, and if $v\prefix s\vert_{B,B}$ has even length, then $v\vert_{B'}=i_*(v\vert_B)$.  
  Suppose that $t\prefix s$ is of even length.  
  Then, since only player $O$ swtiches between the $A',A$-component and the $B',B$-component, both $t\vert_{A',A}$ and $t\vert_{B',B}$ are of even length, it follows that $t\vert_{A',B'}=[i,j]_*(t\vert_{A,B})$.  
  Since $t$ was arbitrary, this means that $s\in \subs_{[i,j]}$.

  Conversely, suppose that $s\in\subs_{[i,j]}$.  
  Then for all even-length $t\prefix s$, $t\vert_{A'}=i_*(t\vert_{A})$ and $t\vert_{B'}=j_*(t\vert_{B})$.  
  Since any play in $\sigma$ or in $\tau$ is itself a play of $\sigma\tensor\tau$, then if $u\prefix s\vert_{A',A}$ has even length, then $u\vert_{A'}=i_*(u\vert_{A})$, and if $v\prefix s\vert_{B',B}$, then $v\vert_{B'}=j_*(v\vert_{B})$.  
  It follows that $s\vert_{A',A}\in \subs_i$ and $s\vert_{B',B}\in\subs_j$, and therefore that $s\in \subs_i\tensor\subs_j$.  
\end{proof}

Now it is fairly clear that if $A,B,C$ are games, then we have structural isomorphisms
\begin{mathpar}
  (A \tensor B) \tensor C \cong A \tensor (B\tensor C)
  \\
  A \cong A \tensor I \and A \cong I \tensor A
  \\
  A \tensor B \cong B \tensor A\,,
\end{mathpar}
induced by the associators, unitors and symmetry of the category of sets with coproduct.
We claim that these are natural transformations.

\begin{proposition}
  The families of morphisms
  \begin{mathpar}
    \cc_{\assoc_{M_A,M_B,M_C}} \from (A \tensor B) \tensor C \to A \tensor (B \tensor C)
    \\
    \cc_{\lunit_{M_A}} \from A \to I \tensor A \and \cc_{\runit_{M_A}} \from A \to A \tensor I
    \\
    \cc_{\sym{M_A,M_B}} \from A \tensor B \to B \tensor A
  \end{mathpar}
  are natural transformations in $\G$.
  \label{PropCoherencesAreNatural}
\end{proposition}
\begin{proof}
  We prove this for the associator; the other cases are similar.

  Let $\sigma\from A' \implies A$, $\tau\from B' \implies B$, $\upsilon\from C' \implies C$ be strategies.  
  By Proposition \ref{PropCopycat}, we have
  \begin{IEEEeqnarray*}{Cl}
    & ((\sigma\tensor\tau)\tensor\upsilon);\cc_{\assoc_{M_{A},M_{B},M_{C}}} \\
    = & \{[\id_{M_{(A'\tensor B')\tensor C'}},\assoc_{M_A,M_B,M_C}]_*(s)\suchthat s\in (\sigma\tensor\tau)\tensor\upsilon\} \\
    = & \left\{[\id_{M_{(A'\tensor B')\tensor C'}},\assoc_{M_A,M_B,M_C}]_*(s) \,\middle|\,\mbox{\pbox{\textwidth}{
      $s\in P_{((A'\tensor B')\tensor C')\implies ((A \tensor B) \tensor C)}$\\
      $s\vert_{A',A}\in\sigma$, $s\vert_{B',B}\in\tau$, $s\vert_{C',C}\in\upsilon$
    }}\right\} \\
    = & \{s\in P_{((A'\tensor B') \tensor C') \implies (A \tensor (B \tensor C))} \suchthat s\vert_{A',A}\in\sigma,s\vert_{B',B}\in\tau,s\vert_{C',C}\in\upsilon\} \\
    = & \left\{[\assoc_{M_{A'},M_{B'},M_{C'}},\id_{M_{A\tensor (B\tensor C)}}]_*(s) \,\middle|\,\mbox{\pbox{\textwidth}{
      $s\in P_{(A'\tensor (B'\tensor C'))\implies (A \tensor (B \tensor C))}$\\
      $s\vert_{A',A}\in\sigma$, $s\vert_{B',B}\in\tau$, $s\vert_{C',C}\in\upsilon$
    }}\right\} \\
    = & \{[\assoc_{M_{A'},M_{B'},M_{C'}},\id_{M_{A\tensor (B\tensor C)}}]_*(s)\suchthat s\in \sigma\tensor (\tau\tensor \upsilon)\} \\
    = & \cc_{\assoc_{M_{A'},M_{B'},M_{C'}}};(\sigma\tensor(\tau\tensor\upsilon))\,.\hspace{1pt plus 1fill} \qedhere
  \end{IEEEeqnarray*}
\end{proof}

Then, by Proposition \ref{PropCopycat} again, these natural transformations satisfy the same coherence diagrams (pentagon, triangles, hexagon etc.) satisfied by the original associators, unitors and symmetry in $(\Set,+)$.  

It follows that $\tensor$ makes $\G$ into a symmetric monoidal category.

\section{$\G$ as a Symmetric Monoidal Closed Category}

\begin{definition}
  Let $A,B,C,D$ be games, let $\sigma$ be a strategy for $A\implies B$ and let $\tau$ be a strategy for $C\implies D$.  
  Then we define a strategy $\sigma\implies \tau\from (B\implies C) \implies (A\implies D)$ by
  \[
    \sigma\implies \tau = \{s\in P_{(B\implies C) \implies (A \implies D)}\suchthat \text{$s\vert_{A,B}\in\sigma$, $s\vert_{C,D}\in\tau$}\}\,.
    \]
\end{definition}

\begin{proposition}
  $\sigma\implies\tau$ is a strategy for $(B\implies C) \implies (A \implies D)$.
  \label{PropImpliesWellDefined}
\end{proposition}
\begin{proof}
  $\sigma\implies\tau$ is certainly a prefix-closed subset of $P_{(B\implies C)\implies (A \implies D)}^{\textit{even}}$.
  
  We examine the sign configuration of a play in $(B\implies C)\implies (A\implies D)$, using Lemma \ref{LemCompositionLemma}.  
  Since we must avoid the configuration $OP$ in either $B\implies C$, $A\implies D$ or in $(B\implies C)\implies (A\implies D)$, we arrive at the following list of possibilities.
  \scriptsize
  \[
\arraycolsep=2.6pt\def\arraystretch{1.5}
    \begin{array}{cccc|cc|c}
      \lambda_B^{OP}(s\vert_B) & \lambda_C^{OP}(s\vert_C) & \lambda_A^{OP}(s\vert_A) & \lambda_D^{OP}(s\vert_D) & \lambda_{B\implies C}^{OP}(s\vert_{B,C}) & \lambda_{A\implies D}^{OP}(s\vert_{A,D}) & \lambda_{(B\implies C)\implies (A\implies D)}^{OP}(s) \\
      \hline
      P & O & P & O & O & O & P \\
      P & P & P & O & P & O & O \\
      O & O & P & O & P & O & O \\
      P & P & P & P & P & P & P \\
      O & O & O & O & P & P & P \\
      P & P & O & O & P & P & P \\
      O & O & P & P & P & P & P
    \end{array}
    \]
  \normalsize
  If $s\in\sigma\implies\tau$, then we can immediately discount the last two of these possibilities, since one includes the illegal configuration $OP$ in $A\implies B$, and the other includes the illegal configuration $OP$ in $B\implies D$.

  By examining the remaining possibilities, we arrive at the conclusion that any $O$-position in configuration $PPPO$ constrains player $P$ to play in $C$ (to reach configuration $POPO$) or to play in $D$ (to reach configuration $PPPP$), and that any $O$-position in configuration $OOPO$ constrains player $P$ to play in $A$ (to reach configuration $OOOO$) or to play in $C$ (to reach configuration $POPO$).  

  Now suppose that $sab,sac\in\sigma\implies\tau$.  
  Then, by our above analysis, $b$ and $c$ must either both take place in the $B,A$-component, in which case $b = c$ by determinism of $\sigma$, or both in the $C,D$-component, in which case $b = c$ by determinism of $\tau$.  
\end{proof}

To prove that $\sigma\implies\tau$ is innocent if $\sigma$ and $\tau$ are, we need a lemma analogous to Lemma \ref{LemTensorViewLemma}.

\begin{lemma}
  Let $s\in \sigma\implies \tau$.  

  i) If $s$ ends with a move in $A$ or $B$, then $\pv{s}^{(B\implies C) \implies (A\implies D)} = \pv{s\vert_{A,B}}^{A\implies B}$.  

  ii) If $s$ ends with a move in $C$ or $D$, then $\pv{s}^{(B\implies C) \implies (A\implies D)} = \pv{s\vert_{C,D}}^{C\implies D}$.
  \label{LemImpliesViewLemma}
\end{lemma}
\begin{proof}
  Exactly the same as in Lemma \ref{LemTensorViewLemma}, using the analysis from the proof of Proposition \ref{PropImpliesWellDefined} to show that player $P$ only switches moves between $A$ and $B$, and between $C$ and $D$, in $\sigma\implies\tau$.
\end{proof}

\begin{proposition}
  Let $\sigma\from A \implies B$, $\tau\from C\implies D$ be innocent strategies.  
  Then $\sigma\implies\tau$ is innocent.
\end{proposition}
\begin{proof}
  Suppose $sab,t\in\sigma\implies\tau$ such that $ta\in P_{(B\implies C)\implies (A \implies D)}$ and $\pv{sa}=\pv{ta}$.  
  Suppose without loss of generality that $a$ is a move in $A$ or $B$.  
  Then $\pv{sa}=\pv{sa\vert_{A,B}}$ and $\pv{ta}=\pv{ta\vert_{A,B}}$ by Lemma \ref{LemImpliesViewLemma}, and therefore $tab\vert_{A,B}\in\sigma$ by innocence of $\sigma$, and so $tab\in\sigma\implies\tau$.
\end{proof}

We now need to prove that $\implies$ is a functor $\oppcat\G\times\G\to\G$.

\begin{proposition}
  Let $\sigma'\from A''\implies A'$, $\sigma\from A'\implies A$, $\tau'\from B'' \implies B'$ and $\tau\from B'\implies B$ be strategies.  
  Then $(\sigma\implies\tau');(\sigma'\implies\tau) = (\sigma';\sigma)\implies(\tau';\tau)$.

  Moreover, if $A',A,B',B$ are games, $f$ is a structural isomorphism from $A'$ to $A$ and $g$ is a structural isomorphism from $B'$ to $B$, then $\cc_f\implies\cc_g = \cc_{[f\inv,g]}$.
  In particular, if $A,B$ are games than $\id_A\implies\id_B=\id_{A\implies B}$.
\end{proposition}
\begin{proof}
  As in Proposition \ref{PropTensorProductIsFunctor}.
\end{proof}

Now it is easy to see that the associator $\assoc_{M_A,M_B,M_C}$ is a structural isomorphism from $(A\tensor B) \implies C$ to $A\implies (B\implies C)$, so it induces a copycat isomorphism $\Lambda_{A,B,C}=\cc_{\assoc_{M_A,M_B,M_C}} \from (A\tensor B) \implies C \to A \implies (B\implies C)$.

\begin{proposition}
  $\Lambda_{A,B,C}$ is natural in $A,B,C$.
\end{proposition}
\begin{proof}
  The same argument as in Proposition \ref{PropCoherencesAreNatural}.
\end{proof}

We have proved the following.

\begin{theorem}
  $\G$ is a symmetric monoidal closed category, with tensor product given by $\tensor$ and internal hom given by $\implies$.
\end{theorem}

\section{Products in $\G$}

\begin{proposition}
  Given some family $A_i$ of games, the game $\prod_i A_i$, as defined in Definition \ref{DefProduct}, is the category-theoretic product of the $A_i$.
  \label{PropProductOfGames}
\end{proposition}
\begin{proof}
  We have natural injections $\inj_j \from M_{A_j} \hookrightarrow M_{\prod_i A_i}$ giving rise to subset inclusions.  
  Then our projections are given by the morphisms 
  \[
    \pr_j \coloneqq \subs_{\inj_j}\from \prod_i A_i \to A_j\,.
    \]
  Now suppose we have some game $B$, and strategies $\sigma_i \from B \implies A_i$ for each $i$.
  Define a strategy
  \[
    \langle \sigma_i \rangle = \bigcup_i [\id_{M_B},\inj_i]_*(\sigma_i)\,.
    \]
  We claim that this is indeed a strategy for $B \implies \prod_i A_i$.
  Indeed, it is certainly a prefix-closed subset of $P_{C\implies\prod_i A_i}$.

  Moreover, if $sab,sac\in\langle \sigma_i \rangle$, then there is some unique $j$ such that $a$ comes from a move in $A_j$, and therefore $sab,sac$ are both plays in $\sigma_j$, so $b=c$.

  Next, we claim that $\langle\sigma_i\rangle;\pr_j = \sigma_j$.  
  Indeed, we have
  \begin{IEEEeqnarray*}{rCl?u}
    \langle\sigma_i\rangle;\pr_j & = & \langle\sigma_i\rangle;\subs_{\inj_j} \\
    & = & \{[\id_{M_B},\inj_j\inv]_*(s)\suchthat s\in\langle\sigma_i\rangle,\,s\vert_{\prod_iAi}\in(\inj_j)_*(P_{A_j})\} & \textit{Prop. \ref{PropCopycat}} \\
    & = & \sigma_j\,.
  \end{IEEEeqnarray*}
  Lastly, suppose $\tau\from B\implies\prod_iA_i$ is a strategy such that $\tau;\pr_j=\sigma_j$ for each $j$.
  We claim that $\tau=\langle\sigma_i\rangle$.
  Indeed, by the argument above, we must have
  \[
    \{[\id_{M_B},\inj_j\inv]_*(s)\suchthat s\in\tau,\,s\vert_{\prod_iA_i}\in(\inj_j)_*(P_{A_j})\} = \sigma_j
    \]
  for each $j$.
  Suppose that $s\in\tau$.  
  Then $s\vert_{\prod_iA_i}\in(\inj_j)_*(P_{A_j})$ for some $j$, by the definition of $\prod_iA_i$.  
  Therefore, $s\in[\id_{M_B},\inj_j]_*(\sigma_j)$.  

  Conversely, let $t\in \sigma_j$.  
  By the above equation, we know that there is some $s\in\tau$ such that $s\vert_{\prod_iA_i}\in(\inj_j)_*(P_{A_j})$ and $[\id_{M_B},\inj_j\inv]_*(s)=t$.  
  It follows that $[\id_{M_B},\inj_j]_*(t)=s\in\tau$.
\end{proof}

An examination of the definitions tells us that
\begin{proposition}
  Let $A_i,B$ be games and let $\phi_i$ be tree embeddings from $A_i$ to $B$.  
  Then $\langle \zz_{\phi_i} \rangle = \zz_\phi$, where $\phi$ is the tree embeddings from $\prod_iA_i$ to $B$ given by
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      \phi_i(s\vert_{A_i}) & \text{if $s$ starts with a move from $A_i$}
    \end{cases}
    \]
  \label{PropProductOfTreeEmbeddings}
\end{proposition}
\begin{proof}
  The only thing we really need to check is that this is indeed a tree embedding.  
  Let $sb,sc$ be positions in $\prod_iA_i$, where $b,c$ are $P$-moves.
  Then $sb,sc$ must start with the same move, so if $\phi(sb)=\phi(sc)$ then we have $\phi_i(sb)=\phi_i(sc)$ for some $i$ and therefore $b=c$.
\end{proof}

Note that $\langle\sigma_i\rangle$ is not in general innocent, even if all the $\sigma_i$ are, and there is no version of Proposition \ref{PropProductOfTreeEmbeddings} that works for subset inclusion strategies.
Of course, since a subset inclusion is a special case of a tree embedding, then $\langle \subs_i\rangle$ is always a tree embedding strategy.

\section{Sequoidal categories}

We have now given the category-theoretic properties of all the connectives from chapter \ref{SecConnectives}, with the exception of the sequoid $\sequoid$ and the exponential $\oc$.

We would like to say that $\blank\sequoid\blank$ is a functor from $\G \times \G \to \G$, as is the case with the tensor product $\blank\tensor\blank$.  
However, this does not quite work: given strategies $\sigma\from A \implies B$ and $\tau\from C \implies D$, we may not get a well-formed strategy for $(A \sequoid C) \implies (B \sequoid D)$ by `playing according to $\sigma$ in $A$ and $B$ and according to $\tau$ in $C$ and $D$'.  
The reason is that the constraint that player $O$ plays in $B$ before $D$ is not strong enough to force player $P$ to play in $A$ before $C$; indeed, suppose that $\sigma$ tells player $P$ to respond to an initial move in $B$ with another move in $B$.  
Suppose that player $O$ then decides to make a move in $D$.  
If $\tau$ tells player $P$ to respond to this move in $D$ with a move in $C$, then she will be stuck, unable to play this move because no move has yet been played in $A$.

We can fix this problem by imposing some constraints on the strategies $\sigma$ and $\tau$.  
The problem occurs when player $O$'s initial move in $B$ is not reflected by an initial move by player $P$ in $A$; therefore, if $\sigma$ is such that player $P$ always responds to the initial move in $B$ with a move in $A$, then we can form a strategy $\sigma\sequoid\tau$ for $(A\sequoid C)\implies (B\sequoid D)$.  
Moreover, this strategy $\sigma\sequoid\tau$ will inherit this property that the first move on the right is always replied to by a move on the left.

\begin{definition}
  Let $A,B$ be games.  
  A \emph{strict morphism} from $A$ to $B$ is a strategy $\sigma$ for $A\implies B$ such that any player $P$ response to an opening move in $B$ is a move in $A$; i.e., such that if $b$ is an initial $O$-move in $B$ and $ba\in\sigma$, then $a$ is a move in $A$.
\end{definition}

We will call such a $\sigma$ a \emph{strict strategy} for $A\implies B$, although this is a slight abuse of language, since the definition depends on the constituent games $A$ and $B$, which may not be recoverable from $A\implies B$.

It is clear that the composition of strict morphisms is again a strict morphism , as is any morphism of the form $\subs_i$, and so we get a wide subcategory $\G_s$ of $\G$ whose objects are games and where the morphisms are the strict strategies.
We then have a natural inclusion functor $J\from \G_s\to \G$.  

\begin{definition}
  Given games $A,B,C,D$, a strict morphism $\sigma\from A \implies B$ and a strategy $\tau\from C\implies D$, we define a strict morphism $\sigma\sequoid\tau\from (A \sequoid C)\implies (B \sequoid D)$ by
  \[
    \sigma\sequoid\tau = \{s\in P_{(A\sequoid C)\implies (B\sequoid D)}\suchthat s\vert_{A,B}\in\sigma,\,s\vert_{C,D}\in\tau\}\,.
    \]
  \label{DefSequoidOfStrategies}
\end{definition}

\begin{proposition}
  $\sigma\sequoid\tau$ is a strategy.  
\end{proposition}
\begin{proof}
  $\sigma\sequoid\tau$ is certainly a prefix-closed subset of $P_{(A\sequoid C)\implies (B\sequoid D)}$.  
  Moreover, if $sab,sac\in\sigma\sequoid\tau$, then $sab,sac\in\sigma\tensor\tau$, so $b=c$.  
\end{proof}

Of course, $P_{A\sequoid B}$ is a subset of $P_{A\tensor B}$, which means that the identity function $M_A + M_B \to M_A + M_B$ gives us a subset inclusion from $A \sequoid B$ to $A \tensor B$, and hence a strategy $\subs_{\id_{M_A+M_B}}$ for $A\tensor B \implies A \sequoid B$, which we shall refer to as $\wk_{A,B}$.  

\begin{proposition}
  Let $A,B,C,D$ be games, let $\sigma\from A \implies B$ be a strict strategy and let $\tau\from C \implies D$ be a strategy.  
  Then the following diagram commutes.
  \[
    \begin{tikzcd}
      A \tensor C \arrow[r, "\sigma\tensor\tau"] \arrow[d, "{\wk_{A,C}}"']
        & B \tensor D \arrow[d, "{\wk_{B,D}}"] \\
      A \sequoid C \arrow[r, "\sigma\sequoid\tau"]
        & B \sequoid D
    \end{tikzcd}
    \]
  \label{PropWkCommutativeDiagram}
\end{proposition}
\begin{proof}
  By Proposition \ref{PropCopycat} and the definition of $\wk$, we know that
  \begin{IEEEeqnarray*}{rCl}
    \sigma\tensor\tau;\wk_{B,D} & = & \{s\in \sigma\tensor\tau,\,s\vert_{B,D}\in P_{B\sequoid D}\}
    \\
    \wk_{A,C};\sigma\sequoid\tau & = & \sigma\sequoid\tau\,,
  \end{IEEEeqnarray*}
  as sets of plays.

  Now we know that $\sigma\sequoid\tau = \{s\in\sigma\tensor\tau\suchthat s\in P_{(A\sequoid C)\implies (B\sequoid D)}\}$, so it suffices to show that if $s\in\sigma\tensor\tau$ is such that $s\vert_{B,D}\in P_{B\sequoid D}$ then $s\in P_{(A\sequoid C)\implies (B\sequoid D)}$.

  Indeed, if $s\vert_{B,D}\in P_{B\sequoid D}$ then $s$ begins with an initial $O$-move in $B$.  
  Then, \emph{since $\sigma$ is strict}, the next move in $s$ must be a move in $A$, and therefore $s\vert_{A,C}$ begins with a move in $A$.
  Since we also have $s\vert_{A,C}\in P_{A\tensor C}$, we must have that $s\vert_{A,C}\in P_{A\sequoid C}$.
\end{proof}
\begin{remark}
  This is the main place where we have used the assumption that $\sigma$ is a strict strategy: if we drop the strictness requirement from Definition \ref{DefSequoidOfStrategies}, then we get a valid (if nonsensical) strategy that has a partiality (`gives up') if playing according to $\sigma$ and $\tau$ would lead to it creating an invalid play.  
  But such a strategy would not satisfy the conclusion of Proposition \ref{PropWkCommutativeDiagram}, since $\sigma\tensor\tau;\wk_{B,D}$ would contain these extra plays where $\wk_{A,C};\sigma\sequoid\tau$ had `given up'.
\end{remark}
\begin{remark}
  Of course, we would \emph{like} to restate Proposition \ref{PropWkCommutativeDiagram} by saying that $\wk$ is some sort of natural transformation, but that doesn't make sense until we've shown that $\blank\sequoid\blank$ is a functor.
\end{remark}

\begin{proposition}
  If we have strict strategies $\sigma'\from A'' \implies A'$ and $\sigma\from A' \implies A$, and strategies $\tau' \from B'' \implies B'$ and $\tau \from B' \implies B$, then we have
  \[
    (\sigma'\sequoid\tau');(\sigma\sequoid\tau) = (\sigma';\sigma)\sequoid(\tau';\tau)\,.
    \]
  If $A',A,B',B$ are games, $i$ is a subset inclusion from $A$ into $A'$ and $j$ is a subset inclusion from $B$ into $B'$, then
  \[
    \subs_i\sequoid\subs_j = \subs_{[i,j]}\from A'\sequoid B' \implies A \sequoid B\,.
    \]
  In particular, if $A,B$ are games, then $\id_A\sequoid\id_B=\id_{A\sequoid B}$.
  \label{PropSequoidIsFunctor}
\end{proposition}
\begin{proof}
  Let $A'',A',A,B'',B',B$ and $\sigma',\sigma,\tau',\tau$ be as above.  

  We have
  \begin{IEEEeqnarray*}{rCl?u}
    \wk_{A'',B''};(\sigma'\sequoid\tau');(\sigma\sequoid\tau) & = & (\sigma'\tensor\tau');\wk_{A',B'};(\sigma\sequoid\tau) & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
    & = & (\sigma'\tensor\tau');(\sigma\tensor\tau);\wk_{A,B} & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
    & = & ((\sigma';\sigma)\tensor(\tau';\tau));\wk_{A,B} & \textit{Prop. \ref{PropTensorProductIsFunctor}} \\
    & = & \wk_{A'',B''};((\sigma';\sigma)\sequoid(\tau';\tau))\,. & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
  \end{IEEEeqnarray*}
  By Proposition \ref{PropSubsetInclusionEpic}, $\wk_{A'',B''}$ is an epimorphism, and therefore we have that
  \[
    (\sigma'\sequoid\tau');(\sigma\sequoid\tau) = (\sigma';\sigma)\sequoid(\tau';\tau)\,.
    \]

  Now let $A',A,B',B$ be games, let $i$ be a subset inclusion from $A$ into $A'$ and let $j$ be a subset inclusion from $B$ into $B'$.  
  Then, since subset inclusion strategies are automatically strict, we have
  \begin{IEEEeqnarray*}{rCl?u}
    \wk_{A',B'};(\subs_i\sequoid\subs_j) & = & (\subs_i\tensor\subs_j);\wk_{A,B} & \textit{Prop. \ref{PropWkCommutativeDiagram}} \\
    & = & \subs_{[i,j]};\wk_{A,B} & \textit{Prop. \ref{PropTensorProductIsFunctor}} \\
    & = & \subs_{[i,j]} & \textit{Prop. \ref{PropCopycat}} \\
    & = & \wk_{A',B'};\subs_{[i,j]}\,. & \textit{Prop. \ref{PropCopycat}} \\
  \end{IEEEeqnarray*}
  As before, we know from Proposition \ref{PropSubsetInclusionEpic} that $\wk_{A',B'}$ is an epimorphism, and so
  \[
    \subs_i\sequoid\subs_j = \subs_{[i,j]}\,.\qedhere
    \]
\end{proof}

Proposition \ref{PropSequoidIsFunctor} tells us that $\blank\sequoid\blank$ is a functor $\G_s\times\G\to \G$.  
As before, write $J$ for the inclusion functor $\G_s\hookrightarrow\G$.
Then we can restate Proposition \ref{PropWkCommutativeDiagram} in a more \emph{natural} way.

\begin{proposition}
  $\wk_{A,B}$ is a natural transformation $JA \tensor B \to J(A \sequoid B)$.
  \label{PropWkNatural}
\end{proposition}

We have some additional structure on the $\tensor$ and $\sequoid$ operators.  
By inspecting the definitions that if $A,X,Y$ are games then the associator $\assoc_{M_A,M_X,M_Y}$ and unitor $\runit_{M_A}$ in $(\Set,+)$ give rise to structural isomorphisms
\begin{mathpar}
  (A \sequoid X) \sequoid Y \cong A \sequoid (X \tensor Y)
  \and
  A \cong A \sequoid I\,.
\end{mathpar}
Indeed, in the first case, both games are the game in which $A$, $X$ and $Y$ are played in parallel, but where the first move must take place in $A$.  
In the second case, we have $A\sequoid I=A\tensor I$, because there are no moves in $I$ anyway, and the copycat morphism induced from the right unitor in $(\Set,+)$ is the same strategy as the right unitor $A \toisom A \tensor I$.

We formalize the structure we have uncovered so far in the concept of a \emph{sequoidal category}.

\begin{definition}[\cite{laird02}]
  A \emph{sequoidal category} $\C$ is given by
  \begin{itemize}
    \item a symmetric monoidal category $(\C,\tensor, I)$ (with coherences $\assoc,$ $\lunit$, $\runit$, $\sym$);
    \item a (strong) right action of $\C$ on a category $\C_s$; i.e., a functor $\blank\sequoid\blank\from\C_s\times\C\to\C_s$ together with natural isomorphisms
      \begin{mathpar}
        \passoc_{a,x,y}\from (a \sequoid x) \sequoid y \toisom a \sequoid (x \tensor y)
        \and
        \run_a \from a \toisom a \sequoid I
      \end{mathpar}
      that make the diagrams
      \begin{mathpar}
        \begin{tikzcd}[column sep=31pt]
          ((a \sequoid x) \sequoid y) \sequoid z \arrow[r, "{\passoc_{a,x,y}\sequoid z}" yshift=1pt] \arrow[d, "{\passoc_{a\sequoid x,y,z}}"' description]
            & (a \sequoid (x \tensor y)) \sequoid z \arrow[r, "{\passoc_{a,x\tensor y,z}}" yshift=1pt]
              & a \sequoid ((x\tensor y) \tensor z)  \arrow[dl, "{a \sequoid \assoc_{x,y,z}}"] \\
          (a \sequoid x) \sequoid (y \tensor z) \arrow[r, "{\passoc_{a,x,(y\tensor z)}}" yshift=1pt]
            & a \sequoid (x \tensor (y \tensor z))
              &
        \end{tikzcd}
        \and
        \begin{tikzcd}
          a \sequoid x \arrow[r, "{a \sequoid \lunit_x}"] \arrow[d, "\run_a \sequoid x"']
            & a \sequoid (I \tensor x) \\
          (a \sequoid I) \sequoid x \arrow[ur, "{\passoc_{a,I,x}}"']
            &
        \end{tikzcd}
        \and
        \begin{tikzcd}
          a \sequoid x \arrow[r, "{a \sequoid \runit_x}"] \arrow[d, "\run_{a \sequoid x}"']
            & a \sequoid (x \tensor I) \\
          (a \sequoid x) \sequoid I \arrow[ur, "{\passoc_{a,x,I}}"']
            &
        \end{tikzcd}
      \end{mathpar}
      commute; and
    \item a lax morphism of actions from $\blank\sequoid\blank$ to the right tensor multiplication action $\blank\tensor\blank$ of $\C$ on itself; i.e., a functor $J\from \C_s \to \C$ and a natural transformation $\wk_{a,x} \from Ja \tensor x \to J(a \sequoid x)$ that makes the following diagrams commute.
      \begin{mathpar}
        \begin{tikzcd}[column sep=30pt]
          (Ja \tensor x) \tensor y \arrow[r, "{\wk_{a,x}\tensor y}"] \arrow[d, "{\assoc_{Ja,x,y}}"'] & J(a \sequoid x) \tensor y \arrow[r, "{\wk_{a\sequoid x,y}}"]
              & J((a \sequoid x) \sequoid y) \arrow[dl, "{J\passoc_{a,x,y}}"] \\
          Ja \tensor (x \tensor y) \arrow[r, "{\wk_{a,x\tensor y}}"]
            & J(a \sequoid (x \tensor y))
              &
        \end{tikzcd}
        \and
        \begin{tikzcd}
          Ja \arrow[r, "J\run_a"] \arrow[d, "\runit_{Ja}"']
            & J(a \sequoid I) \\
          Ja \tensor I \arrow[ur, "{\wk_{a,I}}"']
            &
        \end{tikzcd}
      \end{mathpar}
  \end{itemize}
  \label{DefSequoidalCategory}
\end{definition}
\begin{remark}
  The definitions of \emph{lax action} can be found at the start of chapter \ref{SecParametricMonads}, whie that of an \emph{oplax morphism of actions} is found at Definition \ref{DefOplaxMorphismOfActions}.  
  The definitions we have used are similar: a \emph{strong action} is a lax action in which the coherences (called $m$ and $e$ in chapter \ref{SecParametricMonads} and $\passoc$ and $\run$ here) are isomorphims.  
  A \emph{lax morphism of actions} is defined in the same way as an oplax morphism, except that the coherence (called $\mu$ in Definition \ref{DefOplaxMorphismOfActions} and $\wk$ here) goes in the opposite direction.
\end{remark}

\begin{proposition}
  The monoidal category $\G$, together with the category $\G_s$, the natural transformations
  \begin{mathpar}
    \passoc_{A,X,Y} = \cc_{\assoc_{M_A,M_X,M_Y}} \from (A \sequoid X) \sequoid Y \toisom A \sequoid (X \tensor Y)
    \and
    \run_A = \cc_{\runit_{M_A}} \from A \toisom A \sequoid I\,,
  \end{mathpar}
  the inclusion functor $J\from \G_s \to G$ and the natural transformation
  \begin{mathpar}
    \wk_{A,X}=\subs_{j} \from JA \tensor X = A \tensor X \to A \sequoid X = J(A \sequoid X)
  \end{mathpar}
  form a sequoidal category.
\end{proposition}
\begin{proof}
  We have shown most of this already; all that remains is to show that $\passoc$ and $\run$ are natural transformations and that the five diagrams in Definition \ref{DefSequoidalCategory} commute.  

  Let us start with the diagrams.  
  By Proposition \ref{PropCopycat}, commutativity of these diagrams follows from commutativity of the diagrams formed from the corresponding subset inclusion functions in $\Set$.  
  For example, to show that the first diagram commutes in $\G$, we must show that the following diagram commutes in $\Set$.
  \scriptsize
  \[
    \begin{tikzcd}[column sep=16pt, row sep=30pt]
      ((M_A + M_X) + M_Y) + M_Z \arrow[r, "{[\assoc_{M_A,M_X,M_Y},\id_{M_Z}]}" yshift=3pt] \arrow[d, "{\assoc_{M_A+M_X,M_Y,Z}}" description]
        & (M_A + (M_X + M_Y)) + M_Z \arrow[r, "{\assoc_{M_A,M_X+M_Y,M_Z}}" yshift=3pt]
          & M_A + ((M_X + M_Y) + M_Z) \arrow[dl, "{[\id_{M_A},\assoc_{M_X,M_Y,M_Z}]}"] \\
      (M_A + M_X) + (M_Y + M_Z) \arrow[r, "{\assoc_{M_A,M_X,M_Y+M_Z}}" yshift=3pt]
        & M_A + (M_X + (M_Y + M_Z))
          &
    \end{tikzcd}
    \]
  \normalsize
  This diagram is, of course, none other than the pentagram diagram for the coproduct $+$ in $\Set$.  
  Similarly, the second and third diagrams in Definition \ref{DefSequoidalCategory} reduce in this case to the triangle diagrams for the coproduct $+$ in $\Set$.

  For the fourth diagram in Definition \ref{DefSequoidalCategory}, since $\wk$ is a subset inclusion strategy induced from an identity map, Proposition \ref{PropCopycat} tells us that both arms of the diagram are the strategy induced by the subset inclusion 
  \[
    \assoc_{M_A,M_X,M_Y}\from (M_A + M_X) + M_Y \to M_A + (M_X + M_Y)
    \]
  from $(A \tensor X) \tensor Y$ to $A \sequoid (X \tensor Y)$.
  Similarly, both arms of the last diagram in Definition \ref{DefSequoidalCategory} are the strategies induced by the subset inclusion $\runit_{M_A} \from M_A \to M_A + \emptyset$ from $A$ to $A \sequoid I$.

  It now remains only to show that $\passoc$ and $\run$ are natural transformations.  
  For $\passoc$, suppose that $A',X',Y',A,X,Y$ are games, that $\sigma\from A'\implies A$ is a strict strategy and that $\tau\from B'\implies B,\upsilon\from C'\implies C$ are strategies.  
  Then we need to show that the following diagram commutes.
  \[
    \begin{tikzcd}[column sep=50pt]
      (A' \sequoid X') \sequoid Y' \arrow[r, "{\passoc_{A',X',Y'}}"] \arrow[d, "(\sigma\sequoid\tau)\sequoid\upsilon"']
        & A' \sequoid (X' \tensor Y') \arrow[d, "\sigma\sequoid (\tau\tensor\upsilon)"] \\
      (A \sequoid X) \sequoid Y \arrow[r, "{\passoc_{A,X,Y}}"]
        & A \sequoid (X \tensor Y)
    \end{tikzcd}
    \]
  Indeed, we have
  \begin{IEEEeqnarray*}{rCl?u}
    && (\wk_{A',X'}\tensor Y');\wk_{A'\sequoid X',Y'};\passoc_{A',X',Y'};(\sigma\sequoid(\tau\tensor\upsilon)) \\
    & = & \assoc_{A',X',Y'};\wk_{A',X'\tensor Y'};(\sigma\sequoid(\tau\tensor\upsilon)) & (see above) \\
    & = & \assoc_{A',X',Y'};(\sigma\tensor(\tau\tensor\upsilon));\wk_{A,X\tensor Y} & \textit{Prop. \ref{PropWkNatural}} \\
    & = & ((\sigma\tensor\tau)\tensor\upsilon);\assoc_{A,X,Y};\wk_{A,X\tensor Y} & \textit{Prop. \ref{PropCoherencesAreNatural}} \\
    & = & ((\sigma\tensor\tau)\tensor\upsilon);(\wk_{A,X}\tensor Y);\wk_{A\sequoid X,Y};\passoc_{A,X,Y} & (see above) \\
    & = & (\wk_{A',X'}\tensor Y');((\sigma\sequoid\tau)\tensor\upsilon);\wk_{A\sequoid X,Y};\passoc_{A,X,Y} & \textit{Prop. \ref{PropWkNatural}} \\
    & = & (\wk_{A',X'}\tensor Y');\wk_{A'\sequoid X',Y'};((\sigma\sequoid\tau)\sequoid\upsilon);\passoc_{A,X,Y}\,. & \textit{Prop. \ref{PropWkNatural}}
  \end{IEEEeqnarray*}
  Now observe that $\wk_{A',X'}\tensor Y=\subs_{[\id_{M_{A'}+M_{X'}},\id_{M_{Y'}}]}$ by Proposition \ref{PropTensorProductIsFunctor}, so it is an epimorphism by Proposition \ref{PropSubsetInclusionEpic}.  
  Proposition \ref{PropSubsetInclusionEpic} also tells us that $\wk_{A'\sequoid X',Y'}$ is an epimorphism.  
  Therefore, we have
  \[
    \passoc_{A',X',Y'};(\sigma\sequoid(\tau\tensor\upsilon)) = ((\sigma\sequoid\tau)\sequoid\upsilon);\passoc_{A,X,Y}
    \]
  for any $A',X',Y',A,X,Y,\sigma,\tau,\upsilon$ as above.  
  It follows that $\passoc$ is a natural transformation.

  The proof that $\run$ is a natural transformation is similar.  
  Let $A',A$ be games and let $\sigma\from A'\implies A$ be a strict strategy.  
  We need to show that the following diagram commutes.
  \[
    \begin{tikzcd}
      A' \arrow[r, "\run_{A'}"] \arrow[d, "\sigma"']
        & A' \sequoid I \arrow[d, "\sigma\sequoid I"] \\
      A \arrow[r, "\run_A"]
        & A \sequoid I
    \end{tikzcd}
    \]
  Indeed, we have
  \begin{IEEEeqnarray*}{rCl?u}
    \run_{A'};(\sigma\sequoid I) & = & \runit_{A'};\wk_{A',I};(\sigma\tensor I) & (see above) \\
    & = & \runit_{A'};(\sigma\tensor I);\wk_{A,I} & \textit{Prop. \ref{PropWkNatural}} \\
    & = & \sigma;\runit_A;\wk_{A,I} & \textit{Prop. \ref{PropCoherencesAreNatural}} \\
    & = & \sigma;\run_A\,. & (see above)
  \end{IEEEeqnarray*}

  Therefore, $\run$ is a natural transformation, which completes our check of the criteria required by Definition \ref{DefSequoidalCategory}.
\end{proof}

\section{Tree Embeddings and Zigzag Strategies}

So far, the strategies we have been considering have all been innocent.  
We now start considering some non-innocent strategies.

We can generalize the subset inclusions of the previous chapter to \emph{tree embeddings}.  
Tree embeddings are similar to subset inclusions, but generated by a function between plays, rather than between moves.  
A consequence of this is that while tree embeddings do give rise to strategies, these strategies are not in general innocent.

\begin{definition}
  Let $A,B$ be games.  
  A \emph{tree embedding} from $A$ to $B$ is a function $\phi\from P_A \hookrightarrow P_B$ such that
  \begin{itemize}
    \item $\phi$ preserves length and justification indices; 
    \item for all sequences $s,t\in P_A$, if $t\prefix s$ then $\phi(t)\prefix\phi(s)$; and
    \item if $\phi(sb)=\phi(sc)$, where $b,c$ are $P$-moves in $A$, then $b=c$.
  \end{itemize}

  Given a tree embedding $\phi$ from $A$ to $B$, we define a strategy $\zz_\phi\from B \implies A$ by
  \[
    \zz_\phi = \{s\in P_{B\implies A}\suchthat\text{for all even-length $t\prefix s$, $t\vert_B=\phi(t\vert_A)$}\}\,.
    \]
\end{definition}
\begin{example}
  If $i$ is a subset inclusion from $A$ to $B$, then $i_*$ is a tree embedding from $A$ to $B$ and $\zz_{i_*}=\subs_i$.
\end{example}

\begin{proposition}
  $\zz_\phi$ is a strategy.  
\end{proposition}
\begin{proof}
  $\zz_\phi$ is a prefix-closed subset of $P_{B\implies A}$ by definition.  
  If $sab,sac\in\zz_\phi$, then we have $s\vert_B=\phi(s\vert_A)$ and $sab\vert_B=\phi(sab\vert_A)$.
  Since $\phi$ is length-preserving, $s\vert_A$ and $s\vert_B$ must have the same length, and the same is true of $sab\vert_A$ and $sab\vert_B$.  
  Therefore, either $a$ is a move in $A$ and $s\vert_Bb=\phi(s\vert_Aa)$ or $a$ is a move in $B$ and $s\vert_Ba=\phi(s\vert_Ab)$.  
  The same applies to $c$: so either $s\vert_Bb=\phi(s\vert_Aa)=s\vert_Bc$ or $\phi(s\vert_Ab)=s\vert_Ba=\phi(s\vert_Ac)$.  
  In either case, we have $b=c$.
\end{proof}

We want an analogue of Proposition \ref{PropCopycat}.

\begin{definition}
  Given a tree embedding from $A$ to $B$, and a play $s\in P_{C\implies A}$ for some $C$, we write $s^\phi$ for the play obtained by replacing the moves of $s\vert_A$ wholesale with the moves of $\phi(s\vert_A)$ (using the fact that $\phi$ preserves length and justification indices).
\end{definition}

\begin{proposition}
  If $\sigma\from C \implies B$ is a strategy, then $\sigma;\zz_\phi$ is given by
  \[
    \{s\in P_{C\implies A}\suchthat s^\phi\in\sigma\}\,.
    \]

  In particular, if $\phi$ is a tree embedding from $A$ to $B$ and $\psi$ is a tree embedding from $B$ to $C$, then $\psi\circ\phi$ is a tree embedding from $A$ to $C$ and $\zz_{\psi\circ\phi}=\zz_\psi;\zz_\phi$.
  \label{PropTree}
\end{proposition}
\begin{proof}
  Suppose that $\s\in\sigma\|\zz_\phi$.  
  Then $\s\vert_{C,B}\in\sigma$ and $t\vert_B=\phi(t\vert_A)$ for all even-length $t\prefix \s\vert_{B,A}$.  
  Then it is clear that $(\s\vert_{C,A})^\phi=\s\vert_{C,B}$.  

  Conversely, suppose that $s\in P_{C\implies A}$ and that $s^\phi\in\sigma$.  
  We construct a sequence $\s\in\sigma\|\zz_phi$ such that $\s\vert_{C,B}=s^\phi$ and $\s\vert_{C,A}=s$ by taking the sequence $s$ and inserting, in order, the elements of the sequence $\phi(s\vert_A)$ immediately after each $O$-move in $s\vert_C$ and immediately before each $P$-move in $C$, leaving the rest of $s$ intact.  
  Then $\s\vert_{C,B}=s^\phi\in\sigma$ and $\s\vert_{B,A}\in\zz_\phi$, by construction.  
  So $s=\s\vert_{C,A}\in \sigma;\zz_\phi$.
\end{proof}

\begin{definition}
  We say that a tree embedding $\phi$ is a \emph{tree isomorphism} if it is a bijection.
\end{definition}

\begin{proposition}
  If $\phi$ is a tree isomorphism from a game $A$ to a game $B$, then $\zz_\phi$ is an isomorphism in $\G$.
\end{proposition}
\begin{proof}
  If $\phi$ is a tree isomorphism, then its inverse $\phi\inv$ is also a tree isomorphism, and Proposition \ref{PropTree} tells us that $\zz_\phi$ and $\zz_{\phi\inv}$ are inverses in $\G$.
\end{proof}

More generally:

\begin{proposition}
  If $\phi$ is a surjection, then $\zz_\phi$ is a monomorphism.
  \label{PropZigzagMono}
\end{proposition}
\begin{proof}
  Let $\sigma,\tau\from C \implies B$ be strategies.
  Then, by Proposition \ref{PropTree}, we have
  \[
    \{s\in P_{C\implies A}\suchthat s^\phi\in\sigma\} = \{s\in P_{C\implies A}\suchthat s^\phi\in\tau\}\,.
    \]
  Let $t\in\sigma$.  
  Then, since $\phi$ is surjective, there is some $u\in P_A$ such that $\phi(u)=t\vert_B$.  
  As before, we may construct some sequence $t'$ such that $t'\vert_A=u$ and $t=(t')^\phi$.  
  Then, since $(t')^\phi=t\in\sigma$, we must have $(t')^\phi\in\tau$; i.e., that $t\in\tau$.  
  So $\sigma\subset\tau$.  
  
  Similarly, $\tau\subset\sigma$, and so $\sigma$ and $\tau$ are equal.
\end{proof}

\section{Sequoidally decomposable categories}

We will now consider some important additional category-theoretic properties of the sequoid operator on games that do not follow from the fact that $\G$ is a sequoidal category.

\begin{definition}[\cite{martinsthesis}]
  Let $\C$ be a sequoidal category such that $C_s$ has arbitrary products (including a terminal object $1$).
  We say that $\C$ is \emph{distributive} if whenever $a_i$ is a collection of objects of $\C'$ and $x$ is an object of $\C$, the morphism
  \[
    \dec_{(a_i),x} = \langle \pr_i\sequoid x \rangle \from \prod_ia_i \sequoid x \to \prod_i (a_i \sequoid x)
    \]
  is an isomorphism.
\end{definition}
\begin{remark}
  In particular, taking $(a_i)$ to be the empty collection, the morphism $\lun_x = () \from 1 \sequoid x \to 1$ is an isomorphism.
\end{remark}

\begin{proposition}
  $\G$ is a distributive sequoidal category.
\end{proposition}
\begin{proof}
  Let $(A_i),X$ be games.
  By Proposition \ref{PropProductOfTreeEmbeddings}, the morphism $\langle \pr_i\sequoid X\rangle$ is given by the tree embedding $\phi\from P_{\prod_i(A_i\sequoid X)}\to P_{\prod_iA_i\sequoid X}$ defined as follows.
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      [\inj_{A_j},\inj_{X}]_*(s) & \text{if $s$ begins with a move in the $j$-th component}
    \end{cases}
    \]
  When we say $[\inj_{A_j},\inj_{X^j}]_*(s)$, we have considered $s$ as a sequence in $(M_{A_j} + M_{X^j})^*$.

  We claim that $\phi$ is a bijection.  
  Indeed, it is certainly injective, since if $\phi(s)=\phi(t)$, then the first move of $\phi(s)=\phi(t)$ occurs in one of the $A_j$, which means that $s,t$ must both come from the $j$-th component.
  Then, if we have a non-empty sequence $s\in P_{\prod_iA_i \sequoid X)}$, then $s$ must start with a move in some $A_j$, and must thereafter take place in the games $A_j$ and $X$.  
  Then $s=\phi([\inj_{A_j},\inj_{X^j}]_*(s))$, where we have considered $s$ as a sequence in $(M_{A_j} + M_{X^j})^*$.

  Therefore, $\phi$ is a tree isomorphism, so $\dec_{(A_i),X} = \zz_\phi$ is an isomorphism by Proposition \ref{PropTree}.
\end{proof}

We can get a distributivity result in the other direction, but this one is not as strong, since the morphism we get is only a monomorphism, not an isomorphism.
\begin{definition}
  Let $\C$ be a distributive sequoidal category.  
  We say that $\C$ is \emph{strongly distributive} if whenever $(A_i),(B_i)$ are objects of $\C_s$, where $(B_i)$ is a non-empty collection, then the morphism
  \[
    \langle A_1 \sequoid(\cdots \sequoid (A_n \sequoid J(\pr_i))\cdots)\rangle
    \]
  is a monomorphism
  \[
    A_1 \sequoid\left(\cdots\sequoid\left(A_n \sequoid J\left(\prod_iB_i\right)\right)\cdots\right) \to \prod_i (A_1 \sequoid (\cdots \sequoid (A_n \sequoid J(B_i))\cdots))\,.
    \]
\end{definition}

\begin{proposition}
  $\G$ is a strongly distributive sequoidal category.
\end{proposition}
\begin{proof}
  By Proposition \ref{PropProductOfTreeEmbeddings}, the morphism $\langle (A_1\sequoid(\cdots\sequoid(A_n \sequoid\pr_i)\cdots))\rangle$ is given by the tree embedding 
  \[
    \phi\from P_{\prod_i (A_1 \sequoid(\cdots\sequoid(A_n\sequoid B_i)\cdots))} \to P_{A_1\sequoid(\cdots\sequoid(A_n\sequoid \prod_iB_i))}
    \]
  defined as follows.
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      [\inj_{A_1,\cdots,A_n},\inj_{B_j}]_*(s) & \parbox[t][][t]{180pt}{if $s$ begins with a move in the $j$-th component}
    \end{cases}
    \]
  Note that $\phi$ is not in general injective, since if $s$ occurs entirely inside one of the copies of the $A_i$, then $\phi(s)=\phi(s')$ for any identical sequence $s'$ occurring inside one of the other copies of the $A_i$.

  We claim that $\phi$ is surjective.  
  Indeed, let $t\in P_{A_1\sequoid(\cdots \sequoid(\prod_i B_i))}$ be a non-empty sequence.  
  If $t$ contains moves in one of the $B_j$, then we have $t=\phi([\inj_{A_i^j},\inj_{B_j}]_*(t))$, where $A_i^j$ is the copy of $A_i$ in the $j$-th component of the product and we have considered $t$ as a sequence in $(M_{A_1} + \cdots + M_{A_n} + M_{B_j})^*$.  
  If $t$ only contains moves in the $A_i$, then pick some fixed index $0$; then we have $t=\phi([\inj_{A_i^0}]_*(t))$, where we have considered $t$ as a sequence in $(M_{A_1} + \cdots + M_{A_n})^*$.

  Therefore, $\phi$ is a monomorphism by Proposition \ref{PropZigzagMono}.
\end{proof}

Note that if $\C$ is decomposable, this property of being a monomorphism is automatically preserved by the tensor product; i.e., for any objects $A,(B_i),C$ of $\C_s$ (for $B_i$ a non-empty collection), the morphism
\[
  \langle JC \tensor J(A \sequoid J(\pr_i))\rangle \from JC \tensor J\left(A \sequoid J\left(\prod_iB_i\right)\right) \to \prod_i JC \tensor J(A \sequoid J(B_i))
  \]
is a monomorphism.

\begin{definition}
  A sequoidal category $\C$ is \emph{inclusive} if $\C_s$ is a full-on-objects subcategory of $\C$ containing $\wk$ and all isomorphisms of $\G$, and the functor $J$ is the inclusion functor.
\end{definition}
In such a situation, we will sometimes drop the mention of the functor $J$.

\begin{proposition}
  $\G$ is an inclusive sequoidal category.
\end{proposition}
\begin{proof}
  The only thing we really need to check is that isomorphisms in $\G$ are always strict strategies.  
  Indeed, if $\sigma$ is a strategy for $A \implies B$ and $\tau$ a strategy for $B \implies A$ such that $\sigma;\tau=\id_A$, then for any opening move $a$ in $A$ on the right of $\tau$ there is some $\s\in\int(A,B,A)$ such that $\s\vert_{A,A}=aa$, and therefore the reply to $a$ in $\tau$ must take place in $B$.
\end{proof}

An important fact about the sequoid operator for games is that it gives us a way to decompose the tensor product as
\[
  A \tensor B \cong (A \sequoid B) \times (B \sequoid A)\,.
  \]
Informally, this is because both sides allow player $O$ to start either in $A$ or in $B$, and thereafter to continue in that game.

\begin{definition}
  Let $\C$ be a distributive inclusive sequoidal category, where $\C$ is a symmetric monoidal category.
  We say that $\C$ is \emph{decomposable} if the morphisms
  \begin{mathpar}
    \dec_{a,b}=\langle \wk_{a,Jb},\sym_{Ja,Jb};\wk_{b,Ja} \rangle \from Ja \tensor Jb \to (a \sequoid Jb) \times (b \sequoid Ja)
    \and
    () \from I \to 1
  \end{mathpar}
  are isomorphisms in $\C_s$.
\end{definition}

\begin{proposition}
  Let $\C$ be a decomposable sequoidal category and suppose that $a_1,\cdots,a_n$ is a list of objects of $\C_s$.  
  Then we have an isomorphism
  \[
    a_1 \tensor \cdots \tensor a_n \cong \prod_{i=1}^n (a_i \sequoid (a_1 \tensor \cdots \tensor a_{i-1} \tensor a_{i+1} \tensor \cdots \tensor a_n))\,.
    \]
  \label{PropDecSeq}
\end{proposition}
\begin{proof}
  Induction on $n$.  
  If $n=0$, then we have the isomorphism $() \from I \to 1$.  
  More generally, we have
  \begin{IEEEeqnarray*}{Cl}
    & a_1 \tensor \cdots \tensor a_{n+1}\\
    \cong & (a_1 \tensor \cdots \tensor a_n) \tensor a_{n+1} \\
    \xrightarrow{\dec} & (a_1 \tensor \cdots \tensor a_n) \sequoid a_{n+1} \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \cong & \left(\prod_{i=1}^n\left(a_i \sequoid \Tensor_{j\ne i}^{j\le n} a_j\right)\right) \sequoid a_{n+1} \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \xrightarrow{\dist\times\id} & \prod_{i=1}^n\left(\left(a_i \sequoid \Tensor_{j\ne i}^{j\le n} a_j \right) \sequoid a_{n+1}\right) \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \xrightarrow{\langle\passoc\rangle\times\id} & \prod_{i=1}^n \left(a_i \sequoid \left(\Tensor_{j\ne i}^{j\le n} a_j \tensor a_{n+1}\right)\right) \times a_{n+1} \sequoid (a_1\tensor \cdots \tensor a_n) \\
    \cong & \prod_{i=1}^{n+1} \left(a_i \times \Tensor_{j\ne i}^{j\le n+1} a_j\right) \times a_{n+1} \sequoid (a_1 \tensor \cdots \tensor a_n) \\
    \cong & \prod_{i=1}^{n+1} (a_i \sequoid (a_1 \tensor \cdots \tensor a_{i-1} \tensor a_{i+1} \tensor \cdots \tensor a_{n+1}))\,,
  \end{IEEEeqnarray*}
  where each of the arrows is an isomorphism.
\end{proof}

The specific isomorphism in Proposition \ref{PropDecSeq} is rather complicated at the moment, but we can simplify it.

\begin{definition}
  Given objects $a_1,\cdots,a_n$ of a monoidal category, we write $\sym_i^n$ for the unique symmetric coherence isomorphism
  \[
    a_1 \tensor \cdots \tensor a_n \cong a_i \tensor a_1 \cdots \tensor a_{i-1} \tensor a_{i+1} \tensor a_n\,.
    \]
\end{definition}

\begin{proposition}
  The isomorphism in the proof of Proposition \ref{PropDecSeq} is given by
  \[
    \dec_{(a_i)}^n = \langle \sym_i^{n};\wk_{a_i,a_1\tensor\cdots\tensor a_{i-1}\tensor a_{i+1}\tensor \cdots\tensor a_n}\rangle\,.
    \]
  \label{PropDecSeqFormula}
\end{proposition}
\begin{proof}
  Induction on $n$.
  We will make use of the coherence theorem for symmetric monoidal categories \cite[\sec 11]{WorkingMathematician} to allow us to elide associators.  
  The base case is obviously true, because $()\from I \to 1$ is the unique morphism between these objects.  
  Otherwise, we observe that the morphism into $\prod_{i=1}^{n+1} \left(a_i \sequoid \Tensor_{j\ne i}^{j\le n+1} a_j\right)$ is given component-wise by morphisms $a_1 \tensor \cdots \tensor a_{n+1} \to a_i \sequoid \Tensor_{j\ne i}^{j\le n+1}$ for each $i=1,\cdots,n+1$; we need to check that each of these components is equal to $\sym_i^{n+1};\wk_{a_i,\Tensor_{j\ne i}a_j}$.

  If $i\le n$, then the $i$-th component of the morphism in the proof of Proposition \ref{PropDecSeq} is given by the composite thick dashed arrows in Figure \ref{FigDecSeqFormula}, and is therefore equal to the composite of the solid arrows, which is equal to $\sym_i^{n+1};\wk_{a_i,\Tensor_{j\ne i}a_j}$ as desired.  
  The $n+1$-th component of the morphism in the proof of Proposition \ref{PropDecSeq} is given by the composite
  \small
  \[
    \Tensor_{j=1}^{n+1}a_j \to \Tensor_{j=1}^n a_j \tensor a_{n+1} \xrightarrow{\sym_{\Tensor_{j=1}^na_j,a_{n+1}}} a_{n+1} \tensor \Tensor_{j=1}^n a_j \xrightarrow{\wk_{a_{n+1},\Tensor_{j=1}^n a_j}} a_{n+1} \sequoid \Tensor_{j=1}^n a_j\,,
    \]
  \normalsize
  and then we use the fact that the leftmost two morphisms in this composite compose to give us $\sym_{n+1}^{n+1}$.
  \begin{SidewaysFigure}
    \[
      \begin{tikzcd}[ampersand replacement=\&, column sep=6pt, row sep=30pt]
        \Tensor_{j=1}^{n+1}a_j \arrow[r, thick, dashed] \arrow[dd, "\sym_i^{n+1}"']
          \& \Tensor_{j=1}^n a_j \tensor a_{n+1} \arrow[r, "{\wk_{\Tensor_{j=1}^na_j,a_{n+1}}}", thick, dashed] \arrow[d, "\sym_i^n\tensor a_{n+1}" description, dotted]
            \&[45.5pt] \Tensor_{j=1}^n a_j \sequoid a_{n+1} \arrow[d, "\sym_i^n\sequoid a_{n+1}", thick, dashed]
              \&[31pt] \\
        %
          \& \left(a_i \tensor \Tensor_{j\ne i}^{j\le n} a_j\right)\tensor a_{n+1} \arrow[r, "{\wk_{a_i\tensor\Tensor_{j\ne i}^{j\le n} a_j,a_{n+1}}}" xshift=-10pt, dotted] \arrow[d, "{\assoc_{a_i,\Tensor_{j\ne i}^{j\le n}a_j,a_{n+1}}}" description, dotted] \arrow[dr, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n}a_j}\tensor a_{n+1}}" description, dotted]
            \& |[alias=Z]| \left(a_i \tensor \Tensor_{j\ne i}^{j\le n} a_j\right)\sequoid a_{n+1} \arrow[dr, from=Z.east, bend left=25, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n}a_j}\sequoid a_{n+1}}", thick, dashed]
              \& \\
        a_i \tensor \Tensor_{j\ne i}^{j\le n+1} a_j \arrow[ddrrr, bend right=15, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n+1}a_j}}"']
          \& a_i \tensor \left(\tensor_{j\ne i}^{j\le n}a_j \tensor a_{n+1}\right) \arrow[l, dotted] \arrow[drr, to=Y.west, bend right=10, "{\wk_{a_i,\Tensor_{j\ne i}^{j\le n}a_j\tensor a_{n+1}}}" description, dotted]
            \& \left(a_i \sequoid \Tensor_{j\ne i}^{j\le n}\right)\tensor a_{n+1} \arrow[r, "{\wk_{a_i\sequoid \Tensor_{j\ne i}^{j\le n},a_{n+1}}}" xshift=-10pt, dotted]
              \& \left(a_i \sequoid \Tensor_{j\ne i}^{j\le n} a_j\right) \sequoid a_{n+1} \arrow[d, "{\passoc_{a_i,\Tensor_{j\ne i}^{j\le n}a_j,a_{n+1}}}" {description, yshift=2pt}, thick, dashed] \\
        %
          \&
            \&
              \& |[alias=Y]| a_i \sequoid \left(\Tensor_{j\ne i}^{j\le n} a_j \tensor a_{n+1}\right) \arrow[d, thick, dashed] \\
        %
          \&
            \&
              \& a_i \sequoid \Tensor_{j\ne i}^{j\le n+1}a_j
      \end{tikzcd}
      \]
    \caption[Diagram used in the proof of Proposition \ref{PropDecSeqFormula}]{Diagram used in the proof of Proposition \ref{PropDecSeqFormula}.  
    The pentagon at the heart of the diagram is the coherence diagram for $\passoc$ and $\wk$ from Definition \ref{DefSequoidalCategory}.}
    \label{FigDecSeqFormula}
  \end{SidewaysFigure}
\end{proof}

\begin{proposition}
  $\G$ is a decomposable sequoidal category.
\end{proposition}
\begin{proof}
  Let $A,B$ be games.  
  By Proposition \ref{PropProductOfTreeEmbeddings}, the strategy 
  \[
    \langle \wk_{A,B},\sym_{A,B};\wk_{A,B}\rangle
    \]
  is given by the tree embedding $\phi$ from $(A \sequoid B) \times (B \sequoid A)$ to $A \tensor B)$ given by
  \[
    \phi(s) = \begin{cases}
      \epsilon & \text{if $s=\epsilon$} \\
      s\vert_{A \sequoid B} & \text{if $s$ takes place entirely within $A\sequoid B$} \\
      s\vert_{B \sequoid A} & \text{if $s$ takes place entirely within $B\sequoid A$}
    \end{cases}\,.
    \]
  We claim that this tree embedding is a bijection.  
  Indeed, it is certainly injective.
  Now let $s\in P_{A\tensor B}$ be a non-empty play.  
  Then, if $s$ begins with a move in $A$, we have $s=\phi((\inj_{A\sequoid B})_*(s))$, and if $s$ begins with a move in $B$, we have $s=\phi((\inj_{B\sequoid A})_*(s)$.  
  Therefore, $\phi$ is a tree isomorphism, so $\dec_{A,B}=\zz_\phi$ is an isomorphism in $\G$.

  Lastly, we have $I=1$ in $\G$, and the unique morphism $I\to 1$ is the identity.
\end{proof}

\begin{definition}[\cite{laird02}]
  A \emph{sequoidal closed category} is an inclusive sequoidal category $\C$ such that $\C$ is a monoidal closed category (with inner hom $\implies$) and such that the map $f\mapsto \Lambda(\wk_{A,B};f)$ defines an isomorphism
  \[
    \Lambda_s \from \C_s(A \sequoid B,C) \toisom \C_s(A,B\implies C)\,.
    \]
\end{definition}

\begin{proposition}
  $\G$ is a sequoidal closed category.
\end{proposition}
\begin{proof}
  Since $\wk_{A,B}$ is an epimorphism and $\Lambda$ is a bijection, the map is certainly injective.  
  Showing that it is surjective comes down to proving that uncurrying of a strict strategy for $A\implies (B \implies C)$ is a strict strategy for $(A\sequoid B) \implies C$.
  Indeed, after the opening move in $C$, in both cases player $P$ must play the next move in $A$.
\end{proof}

\section{A Formula for the Exponential}

\begin{definition}
  Let $\C$ be a symmetric monoidal category.  
  Given objects $A_1,\cdots,A_n$ of $\C$ and a permutation $\pi\in \S_n$, there is a unique canonical symmetry isomorphism
  \[
    \sym^\pi \from A_1 \tensor \cdots \tensor A_n \toisom A_{\pi(1)} \tensor \cdots \tensor A_{\pi(n)}\,.
    \]
  Given an object $A$ of $\C$, an \emph{$n$-th symmetrized tensor power} of $A$ is an equalizer $(A^n,\eq^n)$ for the diagram given by all morphisms of the form
  \[
    \sym_\pi \from A ^{\tensor n} \to A ^{\tensor n}\,.
    \]
  We say that the symmetrized tensor power $A^n$ \emph{commutes with the tensor product} if $(B\tensor A^n,B\tensor \eq_n)$ is an equalizer for the diagram given by morphisms of the form
  \[
    B\tensor\sym_\pi \from B\tensor A ^{\tensor n} \to B\tensor A ^{\tensor n}\,.
    \]
\end{definition}

\begin{proposition}[\cite{CalcoPaper}]
  Let $\C$ be an inclusive, strongly distributive, decomposable sequoidal category.  
  Then $\C$ has all symmetrized tensor powers.
  \label{PropSequoidPower}
\end{proposition}
\begin{proof}
  Let $A$ be an object of $\C$ (equivalently, an object of $\C_s$).  
  We inductively define objects $A^{\sequoid n}$ by
  \begin{itemize}
    \item $A^{\sequoid 0} = I$; and
    \item $A^{\sequoid (n+1)}=J(A\sequoid A^{\sequoid n})$.
  \end{itemize}
  We claim that $A^{\sequoid n}$ is a symmetrized tensor power of $A$.

  Given $n$, we inductively define a morphism $\wk^n\from A^{\tensor n} \to A^{\sequoid n}$, where $\wk^0=\id_I$, and $\wk^{n+1}$ is given by the composite
  \[
    A^{\tensor (n+1)} \to A \tensor A^{\tensor n} \xrightarrow{A \tensor \wk^n} A \tensor A^{\sequoid n} \xrightarrow{\wk_{A,A^{\sequoid n}}} A \sequoid A^{\sequoid n}\,.
    \]
  We show by induction on $n$ that if $B$ is an object of $\C$ and $k\ge 0$ then the composite
  \scriptsize
  \begin{mathpar}
    B\tensor (A \sequoid\blank)^kA^{\tensor n}
    \xrightarrow{\langle B\tensor(A \sequoid\blank)^k \sym^\pi \rangle}
    (B\tensor(A \sequoid\blank)^kA^{\tensor n})^{n!}
    \xrightarrow{(B\tensor(A\sequoid\blank)^k\wk^n)^{n!}}
    (B\tensor A^{\sequoid (k+n)})^{n!}
  \end{mathpar}
  \normalsize
  (i.e., the morphism $\langle B\tensor(A\sequoid\blank)^k(\sym^\pi;\wk^n)\rangle$) is a monomorphism.
  In particular, taking $k=0$, we will have shown that $\langle B\tensor (\sym^\pi;\wk^n)\rangle$ is a monomorphism.

  The hypothesis is clearly true for $n=0$; in the general case, we have a composite
  \begin{mathpar}
    B\tensor (A\sequoid\blank)^kA^{\tensor (n+1)}
    \xrightarrow{B\tensor (A\sequoid\blank)^k\langle \sym^{n+1}_i;\wk_{A,A^{\tensor n}}\rangle}
    B\tensor (A \sequoid\blank)^k(A\sequoid A^{\tensor n})^{n+1}
    \xrightarrow{\langle B\tensor (A\sequoid\blank)^k;\pr_i\rangle}
    (B\tensor(A \sequoid\blank)^{k+1} A^{\tensor n})^{n+1}
    \to
    (B\tensor A ^{\sequoid (k + n + 1)})^{(n+1)!}\,,
  \end{mathpar}
  where the last arrow is the tensor product of $B$ with the $(n+1)$-th power of the composite given by
  \footnotesize
  \[
    (A \sequoid\blank)^{k+1}A^{\tensor n}
    \xrightarrow{\langle (A \sequoid \blank)^{k+1}\sym^\sigma\rangle}
    ((A \sequoid\blank)^{k+1}A^{\tensor n})^{n!}
    \xrightarrow{((A \sequoid\blank)^{k+1}\wk^n)^{n!}}
    (A^{\sequoid (k+n+1)})^{n!}\,,
    \]
  \normalsize
  which is a monomorphism by the induction hypothesis.
  Then the previous composite is the composite of monomorphisms (by our assumptions on $\C$), and is therefore itself a monomorphism.  
  Now this composite may be written as
  \[
    \langle B\tensor(A\sequoid\blank)^k(\sym_i^{n+1};\wk_{A,A^{\tensor n}};(A\sequoid\sym^\sigma);(A\sequoid\wk^n)) \rangle\,,
    \]
  which, since $\wk$ is a natural transformation, is equal to
  \[
    \langle B\tensor(A \sequoid\blank)^k(\sym_i^{n+1};(A\tensor\sym^\sigma);(A\tensor\wk^n);\wk_{A,A^{\sequoid n}})\rangle\,,
    \]
  where $\sigma$ ranges over the permutations in $\S_n$.
  Moreover, by the definition of $\wk^n$, this is equal to
  \[
    \langle B\tensor(A \sequoid\blank)^k(\sym_i^{n+1};(A \tensor \sym^\sigma);\wk^{n+1}\rangle\,.
    \]

  Now, given $i\in\{1,\cdots n+1\}$ and $\sigma\in\S_n$, there is a unique permutation $\pi\in\S_{n+1}$ such that $\sym_i^{n+1};(A\tensor\sym^\sigma=\sym^\pi)$; moreover, this defines a bijection from $\{1,\cdots,n+1\}\times\S_n \to \S_{n+1}$.  
  Therefore (after choosing an appropriate enumeration of our permutations), we see that this composite is in fact equal to
  \[
    \langle B\tensor(A \sequoid\blank)^k (\sym^\pi;\wk^{n+1})\rangle\,.
    \]
  Therefore, $\langle B\tensor(A \sequoid\blank)^k(\sym^\pi;\wk^{n+1})\rangle$ is a monomorphism as desired, completing the induction.

  Next, we define morphisms $\eq_n\from A^{\sequoid n} \to A^{\tensor n}$ inductively, where $\eq_0=\id$ and $\eq_{n+1}$ is defined by the following composite
  \[
    A^{\sequoid (n+1)} = A\sequoid A^{\sequoid n} \xrightarrow{\langle (A\sequoid \eq_n)_1^n\rangle} (A \sequoid A^{\tensor n})^n \cong A^{\tensor (n+1)}\,,
    \]
  where the final isomorphism is as in Propositions \ref{PropDecSeq} and \ref{PropDecSeqFormula}.

  First, we show inductively that $\eq_n;\sym^\pi;\wk^n=\id_{A^{\sequoid n}}$ for all permutations $\pi$ of $S_n$.
  This is certainly true for $n=0$; in the general case, let $\pi\in \S_{n+1}$ be a permutation.  
  Let $j=\pi\inv(1)$ be the element sent to $1$ by $\pi$ and let $\sigma$ be the permutation of $1,\cdots,n$ such that applying $\sigma$ to the elements $2,\cdots,n+1$ and composing with $\pi$ gives us the $j$-cycle $(1\,\dots\,j)$.  
  Then we have
  \[
    \sym_j^{n+1};(A\tensor\sym^\sigma) = \sym^\pi\,.
    \]
  Now we get
  \begin{IEEEeqnarray*}{Cl}
    & \eq_{n+1};\sym^\pi;\wk^{n+1} \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\sym^\pi;(A \tensor \wk^n);\wk_{A,A^{\sequoid n}} \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\sym_j^{n+1};(A\tensor\sym^\sigma);(A \tensor \wk^n);\wk_{A,A^{\sequoid n}} \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\sym_j^{n+1};\wk_{A,A^{\tensor n}};(A \sequoid \sym^\sigma);(A \sequoid \wk^n) \\
    = & \langle (A \sequoid \eq_n)_1^n\rangle;(\dec_{\vec A}^{n+1})\inv;\langle \sym_i^{n+1};\wk_{A,A^{\tensor n}}\rangle;\pr_j;(A \sequoid \sym^\sigma);(A \sequoid \wk^n) \\
    = & A \sequoid (\eq_n;\sym^\sigma;\wk^n)\,,
  \end{IEEEeqnarray*}
  which is equal to the identity on $A^{\sequoid (n+1)}$ by the induction hypothesis.

  Now let $\rho$ be a permutation in $\S_n$.  
  We claim that $\eq_n=\eq_n;\sym^{\rho}$.  

  Indeed, we have
  \begin{IEEEeqnarray*}{rCl}
    \eq_n;\langle \sym^{\pi} ; \wk^n \rangle
    & = & \langle \eq_n;\sym^{\pi};\wk^n \rangle \\
    & = & \langle \id \rangle \\
    & = & \langle \eq_n;\sym^{\rho\pi};\wk^n \rangle \\
    & = & \eq_n;\sym^{\rho};\langle \sym^\pi ; \wk^n \rangle\,.
  \end{IEEEeqnarray*}
  Since $\langle \sym^\pi;\wk^n\rangle$ is a monomorphism, this means that $\eq_n=\eq_n;\sym^{\rho}$, as desired.
  Therefore, $\eq_n$ equalizes the morphisms $\eq_n$.  
  We claim that it is an equalizer, and that this equalizer is preserved by the tensor product.

  Indeed, let $B,C$ be objects of $\C$, and let $f \from C \to B \tensor A^{\tensor n}$ be a morphism such that $f=f;(B\tensor\sym^{\pi})$ for all $\pi\in\S_n$.

  Let $\tilde f = f;(B \tensor \wk^n)\from C \to B \tensor A^{\sequoid n}$.  
  We claim that $\tilde f;(B\tensor\eq_n)=f$; indeed, we have
  \begin{IEEEeqnarray*}{rCl}
    \tilde f;(B \tensor\eq_n);\langle B\tensor(\sym^\pi;\wk^n)\rangle 
    & = & \langle f;(B \tensor (\wk^n;\eq_n;\sym^\pi;\wk^n)) \rangle \\
    & = & \langle f;(B\tensor \wk^n)\rangle \\
    & = & f;\langle B \tensor (\sym^\pi;\wk^n)\rangle\,.
  \end{IEEEeqnarray*}
  Therefore, since $\langle B \tensor (\sym^\pi;\wk^n)\rangle$ is a monomorphism, we know that $\tilde f;(B\tensor \eq_n)=f$.

  Now suppose that $h\from C \to B \tensor A^{\sequoid n}$ is such that $h;(B\tensor eq_n)=f$.  
  We claim that $h=\tilde f$.  
  Indeed, we have 
  \[
    \tilde f = f;(B \tensor \wk^n) = h;(B \tensor \eq_n);(B \tensor \wk^n) = h\,.
    \]
  Therefore, $(B\tensor A^{\sequoid n},B\tensor \eq_n)$ is an equalizer of the arrows $B\tensor \sym^\pi\from B \tensor A^{\tensor n} \to B \tensor A^{\tensor n}$, as desired.
\end{proof}

We are interested in symmetrized tensor powers because of an important result of \Mellies, Tabareau and Tasson.
Suppose $\C$ is a monoidal category, and that $\C$ has symmetrized tensor powers that commute with the tensor product.  
Given $n$, we have a morphism
\[
  A^{\tensor n}\tensor() \from A^{\tensor (n+1)} \to A^{\tensor n}\,,
  \]
where $()$ is the unique morphism into the terminal object.  
Then, if $A^n$ and $A^{n+1}$ are the $n$-th and $n+1$-th symmetrized tensor powers of $A$, and $\eq_{n+1},\eq$ the corresponding equalization, for any $\pi\in\S_n$ we have a commutative diagram
\[
  \begin{tikzcd}[column sep=50pt]
    B \tensor A^{n+1} \arrow[r, "B\tensor\eq_{n+1}"]
      & B \tensor A^{\tensor (n+1)} \arrow[r, "B\tensor A^{\tensor n}\tensor()"] \arrow[d, "\sym^{\pi'}"']
        & B \tensor A^{\tensor n} \arrow[d, "\sym^\pi"] \\
    %
      & B \tensor A^{\tensor (n+1)} \arrow[r, "B\tensor A^{\tensor n} \tensor()"]
        & B \tensor A^{\tensor n}
  \end{tikzcd}\,,
  \]
where $\pi'$ is the permutation of $1,\cdots,n+1$ that fixes $1$ and applies $\pi$ to the remaining elements $2,\cdots,n+1$.

This means that for each $\pi\in \S_n$ we have
\begin{IEEEeqnarray*}{rCl}
  (B\tensor\eq_{n+1});(B\tensor A^{\tensor n}\tensor ())
  & = & (B \tensor\eq_{n+1});(B\tensor \sym^{\pi'});(B\tensor A^{\tensor n}\tensor ()) \\
  & = & (B\tensor\eq_{n+1});(B\tensor A^{\tensor n}\tensor());(B\tensor \sym^\pi)\,,
\end{IEEEeqnarray*}
and that there is therefore an induced morphism
\[
  B\tensor A^{n+1} \to B \tensor A^n\,,
  \]
by the universal property of the equalizer.

Note also that if $m,n$ are integers, then any permutations $\sigma$ of $1,\cdots,m$ and $\pi$ of $1,\cdots,n$ induce a permutation $[\sigma,\pi]$ of $1,\cdots,m+n$.  
Then we get morphisms
\[
  A^{m+n} \to A^{\tensor (m+n)} \to A^{\tensor m} \tensor A^{\tensor n}\,,
  \]
which are equalized by all symmetries on $A^{\tensor m}$ and $A^{\tensor n}$ individually.  
Since the equalizers $A^m$ and $A^n$ are preserved by the tensor product, then we get an induced morphisms
\[
  A^{m+n}\to A^m\tensor A^n\,.
  \]

\begin{theorem}[\cite{MelliesCofCommCom}]
  Let $\C$ be a monoidal category such that the monoidal unit for $\C$ is a terminal object.
  Suppose that $\C$ has symmetrized tensor powers that commute with the tensor product.  

  Then, for any objects $A,B$ of $\C$, there is a natural sequence
  \[
    B \leftarrow B\tensor A \leftarrow B\tensor A^2 \leftarrow B \tensor A^3 \leftarrow \cdots\,.
    \]
  In particular, there is a sequence
  \[
    I \leftarrow A \leftarrow A^2 \leftarrow A^3 \leftarrow \cdots\,.
    \]
  Suppose that this sequence has a limit $\oc A$, and that $B\tensor \oc A$ is the limit of the first sequence for all $B$.  

  For each $m$, we can define morphisms
  \[
    \oc A \to A^{m+n} \to A^m \tensor A^n
    \]
  for each $n$, which commute with the morphisms $A^{n+1}\to A^n$ and hence induce a morphism $\oc A \to A^m \tensor \oc A$.  
  Then these morphisms themselves commute with the morphisms $A^{m+1}\tensor \oc A \to A^m \tensor \oc A$, and so we get a morphism $\mu_A\from \oc A \to \oc A \tensor \oc A$.
  
  The morphisms $\mu_A\from \oc A \to \oc A \tensor \oc A$ and $()\from A \to I$ give $\oc A$ the structure of a commutative comonoid in $\C$.  
  In fact, this is the \emph{cofree commutative comonoid} over $A$ in $\C$.  
  The counit $\der_A\from \oc A \to A$ of the adjunction is the map in the limiting cone.
  \label{TheMtt}
\end{theorem}

We want to show that this theorem applies in $\G$.
First, we find an explicit formula for the morphisms $B \tensor A^{\sequoid(n+1)}\to B\tensor A^{\sequoid n}$.

\begin{proposition}
  Let $\C$ be an inclusive, strongly distributive, decomposable sequoidal category -- so $\G$ has symmetrized tensor powers preserved by the tensor product as in Proposition \ref{PropSequoidPower}.  

  Then the canonical morphisms $B \tensor A^{\sequoid (n+1)}\to B\tensor A^{\sequoid n}$ are given by
  \[
    B \tensor (A \sequoid \blank)^n()\,,
    \]
  where $() \from A \to I$ is the unique morphism into the terminal object.
\end{proposition}
\begin{proof}
  First, we show by induction on $n$ that the following diagram commutes.
  \[
    \begin{tikzcd}[column sep=30pt]
      A^{\tensor(n+1)} \arrow[r, "A^{\tensor n}\tensor()"] \arrow[d, "A\tensor\wk^{n+1}"']
        & A^{\tensor n} \arrow[d, "\wk^n"] \\
      A^{\sequoid(n+1)} \arrow[r, "(A\sequoid\blank)^n()"]
        & A^{\sequoid n}
    \end{tikzcd}
    \]
  This is clearly true for $n=0$; in the general case, we have the following commutative diagram --
  \[
    \begin{tikzcd}[column sep=41pt]
      A^{\tensor(n+2)} \arrow[r] \arrow[dd, "\wk^{n+2}"']
        & A \tensor A^{\tensor (n+1)} \arrow[r, "A \tensor (A^{\tensor n}\tensor ())"] \arrow[d, "A \tensor \wk^{n+1}"']
          & A \tensor A^{\tensor n} \arrow[r] \arrow[d, "A\tensor \wk^n"]
            & A^{\tensor(n+1)} \arrow[dd, "\wk^{n+1}"] \\
      %
        & A \tensor A^{\sequoid (n+1)} \arrow[r, "A \tensor (A\sequoid\blank)^n()"] \arrow[dl, "{\wk_{A,A^{\sequoid (n+1)}}}" description]
          & A \tensor A^{\sequoid n} \arrow[dr, "{\wk_{A,A^{\sequoid n}}}" description]
            & \\
      A^{\sequoid(n+1)} \arrow[rrr, "(A \sequoid \blank)^{n+1}()"]
        &
          &
            & A^{\sequoid (n+1)}
    \end{tikzcd}\,\text{--}
    \]
  where the middle square is the inductive hypothesis (tensored by $A$), the outer trapezia are the definitions of $\wk^{n+2}$ and $\wk^{n+1}$, and the bottom trapezium commutes because $\wk$ is a natural transformation.

  Now, by the proof of Proposition \ref{PropSequoidPower}, the canonical morphism $B\tensor A^{\sequoid (n+1)} \to B\tensor A^{\sequoid n}$ must be constructed as the composite
  \[
    B \tensor (\eq_{n+1};(A^{\tensor n}\tensor ());\wk^n)\,,
    \]
  which we have shown is equal to
  \[
    B \tensor (\eq_{n+1};\wk^{n+1};(A \sequoid\blank)^n()) = B \tensor (A \sequoid\blank)^n()\,.\qedhere
    \]
\end{proof}

\begin{definition}
  Let $A$ be a game.  
  We say that $A$ is \emph{well-opened} if initial moves of $A$ can only occur as the very first move in a play.
\end{definition}

It is immediate from the definitions that:
\begin{itemize}
  \item the empty game $I$ and our data-type games $\bC,\bB,\bN$ are well opened;
  \item if $A_i$ are well-opened games, then so is $\prod_iA_i$; and
  \item if $B$ is a well-opened game, then so is $A \implies B$;
\end{itemize}
but that $A \tensor B$, $A\sequoid B$ and $\oc A$ are not in general well-opened, even if $A$ and $B$ are.

\begin{proposition}
  Let $A$ be a well-opened game.  
  Then we have natural morphisms
  \[
    \oc A \to A^{\sequoid n}
    \]
  for each $n$, and these commute with the natural morphisms $A^{\sequoid(n+1)}\to A^{\sequoid n}$ and make $\oc A$ the limit of the sequence
  \[
    I \leftarrow A \leftarrow A^{\sequoid 2} \leftarrow A^{\sequoid 3}\leftarrow\cdots\,.
    \]
  Moreover, $B\tensor\oc A$ is the limit of the sequence
  \[
    B \leftarrow B \tensor A \leftarrow B \tensor A^{\sequoid 2} \leftarrow B \tensor A^{\sequoid 3}\leftarrow \cdots\,.
    \]
\end{proposition}
\begin{proof}
  For the sake of notational simplicity, we will only prove the first part of the Proposition, but the second part (the $B\tensor\cdots$ version) goes through in exactly the same way.

  The morphism in question is the (non-innocent) zigzag strategy given by the tree embedding $\phi_n\from P_{A^{\sequoid n}}\to P_{\oc A}$ defined by
  \[
    \phi_n(s) = \nabla_*(s)\,,
    \]
  where $\nabla\from M_A+\cdots + M_A$ is the co-diagonal.

  We have seen already that the natural morphism $A^{\sequoid (n+1)}\to A^{\sequoid n}$ is the copycat morphism generated by the inclusion $n.(M_A) \to (n+1).(M_A)$, and so it is clear that these commute with $\zz_\phi$ by Proposition \ref{PropTree}.

  Now let $C$ be a game and suppose that there are strategies $\sigma_n \from C \implies A^{\sequoid n}$ that commute with the natural morphisms $A^{\sequoid (n+1)} \to A^{\sequoid n}$.  
  Then we define a morphism $\sigma\from C \to \oc A$ by
  \[
    \sigma = \left\{s\in P_{C\implies \oc A} \,\middle|\, \mbox{\pbox{\textwidth}{
      for some $n$, $s\vert_{\oc A}$ contains \\
      at most $n$ initial moves, and \\
      $[\inj,\inj_{A_1},\cdots,\inj_{A_n}]_*(s)\in\sigma_n$.}}\right\}\,.
    \]
  Here we have used the fact that $A$ is well-opened to tell us that $s\vert_{\oc A}$ is indeed a valid play in $A^{\sequoid n}$.

  We claim that $\sigma$ is indeed a strategy.
  First we show that $\sigma$ is prefix closed.  
  If $s\in \sigma$ and $t\prefix s$, write $n$ for the number of initial moves in $s$.  
  Then $t$ has at most $n$ initial moves; if $[\id_C,\inj_{A_1},\cdots,\inj_{A_n}]_*(s)\in\sigma_n$, then $[\id_C,\inj_{A_1},\cdots,\inj_{A_n}]_*(t)\in\sigma_n$, and therefore $t\in\sigma$.

  Now note that if $s\in C_{C\implies \oc A}$ is such that $s\vert_{\oc A}$ contains $k$ initial moves, and if $m,n\ge k$, then
  \[
    [\inj,\inj_{A_1},\cdots,\inj_{A_m}]_*(s) = [\inj_C,\inj_{A_1},\cdots,\inj_{A_n}]_*(s)\,,
    \]
  since the $\sigma_n$ commute with the natural morphisms $A^{\sequoid (n+1)} \to A^{\sequoid n}$.  
  So, if $sab,sac\in\sigma$, then we can assume that
  \[
    [\inj_C,\inj_{A_1},\cdots,\inj_{A_k}]_*(sab),[\inj_C,\inj_{A_1},\cdots,\inj_{A_k}]_*(sac)\in\sigma_k
  \]
  for some common $k$, and therefore that $b=c$.

  Now we have $\sigma;\zz_{\phi_n}=\sigma_n$ for each $n$ by Proposition \ref{PropTree}.

  Suppose that $\tau$ is some other strategy for $C\implies \oc A$ such that $\tau;\zz_{\phi_n}=\sigma_n$ for each $n$.  
  Cy Proposition \ref{PropTree}, we have
  \[
    \sigma_n = \tau;\zz_{\phi_n} = \{s\in P_{C\implies A^{\sequoid n}}\suchthat s^{\phi_n}\in\tau\}\,.
    \]
  Suppose $s\in\sigma$ and that $s$ contains $n$ initial moves.  
  Then 
  \[
    [\inj_C,\inj_{A_1},\cdots,\inj_{A_n}]_*(s)\in\sigma_n
    \]
  for some $n$.  
  Therefore, $s=([\inj_C,\inj_{A_1},\cdots,\inj_{A_n}]_*(s))^{\phi_n}\in\tau$.  
  So $\sigma\subset\tau$.
  
  Conversely, suppose that $t\in\tau$.  
  Suppose that $t\vert_{\oc A}$ contains $n$ initial moves.  
  Then $t=s^{\phi_n}$ for some sequence $s\in P_{C\implies A^{\sequoid n}}$, and we must have $s\in\sigma_n$.  
  Therefore, $t\in\sigma$.  
  So $\tau\subset\sigma$.
\end{proof}

Therefore, by Theorem \ref{TheMtt}, if $A$ is a well-opened game, then $\oc A$ inherits the structure of a cofree commutative comonoid on $A$.

Let $\G_{wo}$ denote the category of well-opened games and strategies.  
Let $\CCom(\G)$ denote the category of commutative comonoids with respect to the symmetric monoidal structure on $\G$.

In general, given two commutative comonoids $M,N$ in a symmetric monoidal category $\C$, we can form the \emph{tensor product}
\begin{mathpar}
  M \tensor N \to (M \tensor M) \tensor (N \tensor N) \to (M \tensor N) \tensor (M \tensor N)
  \and
  M \tensor N \to I \tensor I \to I\,,
\end{mathpar}
and this makes $\CCom(\C)$ into a \emph{Cartesian} category.  

Now note that we have defined a functor
\[
  \G_{wo} \to \CCom(\G)
  \]
which is a right adjoint on to its image, and therefore preserves products.  
So if $A,B$ are well-opened games, then we get a natural isomorphism of comonoids between the tensor product of the comonoids on $\oc A$ and $\oc B$ and the comonoid on $\oc(A\times B)$.
In particular, we have a natural isomorphism
\[
  \oc A \tensor \oc B \cong \oc (A \times B)\,.
  \]
We define a category $\G_{wo}^{\oc}$ to be the image of the functor $\G_{wo}\to \CCom(\G)$ inside $\CCom(\G)$.  
By our discussion above, $\G_{wo}^{\oc}$ is a Cartesian category.  

A more convenient description of $\G_{wo}^{\oc}$ is that it is the category where the objects are well-opened games and where the morphisms
\[
  A \to B
  \]
are morphisms $\oc A \to B$ in the original category $\G$.
We compose two such morphisms $\sigma \from \oc A \implies B$ and $\tau \from \oc B \implies C$ as
\[
  \oc A \xrightarrow{\sigma^\dag} \oc B \xrightarrow{\tau} C\,,
  \]
where the \emph{promotion} $\sigma^\dag$ of $\sigma$ comes from the description of $\oc A$ as the cofree commutative comonoid on $A$.

Since the functor $\G_{wo}\to \CCom(\G)$ preserves products, $\G_{wo}^{\oc}$ obtains a Cartesian structure given by the category-theoretic product $\times$.  
We claim that it is Cartesian closed, with the function object from $A$ to $B$ given by $\oc A \implies B$.  
Indeed, we have
\begin{IEEEeqnarray*}{rCl}
  \G_{wo}^{\oc}(A,\oc B\implies C)
  & \cong & \G(\oc A,\oc B \implies C) \\
  & \cong & \G(\oc A \tensor \oc B,C) \\
  & \cong & \G(\oc(A \times B),C) \\
  & \cong & \G_{wo}^{\oc}(A\times B,C)\,.
\end{IEEEeqnarray*}

We have one thing left to prove.
\begin{proposition}
  Let $\sigma\from \oc A \implies B$, $\tau\from \oc B \implies C$ be innocent strategies, where $A,B,C$ are well-opened games.  
  Then the composite of $\sigma$ and $\tau$ in $\G_{wo}^{\oc}$ is an innocent strategy.
\end{proposition}
\begin{proof}
  We may write this composite as
  \[
    \oc A \xrightarrow{m}
    \oc \oc A \xrightarrow{\oc\sigma}
    \oc B \xrightarrow{\tau}\,,
    \]
  where $\oc\sigma$ is the strategy formed by playing $\sigma$ in parallel with itself, whereas $m\from \oc A \to \oc \oc A$ comes from the fact that $\oc A$ is the cofree commutative comonoid on $A$.
  $\oc \sigma$ is innocent for the same reasons as in Proposition \ref{PropTensorInnocent}, so it suffices to show that $m$ is innocent.  

  Indeed, it is clear from our definitions that $\oc\oc A = \oc A$ as games.  
  Then, $m$ is in fact the identity strategy between these two games, so is innocent.
\end{proof}

\section{The Exponential as a Final Coalgebra}

\begin{definition}
  Let $F \from \C \to \C$ be a functor.  
  A \emph{coalgebra for $F$} or \emph{$F$-coalgebra} is an object $a$ of $\C$, together with a morphism $f\from a \to Fa$.

  A \emph{coalgebra homomophism} from $(a,f)$ to $(b,g)$ is a morphism $h\from a \to b$ such that the following diagram commutes.
  \[
    \begin{tikzcd}
      a \arrow[r, "f"] \arrow[d, "h"']
        & Fa \arrow[d, "Fh"] \\
      b \arrow[r, "g"]
        & Fb
    \end{tikzcd}
    \]

  Clearly, the coalgebras for a given functor $F$ form a category.  
  A \emph{final coalgebra} for $F$ is a terminal object for this category; i.e., an $F$-coalgebra $(t,\alpha)$ such that for all $F$-coalgebras $(a,f)$ there is a unique morphism $\fcoal f \from a \to t$ such that the following diagram commutes.
  \[
    \begin{tikzcd}
      a \arrow[r, "f"] \arrow[d, "\fcoal f"']
        & Fa \arrow[d, "F\fcoal f"] \\
      t \arrow[r, "\alpha"]
        & Ft
    \end{tikzcd}
    \]
\end{definition}
We call $\fcoal f$ the \emph{anamorphism} of $f$.

We use two standard pieces of theory about coalgebras.  

\begin{theorem}[Lambek's Theorem, \cite{Lambek}]
  If $(t,\alpha)$ is a final coalgebra for a functor $F$, then $\alpha\from t \to Ft$ is an isomorphism with inverse given by $\fcoal{F\alpha}$.
\end{theorem}

\begin{theorem}[Ad{\'{a}}mek's Theorem, {\cite{Adamek}}]
  Suppose $\C$ has a terminal object $1$.  
  By repeatedly applying $F$ to the morphism $F1 \to 1$, we build up a sequence
  \[
    1 \leftarrow F1 \leftarrow F^2 1 \leftarrow F^31 \leftarrow \cdots\,.
    \]
  If this sequence has a limit $F^{\omega}1$, and if the morphism $\beta\from F(F^{\omega}1) \to F^{\omega}1$ induced from the univeral property of the limit is an isomorphism, then $(F^{\omega}1,\beta\inv)$ is a final coalgebra for $F$.
\end{theorem}

Now we have already shown that if $A$ is well-opened, then $\oc A$ is the limit of the sequence
\[
  I \leftarrow A \leftarrow A^{\sequoid 2} \leftarrow A^{\sequoid 3} \leftarrow \cdots\,,
  \]
and this sequence is precisely the sequence from Ad{\'a}mek's Theorem, when $F=J(A\sequoid\blank) \from \G \to \G$.
Moreover, this limit is preserved when taking the sequoid with $A$ on the left, and so we get that
\begin{corollary}
  If $A$ is a well-opened game, then $\oc A$ is the final coalgebra for the functor $A \sequoid \blank$.
\end{corollary}
In this case, the morphism $\oc A \to A \sequoid \oc A$ is the zigzag strategy that plays copycat between the different copies of $A$; i.e., $\zz_\phi$, where $\phi\from P_{A\sequoid \oc A} \to P_{\oc A}$ is the tree isomorphism given by
\[
  \phi(s) = [\inj_{M_A},\id]_*(s)\,.
  \]

One small thing we need to do is to relate the two structures on the exponential.

\begin{proposition}
  The final coalgebra
  \[
    \alpha\from \oc A \to A \sequoid \oc A
    \]
  is given by the composite
  \[
    \oc A \xrightarrow{\mu_A} \oc A \tensor \oc A \xrightarrow{\der_A\tensor \oc A} A \tensor \oc A \xrightarrow{\wk_A,\oc A} A \sequoid \oc A\,.
    \]
  \label{PropFormulaForAlpha}
\end{proposition}
\begin{proof}
  By Theorem \ref{TheMtt}, we can tell that this composite is a copycat strategy between $\oc A$ and $A \sequoid \oc A$, as is $\alpha$.  
  Since $A$ is well-opened, there is a unique such strategy.
\end{proof}

\section{Denotational Semantics of Idealized Algol}

We now come to interpret Idealized Algol within our category $\G_{wo}^{\oc}$.  
The base types $\com$, $\bool$ and $\nat$ are interpreted by the games $\bC$, $\bB$ and $\bN$, while the type $\Var$ is interpreted by the game
\[
  \Varr = \bC^{\bN} \times \bN\,,
  \]
where $\bC^{\bN}$ is the product of $\bN$-many copies of $\bC$.
Given types $S,T$, the denotation $\deno{S\to T}$ of the type of functions from $S$ to $T$ is given by
\[
  \deno{S}\to\deno{T} \coloneqq \oc\deno{S}\implies\deno{T}\,.
  \]
This gives us the denotation of the types of Idealized Algol.  

We inductively define a denotation of terms-in-context $\Gamma\ts M$ of IA, where $\deno{x_1\from T_1,\cdots,x_n\from T_n\ts M\from T}$ is a strategy
\[
  \deno{T_1} \times \cdots \times \deno{T_n} \to \deno{T}\,.
  \]
First note that we have natural innocent strategies $a \from \bC$, $\true,\false\from\bB$ and $n \from \bN$, which give us the denotations of $\Gamma\ts\skipp$, $\Gamma\ts\true$, $\Gamma\ts\false$ and $\Gamma\ts n$.

Moreover, if we have a strategy

\[
  \deno{\Gamma,x\from S \ts M\from T} \from \deno{\Gamma}\times\deno{S} \to \deno{T}\,,
  \]
then, since $\G_{wo}^{\oc}$ is Cartesian closed, we get a strategy
\[
  \deno{\Gamma\ts \lambda x^s.M} \from \deno{\Gamma} \to \deno {S} \to \deno{T}\,.
  \]
In addition, we have natural morphisms
\[
  \deno{\Gamma,x\from T\ts x\from T} = \deno{\Gamma}\times\deno{T} \xrightarrow{\pr_{\deno{T}}} \deno{T}\,.
  \]
Lastly, if we have strategies
\begin{mathpar}
  \deno{\Gamma\ts M\from S \to T} \from \deno{\Gamma} \to \deno{S} \to \deno{T}
  \and
  \deno{\Gamma\ts N \from S} \from \deno{\Gamma} \to \deno{S}\,,
\end{mathpar}
then we get a strategy
\[
  \deno{\Gamma\ts MN\from T} = \deno \Gamma \xrightarrow{\Delta} \deno\Gamma\times\deno\Gamma \xrightarrow{\deno{\Gamma\ts M}\times\deno{\Gamma\ts N}} (\deno S \to \deno T) \times \deno S \xrightarrow{\ev} \deno{S}\,.
  \]

In order to form the denotation of the next lot of terms, we need a new definition.
\begin{definition}
  Let $X$ be a set, and let $(\sigma_x\suchthat x\in X)$ be a collection of strategies for a game $A$.  
  Write $X$ for the datatype game corresponding to $X$.  
  Then we define a strict strategy $(\sigma_x) \from X \to A$ by
  \[
    (\sigma_x) = \{\epsilon\}\cup\{*q\suchthat {*}\in P_A\}\cup \{*qys\suchthat {*}s\in\sigma_y\}\,.
    \]
  In other words, after the initial move in $A$, $(\sigma_x)$ requests some element $y\in X$, and thereafter plays according to $\sigma_y$ in $A$.
\end{definition}

\begin{proposition}
  If the $\sigma_x$ are innocent strategies, then $(\sigma_x)$ is an innocent strategy.
\end{proposition}
\begin{proof}
  If $*s\in\sigma_y$, then $\pv{*qysa}=*qy\pv{sa}$.  
  Then, if $t\in(\sigma_x)$ and $\pv{ta}=*qy\pv{sa}$, we have $t=*qyt'$ for $t'\in\sigma_y$ and $\pv{*t'a}=\pv{*sa}$.  
  So if $*sab\in\sigma_y$, then $*t'ab\in\sigma_y$ and therefore $tab\in(\sigma_x)$.
\end{proof}

The most important feature of strategies of the form $(\sigma_x)$ is the most obvious one: given $X$, and $y\in X$, we have a strategy $y$ for the game $X$ with maximal play $qx$.  
Then $y;(\sigma_x) = \sigma_y$.

Now we define morphisms
\begin{itemize}
  \item $\seq_X = (\id_X) \from \bC \to (X \to X)$;
  \item $\If_X = (\lambda x.\lambda y.x,\lambda x.\lambda y.y) \from \bB \to (X \to X \to X)$;
  \item $\suc = (1, 2, 3, 4,\cdots) \from \bN \to \bN$;
  \item $\pred = (0,0,1,2,\cdots)\from \bN \to \bN$;
  \item $\IfO_X = (\lambda x.\lambda y.x,\lambda x.\lambda y.y,\lambda x.\lambda y.y,\cdots)\from \bN \to (X \to X \to X)$;
  \item $\assign = (\pr_0,\pr_1,\cdots) \from \bN \to (\Varr \to \bC)$; and
  \item $\dereff = \pr_\bN \from \Varr \to \bN$;
  \item $\mkvar = \lambda w.\lambda r.\langle (w\,n)_{n\in\bN},r\rangle \from (\bN \to \bC) \to \bN \to \Varr$.
\end{itemize}
These give us an obvious way to interpret most of the rest of the terms of Idealized Algol.  
For example, if we have strategies
\begin{mathpar}
  \deno{\Gamma\ts V\from \Varr}
  \and
  \deno{\Gamma\ts E\from \bN}\,,
\end{mathpar}
then we get a strategy
\[
  \deno{\Gamma\ts V\gets E \from \bC} = \deno{\Gamma} \xrightarrow{\Delta} \deno{\Gamma}\times\deno{\Gamma} \xrightarrow{\deno{\Gamma\ts E}\times\deno{\Gamma\ts V}} \bN \times \Varr \xrightarrow{\assign} \bC\,.
  \]

\section{Order-Enrichment of $\G$}

The remaining parts of Idealized Algol that we have yet to define are the fixpoint combinator $\Y_T$ and the new variable constructor $\neww$.  

To define $\Y_T$, we use order-enriched properties of $\G$.  

Note that if $A$ is a game, then we can order the strategies for $A$ by subset inclusion.  
Then this order is clearly preserved by composition.  

\begin{proposition}
  The partial order of strategies for $A$, ordered by inclusion, is directed-complete.  
  So is the partial order of innocent strategies for $A$.
\end{proposition}
\begin{proof}
  Let $\Sigma$ be a directed set of strategies for $A$; so if $\sigma,\tau\in\Sigma$ then there is some $\upsilon\in\Sigma$ such that $\sigma\subset\upsilon$ and $\tau\subset\upsilon$.  
  We claim that $\bigcup\Sigma$ is a strategy for $A$.  
  Indeed, it is certainly even-prefix-closed, and if $sab,sac\in\Sigma$, then $sab\in\sigma$ and $sac\in\tau$ for $\sigma,\tau\in\Sigma$, and therefore $sab,sac\in\upsilon$ for some $\upsilon\in\Sigma$ and so $b=c$.

  Now suppose that all $\sigma\in\Sigma$ are innocent.
  Let $sab\in\bigcup\Sigma$ and suppose that $t\in \bigcup\Sigma$ is such that $\pv{ta}=\pv{sa}$.  
  Then, as before, we have $sab,t\in\upsilon$ for some innocent $\upsilon\in\Sigma$, and therefore $tab\in\upsilon\subset\bigcup\Sigma$.
\end{proof}

It is clear then that composition of strategies is Scott-continuous with respect to this ordering.

Writing $\bot = \{\epsilon\}$ for the bottom strategy for a game $A$, if we have a strategy $\sigma\from A \to A$, then the Kleene fixed point theorem tells us that we may construct a fixed point for $\sigma$ as the union of the chain
\[
  \bot \subset \bot;\sigma \subset \bot;\sigma;\sigma \subset \cdots\,.
  \]
Given a game $A$, we define a strategy $\Y_A\from (A \to A) \to A$ as the fixed point of the strategy
\[
  \lambda F.\lambda f.f(Ff) \from ((A \to A) \to A) \to (A \to A) \to A\,.
  \]
We can then use $\Y_A$ to interpret the term $\Gamma\ts\Y_TM\from T$ for any term $\Gamma\ts M\from T\to T$.

We will later require other order-theoretic properties of the set of strategies for a game $A$.  
Recall that an element $\sigma$ of a directed-complete partially ordered set is called \emph{compact} if whenever we have $\sigma = \bigcup\Sigma$ for some directed set $\Sigma$, then $\sigma\in\Sigma$.  

A little thought convinces us that a strategy $\sigma\from A$ is compact if and only if it is finite as a set of plays; indeed, suppose $\sigma$ is a finite set and $\sigma=\bigcup\Sigma$.  
For each $s\in\sigma$, we have $s\in\tau_s$ for some $\tau_s\in\Sigma$; since $\Sigma$ is directed, then there is some $\upsilon\in\Sigma$ such that $\tau_s\in\Sigma$ for each $s$, and therefore $\sigma\subset\upsilon\subset\sigma$.
Conversely, if $\sigma$ is infinite, then by K\"{o}nig's lemma, it either has an infinite branching point (i.e., $s\in\sigma$ such that there are infinitely many plays $sab\in\sigma$) or an infinite branch (i.e., an infinite increasing sequence $s_1\prefix s_2\prefix \cdots$ in $\sigma$).  
In either case, it is easy to construct some directed set $\Sigma$ such that $\sigma=\bigcup\Sigma$ but $\sigma\not\in\Sigma$.

Recall that a directed-complete partial order $P$ is said to be \emph{algebraic} if whenever $p\in P$, the set of compact elements of $P$ lying below $p$ is directed and its supremum is $p$.  

\begin{proposition}
  The set of strategies for a game $A$ is an algebraic directed-complete partial order.
\end{proposition}
\begin{proof}
  Let $\sigma$ be a strategy for a game $A$ and let $\tau_1,\tau_2$ be two finite sub-strategies such that $\tau_1,\tau_2\subset\sigma$.  
  Then $\tau_1\cup\tau_2\subset\sigma$ and is finite; moreover, if $sab,sac\in\tau_1\cup\tau_2$, then $sab,sac\in\sigma$, so $b=c$.  

  Lastly, given any $s\in\sigma$, there is a compact strategy $\sigma_s$ containing $s$; namely
  \[
    \sigma_s = \{t\suchthat \text{$t\prefix s$ has even length}\}\,.\qedhere
    \]
\end{proof}

\section{The Strategy $\cell$}
\label{SecCell}

Now we come to the denotation of $\neww$.  
For this, we shall define a strategy $\cell\from \oc\bN \implies \oc \Varr$ by using the property of $\oc \Varr$ as a final coalgebra.

Given $n\in\bN$, we define a strategy $\wwrite_n\from \oc\bN \implies \bC \sequoid\oc\bN$ by
\[
  \wwrite_n = \oc\bN \xrightarrow{()} I \xrightarrow{\skipp\tensor \oc n} \bC \tensor \oc\bN \xrightarrow{\wk} \bC \sequoid\oc\bN\,.
  \]
Let $\rread \from \oc\bN \implies \bN \sequoid \oc\bN$ be the morphism part $\alpha$ of the limiting coalgebra.  
In other words, by Proposition \ref{PropFormulaForAlpha}, $\rread$ is the composite
\[
  \rread = \oc\bN \xrightarrow{\mu_\bN} \oc\bN \tensor \oc\bN \xrightarrow{\der_\bN\tensor\oc\bN} \bN \tensor \oc\bN \xrightarrow{\wk_{\bN,\oc\bN}} \bN \sequoid\oc\bN\,.
  \]
Then we get a coalgebra $\cell_0\from \oc \bN \implies \Varr \sequoid \oc \bN$ given by
\[
  \oc\bN \xrightarrow{\langle (\wwrite_n)_{n\in\bN}, \rread\rangle}
  (\bC \sequoid \oc\bN)^{\bN} \times (\bN \sequoid \oc\bN) \xrightarrow{\dist_{(\bC)_{\bN},\bN,\oc\bN}\inv}
  (\bC^\bN \times \bN) \sequoid \oc\bN = \Varr \sequoid \oc \bN\,.
  \]
We then take the anamorphism $\cell=\fcoal{\cell_0}\from \oc\bN \implies \oc\Varr$; i.e., $\cell$ is the unique morphism making the following diagram commute.
\[
  \begin{tikzcd}
    \oc\bN \arrow[r, "\cell_0"] \arrow[d, "\cell"']
      & \Varr \sequoid \oc\bN \arrow[d, "\Varr \sequoid \cell"] \\
    \oc\Varr \arrow[r, "\alpha_{\Varr}"]
      & \Varr \sequoid \oc\Varr
  \end{tikzcd}
  \]
Concretely, the strategy $\cell$ behaves as follows.  
When player $O$ plays in $\oc\Var$, he chooses to play either in one of the copies of $\bC$ or in $\bN$.  
If he plays the initial move $q_n$ in the $n$-th copy of $\bC$, player $P$ updates the value she has stored in her head to $n$.  
If he plays the initial move $q$ in $\bN$, then player $P$ replies with this stored value.  
Lastly, if he plays this initial move $q$ without having played in any of the copies of $\bC$, then player $P$ interrogates the argument in order to find out which value to play.

This strategy $\cell$ now gives us a morphism $\neww_A \from \oc(\oc\Varr \implies A) \implies A$ given by
\begin{IEEEeqnarray*}{rCl}
  \oc(\oc\Varr\implies A) & \xrightarrow{\mathmakebox[50pt]{\der}} & (\oc\Varr\implies A) \\
  & \xrightarrow{\mathmakebox[50pt]{\lunit}} & I \tensor (\oc\Varr\implies A) \\
  & \xrightarrow{\mathmakebox[50pt]{\oc0\tensor (\oc\Varr\implies A)}} & \oc\bN \tensor (\oc \Varr\implies A) \\
  & \xrightarrow{\mathmakebox[50pt]{\cell\tensor (\oc\Varr\implies A)}} & \oc\Varr \tensor (\oc \Varr \implies A) \\
  & \xrightarrow{\mathmakebox[50pt]{\ev}} & A\,.
\end{IEEEeqnarray*}

We use this to provide the denotation of the term $\neww$.

\begin{lemma}
  $\cell_0;(\pr_n\sequoid\oc\bN) = \wwrite_n$ for each $n$ and $\cell_0;(\pr_\bN\sequoid\oc\bN) = \rread$, where $\pr_n\from \Varr=\bC^\bN \times \bN \implies \bC$ is the projection on to the $n$-th copy of $\bC$ and $\pr_\bN\from \Varr = \bC^\bN \times \bN \implies \bN$ is the projection on to the copy of $\bN$.
  \label{LemCellProjections}
\end{lemma}
\begin{proof}
  We have
  \[
    \dist_{(\bC)_{\bN},\bN,\oc\bN};\pr_n = \langle(\pr_n\sequoid\oc \bN)_{n\in\bN},\pr_{\bN}\sequoid\oc\bN\rangle;\pr_n = \pr_n\sequoid\oc\bN
    \]
  and
  \[
    \dist_{(\bC)_{\bN},\bN,\oc\bN};\pr_\bN = \langle(\pr_n\sequoid\oc \bN)_{n\in\bN},\pr_{\bN}\sequoid\oc\bN\rangle;\pr_\bN = \pr_\bN\sequoid\oc\bN\,,
    \]
  so
  \begin{IEEEeqnarray*}{Cl}
    & \cell_0;(\pr_n\sequoid\oc\bN) \\
    = & \langle (\wwrite_n)_{n\in\bN},\rread \rangle;\dist_{(\bC)_\bN,\bN,\oc\bN}\inv;(\pr_n\sequoid\oc\bN) \\
    = & \langle (\wwrite_n)_{n\in\bN},\rread \rangle ;\dist_{(\bC)_\bN,\bN,\oc\bN}\inv\dist_{(\bC)_\bN,\bN,\oc\bN};\pr_n \\
    = & \langle (\wwrite_n)_{n\in\bN},\rread\rangle;\pr_n \\
    = & \wwrite_n
  \end{IEEEeqnarray*}
  and
  \begin{IEEEeqnarray*}{Cl}
    & \cell_0;(\pr_\bN\sequoid\oc\bN) \\
    = & \langle (\wwrite_n)_{n\in\bN},\rread \rangle;\dist_{(\bC)_\bN,\bN,\oc\bN}\inv;(\pr_\bN\sequoid\oc\bN) \\
    = & \langle (\wwrite_n)_{n\in\bN},\rread \rangle ;\dist_{(\bC)_\bN,\bN,\oc\bN}\inv\dist_{(\bC)_\bN,\bN,\oc\bN};\pr_\bN \\
    = & \langle (\wwrite_n)_{n\in\bN},\rread\rangle;\pr_\bN \\
    = & \rread\,.\hspace{1em plus 1fill}\qedhere
  \end{IEEEeqnarray*}
\end{proof}

\section{Big-Step Operational Semantics}

We now introduce the operational semantics of Idealized Algol, so that we can prove soundness and adequacy of our semantics for it.

We first define a \emph{canonical form} of the language to be
\begin{itemize}
  \item at type $\com$, the term $\skipp$;
  \item at type $\bool$, the terms $\true$ and $\false$;
  \item at type $\nat$, the numerals $n$; 
  \item at type $\Var$, variable names $x$ of type $\Var$ and expressions of the form $\mkvar W\,R$; and
  \item at type $S\to T$, expressions of the form $\lambda x^S.M$.
\end{itemize}

We define a \emph{$\Var$-context} to be a context $\Gamma$ of the form $x_1\from \Var,\cdots,x_n\from \Var$.
Given a $\Var$-context $\Gamma$, we define a \emph{$\Gamma$-store} to be a function $s$ from the variable names occurring in $\Gamma$ to the natural numbers.  
Given such a store $s$, we write $(s\vert x \mapsto n)$ for the store given by
\[
  (s\vert x\mapsto n)(y) = \begin{cases}
    n & \text{if $y = x$} \\
    s(y) & \text{otherwise}
  \end{cases}\,.
  \]
We now inductively define a relation $\Gamma,s\ts M\converges c,s'$, where
\begin{itemize}
  \item $\Gamma$ is a $\Var$-context; 
  \item $s$ and $s'$ are $\Gamma$-stores;  and
  \item $\Gamma\ts M$, $\Gamma\ts c$ are Idealized Algol terms-in-context, where $c$ is a canonical form.
\end{itemize}
The definition of this relation is shown in Figure \ref{FigIaOpSem}.

\begin{figure}
  \vspace{-27pt}
  \begin{mathpar}
    \inferrule*{ }{\Gamma,s\ts c \converges c,s}
    \and
    \inferrule*{\Gamma,s \ts M \converges \lambda x.M',s' \\ \Gamma,s' \ts M'[N/x] \converges c,s''}{\Gamma,s \ts MN \converges c,s''}
    \and
    \inferrule*{\Gamma,s \ts M(\Y M) \converges c,s'}{\Gamma,s \ts \Y M \converges c,s'}
    \and
    \inferrule*{\Gamma,s\ts M \converges n,s'}{\Gamma,s\ts \suc M \converges n+1,s'}
    \\\and
    \inferrule*{\Gamma,s\ts M \converges n+1,s'}{\Gamma,s\ts \pred M \converges n,s'}
    \and
    \inferrule*{\Gamma,s\ts M \converges 0,s'}{\Gamma,s\ts \pred M \converges 0,s'}
    \and
    \inferrule*{\Gamma,s\ts M \converges \skipp,s' \\ \Gamma,s'\ts N \converges c,s''}{\Gamma,s \ts M;N \converges c,s''}
    \and
    \inferrule*{\Gamma,s\ts M \converges \true,s' \\ \Gamma,s' \ts N \converges c,s''}{\Gamma,s \ts \If M \Then N \Else P \converges c,s''}
    \and
    \inferrule*{\Gamma,s\ts M \converges \false,s' \\ \Gamma,s' \ts P \converges c,s''}{\Gamma,s \ts \If M \Then N \Else P \converges c,s''}
    \and
    \inferrule*{\Gamma,s\ts M \converges 0,s' \\ \Gamma,s' \ts N \converges c,s''}{\Gamma,s \ts \IfO M \Then N \Else P \converges c,s''}
    \and
    \inferrule*{\Gamma,s\ts M \converges n+1,s' \\ \Gamma,s' \ts P \converges c,s''}{\Gamma,s \ts \IfO M \Then N \Else P \converges c,s''}
    \and
    \inferrule*[right=$x\in\Gamma$]{\Gamma,s\ts E \converges n,s' \\ \Gamma,s' \ts V \converges x,s''}{\Gamma,s\ts V \gets E \converges \skipp,(s''\vert x \mapsto n)}
    \and
    \inferrule*[right={$s'(x)=n$}]{\Gamma,s\ts V \converges x,s'}{\Gamma,s\ts !V \converges n,s'}
    \and
    \inferrule*{\Gamma,x\from\Var,(s\vert x\mapsto 0)\ts M \converges c,(s'\vert x\mapsto n)}{\Gamma,s\ts \neww \lambda x.M \converges c,s'}
    \and
    \inferrule*{\Gamma,s\ts E \converges n,s' \\ \Gamma,s'\ts V \converges \mkvar W R,s'' \\ \Gamma,s'' \ts Wn \converges \skipp,s'''}
    {\Gamma,s \ts V\gets E \converges \skipp,s'''}
    \and
    \inferrule*{\Gamma,s\ts V \converges \mkvar W R,s' \\ \Gamma,s'\ts R \converges n,s''}{\Gamma,s\ts !V \converges n,s''}
  \end{mathpar}
  \caption[Operational semantics for Idealized Algol.]{Operational semantics for Idealized Algol. See \cite{RusssThesis} and \cite{SamsonGuyIAActive}.}
  \label{FigIaOpSem}
\end{figure}

\section{Small-Step Operational Semantics}

We also give a small-step operational semantics for Idealized Algol, which will sometimes be easier to work with.  

This time, instead of defining a relation $\Gamma,s\ts M\converges c,s'$, we define a relation $\Gamma,s\ts M\opto \Gamma,\Delta,s'\ts M'$, where
\begin{itemize}
  \item $\Gamma,\Delta$ are disjoint $\Var$-contexts; 
  \item $s$ is a $\Gamma$-store and $s'$ a $\Gamma,\Delta$-store;  and
  \item $\Gamma\ts M$, $\Gamma,\Delta\ts M'$ are Idealized Algol terms-in-context.
\end{itemize}

As an auxiliary definition, we need the notion of an \emph{evaluation context} (see \cite{Felleisen}).
This is a single-holed context defined inductively by the following BNF formula, where $M$ ranges over IA terms (subject to typing rules).
\begin{center}
\parbox{0.8\textwidth}{
\begin{mathpar}
  \EE \Coloneqq - \mid \EE\,M \mid \suc \EE \mid \pred \EE \mid \EE;M \mid \If \EE\Then M \Else M \mid \IfO \EE \Then M \Else M \mid !\EE \mid M \gets \EE \mid \EE \gets n
\end{mathpar}}
\end{center}

Next, we define a relation $\Gamma,s,M\oopto\Gamma,\Delta,s',M'$ as in Figure \ref{FigIaSsOpSem}.

We then define the relation $\opto$ as
\[
  \inferrule*{ \Gamma,s\ts M\oopto \Gamma,\Delta,s'\ts M'}{\Gamma,s\ts \EE[M] \opto \Gamma,\Delta,s'\ts\EE[M']}
  \]
for each evaluation context $\EE$.

\begin{figure}
  \begin{mathpar}
    \Gamma,s\ts (\lambda x.M)N \oopto \Gamma,s\ts M[N/x]
    \and
    \Gamma,s\ts \Y M \oopto \Gamma,s\ts M(\Y M)
    \and
    \Gamma,s\ts \suc n \oopto \Gamma,s\ts n+1
    \\
    \Gamma,s \ts \pred (n+1) \oopto \Gamma,s\ts n
    \and
    \Gamma,s\ts \pred 0 \oopto \Gamma,s\ts 0
    \\
    \Gamma,s\ts \skipp;M \oopto \Gamma,s\ts M
    \\
    \Gamma,s\ts \If \true \Then N \Else P \oopto \Gamma,s\ts N
    \and
    \Gamma,s\ts \If \false \Then N \Else P \oopto \Gamma,s\ts P
    \and
    \Gamma,s\ts \IfO 0 \Then N \Else P \oopto \Gamma,s\ts N
    \and
    \Gamma,s\ts \IfO (n+1) \Then N \Else P \oopto \Gamma,s\ts P
    \and
    x,\Gamma,s\ts x \gets n \oopto x,\Gamma,(s\vert x\mapsto n)\ts \skipp
    \and
    x,\Gamma,s\ts \oc x \oopto x,\Gamma,s\ts s(x)
    \\
    \Gamma,s\ts \neww \lambda x.M \oopto \Gamma,x,(s\vert x\mapsto 0)\ts M
    \\
    \Gamma,s \ts (\mkvar W\,R) \gets n \oopto \Gamma,s\ts Wn
    \and
    \Gamma,s \ts \oc(\mkvar W\,R) \oopto \Gamma,s\ts R
  \end{mathpar}
  \caption{Felleisen-style small-step operational semantics for Idealized Algol.}
  \label{FigIaSsOpSem}
\end{figure}

We need to prove that this is equivalent to our original semantics.
Given a $\Gamma,\Delta$-store $s$, write $s\vert_{\Gamma}$ for the restriction of $s$ to $\Gamma$.

\begin{lemma}
  Suppose that $\Gamma,s\ts M \oopto \Gamma,\Delta,s'\ts M'$ and that $\Gamma,\Delta,s'\ts \EE[M'] \converges c,s''$.  
  Then $\Gamma,s\ts \EE[M]\converges c,s''\vert_\Gamma$.
  \label{LemSmallToBig}
\end{lemma}
\begin{proof}
  Structural induction on $\EE$.
  The base case, when $\EE$ is a hole, covers the interesting cases, so we shall leave it to last.
  The remaining cases are quite similar, so we will show the proof for one of them for illustration.

  If $\EE=\EE'\,N$, for some term $N$, then we have $\Gamma,\Delta,s'\ts \EE'[M']\,N\converges c,s''$.  
  By inspection of the rules in Figure \ref{FigIaOpSem}, the derivation of this must end with a rule of the form
  \[
    \inferrule*{\Gamma,\Delta,s'\ts \EE'[M'] \converges \lambda x.M'',t \\ \Gamma,\Delta,t \ts M''[N/x] \converges c,s''}
    {\Gamma,\Delta,s'\ts \EE'[M']\,N \converges c,s''}\,.
    \]
  Thus, $\Gamma,\Delta,s'\ts \EE'[M']\converges \lambda x.M'',t$ and $\Gamma,\Delta\ts M''[N/x]\converges c,s''$ must be provable for some $M'',t$.
  By the induction hypothesis, this means that $\Gamma,s\ts \EE'[M]\converges \lambda x.M'',t$ is provable.
  Then we have a derivation
  \[
    \inferrule*{\Gamma,\Delta,s\ts \EE'[M] \converges \lambda x.M'',t \\ \Gamma,\Delta,t \ts M''[N/x] \converges c,s''}
    {\Gamma,\Delta,s\ts \EE'[M]\,N\converges c,s''\vert_{\Gamma,\Delta}}\,.
    \]
  Then, because any variables in $\Delta$ are not mentioned in $\EE'[M]\,N$ or in $c$, we have
  \[
    \Gamma,s\ts \EE'[M]\,N\converges c,s''\vert_\Gamma\,.
    \]
  Now, let us suppose that $\EE$ is a hole, so that $\EE[M']=M'$.  

  Then there are a number of cases, depending on the particular $\oopto$ rule we are using.  
  Many of these cases are similar, so we will cover a few of them for the purposes of illustration.
  \begin{itemize}
    \item Suppose that $\Gamma,s\ts M[N/x]\converges c,s'$.  
      Then we have a derivation
      \[
        \inferrule*
        {
          \inferrule*
          {
          }
          {
            \Gamma,s \ts \lambda x.M \converges \lambda x.M,s
          }
          \\
          \Gamma,s\ts M[N/x] \converges c,s'
        }
        {
          \Gamma,s\ts (\lambda x.M)N \converges c,s'
        }\,.
        \]
    \item We have a derivation
      \[
        \inferrule*
        {
          \inferrule*
          {
          }
          {
            \Gamma,s\ts x\converges x,s
          }
          \\
          \inferrule*
          {
          }
          {
            \Gamma,s\ts n\converges n,s
          }
        }
        {
          \Gamma,s\ts x\gets n\converges \skipp,(s\vert x\mapsto n)
        }\,.
        \]
    \item We have a derivation
      \[
        \inferrule*
        {
          \inferrule*
          {
          }
          {
            \Gamma,s\ts x \converges x,s'
          }
        }
        {
          \Gamma,s\ts \oc x\converges s(x),s
        }\,.
        \]
    \item Suppose that $\Gamma,x,(s\vert x\mapsto 0) \ts M\converges c,s'$.  
      Then we have a derivation
      \[
        \inferrule*
        {
          \Gamma,x,(s\vert x\mapsto 0) \ts M \converges c,s'
        }
        {
          \Gamma,s\ts \neww\lambda x.M \converges c,s'\vert_\Gamma
        }\,,
        \]
      since $s'=(s'\vert_\Gamma\vert x\mapsto s'(x))$.\qedhere
  \end{itemize}
\end{proof}

We have proved:

\begin{proposition}
  Suppose that we have a sequence
  \[
    \Gamma_1,s^{(1)},M_1\opto\cdots\opto\Gamma_n,s^{(n)},M_n\,,
    \]
  where $M_n$ is a canonical form.  
  Then $\Gamma_1,s^{(1)} \ts M_1\converges M_n,s^{(n)}\vert_{\Gamma_1}$.  
  \label{PropSmallToBig}
\end{proposition}
\begin{proof}
  Induction on $n$.  
  The inductive step is Lemma \ref{LemSmallToBig}, while the base case ($n=1$) is given by the derivation
  \[
    \inferrule*{ }
    {\Gamma,s\ts c\converges c,s}\,.\qedhere
    \]
\end{proof}

We can also prove the converse.

\begin{proposition}
  Suppose that $\Gamma,s\ts M\converges c,s'$.  
  Then there are sequences $\Gamma=\Gamma_1,\cdots,\Gamma_n=\Gamma,\Delta$, $s=s^{(1)},\cdots,s^{(n)}$, $M=M_1,\cdots,M_n=c$ such that
  \[
    \Gamma_1,s^{(1)}\ts M_1 \opto \cdots \opto \Gamma_n,s^{(n)}\ts M_n\,,
    \]
  and $s^{(n)}\vert_{\Gamma}=s'$.
  \label{PropBigToSmall}
\end{proposition}
\begin{proof}
  Induction on the derivation of $\Gamma,s\ts M\converges c,s'$.  
  Since most of the cases are similar, we cover a selection for illustration.

  \begin{itemize}
    \item Suppose that the last step in the derivation is
      \[
        \inferrule*{ }
        {\Gamma,s\ts c\converges c,s}\,.
        \]
      Then we have the one-element sequence $\Gamma,s\ts c$.  
    \item Suppose that the last step in the derivation is
      \[
        \inferrule*
        {
          \Gamma,s\ts M\converges \lambda x.M',s' \\ \Gamma,s' \ts M'[N/x]\converges c,s''
        }
        {
          \Gamma,s \ts MN\converges c,s''
        }\,.
        \]
      Then, by the inductive hypothesis, we have small-step derivations
      \begin{mathpar}
        \Gamma,s \ts M \opto \cdots \opto \Gamma,\Delta,t',\lambda x.M'
        \and
        \Gamma,s' \ts M'[N/x]\opto \cdots \opto \Gamma,\Delta',t'',c\,,
      \end{mathpar}
      where $t'\vert_\Gamma=s'$ and $t''\vert_\Gamma=s''$.

      If we apply the evaluation context $-N$ pointwise to the first small-step derivation, then we have another valid small-step derivation.  
      Then we can join the two together to get the derivation
      \begin{center}
        \parbox{0.8\textwidth}{
        \begin{mathpar}
          \Gamma,s \ts MN \opto \cdots \opto \Gamma,\Delta,t',(\lambda x.M')N \opto \Gamma,\Delta,t',M'[N/x] \opto \cdots \opto \Gamma,\Delta\cup\Delta',t''\setminus t',c\,,
        \end{mathpar}}
      \end{center}
      where $t''\setminus t'$ is the $\Gamma,\Delta\cup\Delta'$-store that agrees with $t''$ on $\Gamma,\Delta'$ and with $t'$ on $\Delta\setminus\Delta'$.
      Then $(t''\setminus t')\vert_{\Gamma}=s''$.
    \item Suppose that the last step in the derivation is
      \[
        \inferrule*
        {
          \Gamma,s\ts E\converges n,s' \\ \Gamma,s'\ts V\converges x,s''
        }
        {
          \Gamma,s \ts V \gets E \converges\skipp,(s''\vert x\mapsto n)
        }\,.
        \]
      By the inductive hypothesis, we have small-step derivations
      \begin{mathpar}
        \Gamma,s\ts E \opto \cdots \opto \Gamma,\Delta,t',n
        \and
        \Gamma,s'\ts V \opto \cdots \opto \Gamma,\Delta',t'',x\,,
      \end{mathpar}
      where $t'\vert_{\Gamma}=s'$ and $t''\vert_{\Gamma}=s''$.

      We may apply the evaluation context $V\gets-$ pointwise to the first derivation and the evaluation context $-\gets n$ pointwise to the second, and then string the two together to get
      \begin{center}
        \parbox{0.8\textwidth}{
        \begin{mathpar}
          \Gamma,s\ts V\gets E \opto \cdots \opto \Gamma,\Delta,t',V\gets n \opto \cdots \opto \Gamma,\Delta\cup\Delta',t''\setminus t',x\gets n \opto \Gamma,\Delta\cup\Delta',(t''\setminus t'\vert x\mapsto n)\,,
        \end{mathpar}}
      \end{center}
      where we have $(t''\setminus t'\vert x\mapsto n)\vert_\Gamma=(s''\vert x\mapsto n)$.
    \item Suppose that the last step in the derivation is
      \[
        \inferrule*
        {
          \Gamma,s\ts V \converges x,s'
        }
        {
          \Gamma,s\ts \oc V \converges s'(x),s'
        }\,.
        \]
      Then, by the induction hypothesis, we have a small-step derivation
      \[
        \Gamma,s\ts V \opto \cdots \opto \Gamma,\Delta,t'\ts x\,,
        \]
      where $t'\vert_\Gamma=s'$.  
      Then we may compose this derivation pointwise with the evaluation context $\oc-$, and add an extra term on the end, to arrive at the derivation
      \[
        \Gamma,s\ts \oc V \opto \cdots \opto \Gamma,\Delta,t'\ts \oc x \opto \Gamma,\Delta,t'\ts t'(x)\,,
        \]
      where $t'(x)=s'(x)$.
    \item Lastly, suppose that the last step in the derivation is
      \[
        \inferrule*
        {
          \Gamma,x,(s\vert x\mapsto 0) \ts M \converges c,(s'\vert x\mapsto n)
        }
        {
          \Gamma,s \ts \neww \lambda x.M \converges c,s'
        }\,.
        \]
      By the induction hypothesis, we have a small-step derivation
      \[
        \Gamma,x,(s\vert x\mapsto 0) \ts M \opto \cdots \opto \Gamma,\Delta,x,(t'\vert x\mapsto n),c\,,
        \]
      where $t'\vert_\Gamma=s'$.  
      Then we may add a term at the beginning to give us
      \begin{center}
        \parbox{0.6\textwidth}{
        \begin{mathpar}
          \Gamma,s \ts \neww \lambda x.M \opto \Gamma,x,(s\vert x\mapsto 0) \ts M \opto \cdots \opto \Gamma,\Delta,x,(t'\vert x\mapsto n),c\,,
        \end{mathpar}}
      \end{center}
      where $(t'\vert x\mapsto n) \vert_\Gamma=s'$.\qedhere
  \end{itemize}
\end{proof}

\section{Soundness}

To prove soundness of our model, we shall use the small-step formulation.  
Our reason for this is that the most difficult part of the denotational semantics we are using is the part to do with state.  
In the big-step formulation, nearly every rule involves the state changing in some way, whereas in the small-step formulation, only the rules that specifically pertain to the stateful components of the language do.

Given a $\Var$-context $\Gamma$, we will write $S_\Gamma$ for $\bN \times \cdots \times \bN$ and $\V_\Gamma$ for $\Varr \times \cdots \times \Varr$, where in each case the terms of the tensor product are indexed by the variables in $\Gamma$.  
Then, given some term $\Gamma\ts M$ in context, its denotation will be a morphism $\deno{\Gamma\ts M\from T} \from \oc \V_\Gamma \implies \deno{T}$.

Given $\Gamma$, we have a morphism $\cell^\Gamma\from \oc S_\Gamma \implies \oc V_\Gamma$, given by
\[
  \oc S_\Gamma \cong \oc \bN \tensor \cdots \tensor \oc \bN \xrightarrow{\cell \tensor \cdots \tensor \cell} \oc \Varr \tensor \cdots \tensor \oc \Varr \cong \oc V_\Gamma\,.
  \]
\begin{lemma}
  For $j=1,\cdots,|\Gamma|$, the following diagram commutes.
  \[
    \begin{tikzcd}
      \oc S_\Gamma \arrow[r, "\cell^\Gamma"] \arrow[d, "\oc\pr_j"']
        & \oc V_\Gamma \arrow[d, "\oc \pr_j"] \\
      \oc \bN \arrow[r, "\cell"]
        & \oc \Varr
    \end{tikzcd}
    \]
\end{lemma}
\begin{proof}
  We have a commutative diagram
  \[
    \begin{tikzcd}[column sep=40pt, row sep=40pt]
      \oc S_\Gamma \arrow[r, Isom] \arrow[dr, "\oc \pr_j"']
        & \oc \bN \tensor \cdots \tensor \oc \bN \arrow[r, "\cell \tensor \cdots \tensor \cell"] \arrow[d, "() \tensor \cdots \tensor \oc\bN \tensor \cdots \tensor ()"' {description, xshift=10pt}]
          & \oc \Varr \tensor \cdots \tensor \oc \Varr \arrow[r, Isom] \arrow[d, "() \tensor \cdots \tensor \oc\Varr \tensor \cdots \tensor ()" {description, xshift=-10pt}]
            & \oc V_\Gamma \arrow[dl, "\oc \pr_j"] \\
      %
        & \oc\bN \arrow[r, "\cell"]
          & \oc\Varr
            &
    \end{tikzcd}\,,
    \]
  where the outer triangles commute because the vertical arrows are the projections in the tensor product of comonoids.
\end{proof}

Given a $\Gamma$-store $s$, we will write $\deno{s}$ for the corresponding morphism $I \to S_\Gamma$.

We start our proof of soundness with a result about evaluation contexts.
This result captures the fact that the term filling the hole of an evaluation context is the first thing to be computed, using the sequoid operator to capture this notion of precedence.
\begin{lemma}
  Let $\Gamma\ts M\from T$ be an Idealized Algol term-in-context, and let $\EE$ be an evaluation context with a hole of type $T$, where $\EE[M]\from U$.  
  Then there is a game $A$ and strategies $\sigma\from \oc\V_\Gamma \implies A$, $\tau\from\deno{T}\sequoid A \implies \deno{S}$, where $\tau$ is a strict strategy, such that the denotation $\deno{\Gamma\ts\EE[M]}$ factors as
  \[
    \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc \V_\Gamma \tensor \oc \V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma} \deno{T}\tensor A \xrightarrow{\wk_{\deno{T},A}} \deno{T} \sequoid A \xrightarrow{\tau} \deno{U}\,.
    \]
  \label{LemEvContexLemma}
\end{lemma}
\begin{proof}
  Structural induction on $\EE$.
  \begin{itemize}
    \item If $\EE=-$ is a hole, then we may take $A=I$, $\sigma=()$ and $\tau=\run_{\deno T}$.  

    \item If $\EE=\EE' N$ for some term $N$, where $\EE'$ has type $S\to T$, $N$ has type $S$, and $M\from S'$ fits into the hole, then the denotation $\deno{\Gamma \ts \EE[M]} = \deno{\Gamma \ts \EE'[M]\,N}$ is given by the composite
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\deno{\Gamma \ts \EE'[M]}\tensor \deno{\Gamma \ts N}} (\oc\deno{S} \implies \deno{T}) \tensor \oc\deno{S} \xrightarrow{\ev_{\oc\deno{S},\deno{T}}} \deno{T}.
        \]
      By the inductive hypothesis, $\deno{\Gamma\ts\EE' M}$ factors as
      \small
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc \V_\Gamma \tensor \oc \V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma'} \deno{S'}\tensor A' \xrightarrow{\wk_{\deno{S'},A'}} \deno{S'} \sequoid A' \xrightarrow{\tau'} (\oc\deno{S}\implies\deno{T}),
        \]
      \normalsize
      for appropriate $A',\sigma',\tau'$.  
      Then $\deno{\Gamma\ts\EE[M]} = \deno{\Gamma\ts\EE'[M]\,N}$ is given by the thick dashed arrows in the diagram in Figure \ref{FigEvContextApp}.  
      But this composite is equal to that given by the thin solid arrows in the diagram, which is of the required form, with
      \begin{mathpar}
        A = A' \tensor \oc\deno{S}
        \and
        \sigma = \mu_{\V_\Gamma};(\sigma'\tensor\deno{\Gamma\ts N}^\dag)
        \and
        \tau = \passoc_{\deno{S'},A',\oc\deno{S}}\inv;(\tau'\sequoid\oc\deno{S});\ev_{s\;\oc\deno{S},\deno{T}}\,.
      \end{mathpar}
      \begin{figure}
        \small
        \[
          \begin{tikzcd}[column sep=79pt]
            \oc\V_\Gamma \arrow[d, "\mu_{\V_\Gamma}"' yshift=3pt, thick, dashed] \arrow[r, "\mu_{\V_\Gamma}"]
              & \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[d, "\oc\V_\Gamma\tensor\mu_{\V_\Gamma}"] \\
            \oc \V_\Gamma \tensor \oc \V_\Gamma \arrow[d, "\mu_{\V_\Gamma}\tensor \oc\V_\Gamma"' yshift=3pt, thick, dashed]
              & \oc \V_\Gamma \tensor (\oc \V_\Gamma \tensor \oc \V_\Gamma) \arrow[d, "\deno{\Gamma \ts M}\tensor (\sigma' \tensor \deno{\Gamma\ts N}^\dag)"] \\
            (\oc \V_\Gamma \tensor \oc \V_\Gamma) \tensor \oc \V_\Gamma \arrow[d, "(\deno{\Gamma\ts M} \tensor \sigma')\tensor\deno{\Gamma\ts N}^\dag"' yshift=3pt, thick, dashed] \arrow[ur, "\assoc_{\V_\Gamma,\V_\Gamma,\V_\Gamma}" description, dotted]
              & \deno{S'} \tensor (A' \tensor \oc\deno{S}) \arrow[d, "{\wk_{\deno{S'},A' \tensor \oc \deno{S}}}"] \\
            (\deno{S'} \tensor A') \tensor \oc\deno{S} \arrow[d, "{\wk_{\deno{S'},A'}\tensor \oc\deno{S}}"' yshift=3pt, thick, dashed] \arrow[ur, "\assoc_{\deno{S'},A',\oc\deno{S}}" description, dotted]
              & \deno{S'} \sequoid (A' \tensor \oc\deno{S}) \arrow[d, "{\passoc_{\deno{S'},A',\oc\deno{S}}\inv}"] \\
            (\deno{S'} \sequoid A') \tensor \oc\deno{S} \arrow[d, "\tau' \tensor\oc\deno S"' yshift=3pt, thick, dashed] \arrow[r, "{\wk_{\deno{S'}\sequoid A',\oc\deno{S}}}" description, dotted]
              & (\deno{S'} \sequoid A') \sequoid \oc\deno{S} \arrow[d, "\tau' \sequoid \oc\deno{S}"] \\
            (\oc \deno{S} \implies \deno{T}) \tensor \oc\deno{S} \arrow[d, "{\ev_{\oc\deno{S},\deno{T}}}"' yshift=3pt, thick, dashed] \arrow[r, "{\wk_{\oc\deno S \implies \deno T,\oc\deno S}}" description, dotted]
              & (\oc\deno{S} \implies \deno{T}) \sequoid \oc\deno{S} \arrow[dl, "{\ev_{s\;\oc\deno{S},\deno{T}}}"] \\
            \deno{T}
              &
          \end{tikzcd}
          \]
        \normalsize
        \caption[The property in Lemma \ref{LemEvContexLemma} is preserved by function application.]{The property in Lemma \ref{LemEvContexLemma} is preserved by function application.  
        Here, $\ev_{s\;\oc\deno{S},\deno{T}} = \Lambda_s\inv(\id_{\oc\deno{S}\implies \deno{T}})$.}
        \label{FigEvContextApp}
      \end{figure}
    \item If $\EE=\suc \EE'$ or $\pred \EE'$, where $\EE'$ is a context of type $\nat$, and $M\from T$ is a term that fits into the hole, then the denotation $\deno{\Gamma\ts\EE[M]}$ is given by the composite
      \[
        \oc \V_\Gamma \xrightarrow{\deno{\Gamma \ts \EE'[M]}} \bN \xrightarrow{\theta} \bN\,,
        \]
      where $\theta$ is either $\pred$ or $\suc$.
      By the inductive hypothesis, $\deno{\Gamma\ts\EE'[M]}$ factors as
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc \V_\Gamma \tensor \oc \V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma'} \deno{T}\tensor A' \xrightarrow{\wk_{\deno{T},A'}} \deno{T} \sequoid A' \xrightarrow{\tau'} \bN\,,
        \]
      for appropriate $A',\sigma',\tau'$.  
      Then we can compose on the right by $\theta$, and we are already in the required form, for
      \begin{mathpar}
        A = A' \and \sigma = \sigma' \and \tau = \tau';\theta\,.
      \end{mathpar}
    \item Similarly, if $\EE = \oc\EE'$, where $\EE'$ is a context of type $\Var$, and $M\from T$ is a term that fits into the hole, then the denotation $\deno{\Gamma\ts\EE[M]}$ is given by the composite
      \[
        \oc \V_\Gamma \xrightarrow{\deno{\Gamma \ts \EE'[M]}} \Varr \xrightarrow{\dereff} \bN\,.
        \]
      By the inductive hypothesis, $\deno{\Gamma\ts\EE'[M]}$ factors as
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc \V_\Gamma \tensor \oc \V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma'} \deno{T}\tensor A' \xrightarrow{\wk_{\deno{T},A'}} \deno{T} \sequoid A' \xrightarrow{\tau'} \Varr\,,
        \]
      for appropriate $A',\sigma',\tau'$.  
      Then we can compose on the right by $\dereff$, and we are already in the required form, for
      \begin{mathpar}
        A = A' \and \sigma = \sigma' \and \tau = \tau';\dereff\,.
      \end{mathpar}
    \item If $\EE=\EE';N$ for some term $N$ of type $X\in\{\com,\bool,\nat\}$, where $\EE'$ is an evaluation context of type $\com$, and if $M\from T$ fits into the hole in $\EE'$, then the denotation $\deno{\Gamma\ts\EE[M]}$ is given by the composite
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\deno{\Gamma\ts\EE'[M]}\tensor\deno{\Gamma\tensor N}} \bC \times X \xrightarrow{\Lambda\inv(\seq_X)} X\,.
        \]
      If $\EE = N\gets\EE'$, for some term $N$ of type $\Var$, where $\EE'$ is an evaluation context of type $\com$, and if $M\from T$ fits into the hole in $\EE'$, then the denotation $\deno{\Gamma\ts\EE[M]}$ is given by the composite
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\deno{\Gamma\ts\EE'[M]}\tensor\deno{\Gamma\tensor N}} \bN \times \Var \xrightarrow{\Lambda\inv(\assign)} \bC\,.
        \]
      Write $Y=\bC$, $X'=X$, $Z=X$ and $\upsilon=\seq_X$ in the sequencing case, and $Y=\bN$, $X'=\Var$, $Z=\bC$ and $\upsilon=\assign$ in the variable assignment case.
      Then, by the inductive hypothesis, $\deno{\Gamma\ts\EE'[M]}$ factors as
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc \V_\Gamma \tensor \oc \V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma'} \deno{T}\tensor A' \xrightarrow{\wk_{\deno{T},A'}} \deno{T} \sequoid A' \xrightarrow{\tau'} Y\,,
        \]
      for suitable $A',\sigma',\tau'$.
      Then $\deno{\Gamma\ts\EE[M]}$ is given by the thick dashed arrows in the diagram in Figure \ref{FigEvContextSeqAss}.  
      But this composite is equal to that given by the thin solid arrows in the diagram, which is of the required form, with
      \begin{mathpar}
        A = A' \tensor X'
        \and
        \sigma = \mu_{\V_\Gamma};(\sigma'\tensor\deno{\Gamma\ts N})
        \and
        \tau = \passoc_{\deno{T},A',X'}\inv;(\tau'\sequoid X');\Lambda_s\inv(\upsilon)\,.
      \end{mathpar}
      \begin{figure}
        \small
        \[
          \begin{tikzcd}[column sep=79pt]
            \oc\V_\Gamma \arrow[d, "\mu_{\V_\Gamma}"' yshift=3pt, thick, dashed] \arrow[r, "\mu_{\V_\Gamma}"]
              & \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[d, "\oc\V_\Gamma\tensor\mu_{\V_\Gamma}"] \\
            \oc \V_\Gamma \tensor \oc \V_\Gamma \arrow[d, "\mu_{\V_\Gamma}\tensor \oc\V_\Gamma"' yshift=3pt, thick, dashed]
              & \oc \V_\Gamma \tensor (\oc \V_\Gamma \tensor \oc \V_\Gamma) \arrow[d, "\deno{\Gamma \ts M}\tensor (\sigma' \tensor \deno{\Gamma\ts N})"] \\
            (\oc \V_\Gamma \tensor \oc \V_\Gamma) \tensor \oc \V_\Gamma \arrow[d, "(\deno{\Gamma\ts M} \tensor \sigma')\tensor\deno{\Gamma\ts N}"' yshift=3pt, thick, dashed] \arrow[ur, "\assoc_{\V_\Gamma,\V_\Gamma,\V_\Gamma}" description, dotted]
              & \deno{T} \tensor (A' \tensor X') \arrow[d, "{\wk_{\deno{T},A' \tensor X'}}"] \\
            (\deno{T} \tensor A') \tensor X' \arrow[d, "{\wk_{\deno{T},A'}\tensor X'}"' yshift=3pt, thick, dashed] \arrow[ur, "\assoc_{\deno{T},A',X'}" description, dotted]
              & \deno{T} \sequoid (A' \tensor X') \arrow[d, "{\passoc_{\deno{T},A',X'}\inv}"] \\
            (\deno{T} \sequoid A') \tensor X' \arrow[d, "\tau' \tensor X'"' yshift=3pt, thick, dashed] \arrow[r, "{\wk_{\deno{T}\sequoid A',X'}}" description, dotted]
              & (\deno{T} \sequoid A') \sequoid X' \arrow[d, "\tau' \sequoid X'"] \\
            Y \tensor X' \arrow[d, "\Lambda\inv(\upsilon)"' yshift=3pt, thick, dashed] \arrow[r, "{\wk_{Y,X'}}" description, dotted]
              & Y \sequoid X' \arrow[dl, "\Lambda_s\inv(\upsilon)"] \\
            \deno{T}
              &
          \end{tikzcd}
          \]
        \normalsize
        \caption[The property in Lemma \ref{LemEvContexLemma} is preserved by sequencing and variable assignment.]{The property in Lemma \ref{LemEvContexLemma} is preserved by sequencing and variable assignment.
        We use the fact that $\upsilon\in\{\seq_X,\assign\}$ is a strict strategy, so that $\Lambda_s\inv(\upsilon)$ is well-defined.}
        \label{FigEvContextSeqAss}
      \end{figure}
    \item If $\EE = \If \EE' \Then N \Else P$ for a context $\EE'$ of type $\bool$, where $N$ and $P$ are terms of type $X\in\{\bool,\com,\nat\}$, then write $Y=\bool$ and $\eta = \If_X$.  
      If $\EE = \IfO \EE' \Then N \Else P$ for a context $\EE'$ of type $\nat$, where $N$ and $P$ are terms of type $X\in\{\bool,\com,\nat\}$, then write $Y=\nat$ and $\eta=\IfO_X$.  
      In either case, if $M\from T$ is a term that fits into the hole, then the denotation $\deno{\Gamma\ts\EE[M]}$ is given by
      \begin{mathpar}
        \oc\V_\Gamma \xrightarrow{\mu_{V_\Gamma}} \oc\V_\Gamma\tensor\oc\V_\Gamma \xrightarrow{\mu_\Gamma \tensor \V_\Gamma} (\oc \V_\Gamma \tensor \oc \V_\Gamma) \tensor \oc\V_\Gamma \\\xrightarrow{(\deno{\Gamma\ts\EE'[M]} \tensor \deno{\Gamma\ts N}) \tensor \deno{\Gamma \ts P}} (Y \tensor X) \tensor X \xrightarrow{\Lambda\inv(\Lambda\inv(\eta))} X\,.
      \end{mathpar}
      By the inductive hypothesis, $\deno{\Gamma\ts\EE'[M]}$ factors as
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc \V_\Gamma \tensor \oc \V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma'} \deno{T}\tensor A' \xrightarrow{\wk_{\deno{T},A'}} \deno{T} \sequoid A' \xrightarrow{\tau'} Y\,,
        \]
      for appropriate $A',\sigma',\tau'$.  
      Then $\deno{\Gamma\ts\EE[M]} = \deno{\Gamma\ts\EE'[M]\,N}$ is given by the thick dashed arrows in the diagram in Figure \ref{FigEvContextCond}.  
      But this composite is equal to that given by the thin solid arrows in the diagram, which is of the required form, with
      \begin{mathpar}
        A = (A' \tensor X)\tensor X
        \and
        \sigma = \mu_{\V_\Gamma};(\mu_{\V_\Gamma}\tensor\oc\V_\Gamma);((\sigma'\tensor\deno{\Gamma\ts N})\tensor \deno{\Gamma\ts P})
        \and
        \tau = \passoc_{\deno T,A'\tensor X,X}\inv;(\passoc_{\deno T,A',X}\inv\sequoid X);((\tau'\sequoid X)\sequoid X);\Lambda_s\inv(\Lambda_s\inv(\eta))\,.
      \end{mathpar}
      \begin{SidewaysFigure}
        \small
        \[
          \begin{tikzcd}[ampersand replacement=\&, column sep=78pt, row sep=30pt]
            \oc \V_\Gamma \arrow[rr, "\mu_{\V_\Gamma}"] \arrow[d, "\mu_{\V_\Gamma}"', thick, dashed]
              \&
                \& \oc \V_\Gamma \tensor \oc \V_\Gamma \arrow[d, "\oc\V_\Gamma \tensor\mu_{\V_\Gamma}"] \\
            \oc \V_\Gamma \tensor \oc\V_\Gamma \arrow[r, "\mu_{\V_\Gamma}\tensor \oc\V_\Gamma", dotted] \arrow[d, "\mu_{\V_\Gamma}\tensor\oc\V_\Gamma"', thick, dashed]
              \& (\oc \V_\Gamma \tensor \oc\V_\Gamma) \tensor \oc\V_\Gamma \arrow[r, "{\assoc_{\oc\V_\Gamma,\oc\V_\Gamma,\oc\V_\Gamma}}", dotted] \arrow[d, "(\oc\V_\Gamma \tensor \mu_{\V_\Gamma}) \tensor \oc\V_\Gamma" description, dotted]
                \& \oc \V_\Gamma \tensor (\oc \V_\Gamma \tensor \oc\V_\Gamma) \arrow[d, "\oc\V_\Gamma \tensor (\mu_{\V_\Gamma}\tensor \oc\V_\Gamma)"] \\
            (\oc \V_\Gamma \tensor \oc\V_\Gamma)\tensor \oc\V_\Gamma \arrow[d, "(\mu_{\V_\Gamma}\tensor\oc\V_\Gamma)\tensor \oc\V_\Gamma"', thick, dashed]
              \& |[alias=Z]| (\oc \V_\Gamma \tensor(\oc\V_\Gamma\tensor \oc\V_\Gamma)) \tensor \oc\V_\Gamma \arrow[r, "{\assoc_{\oc\V_\Gamma,\oc\V_\Gamma\tensor\oc\V_\Gamma,\oc\V_\Gamma}}", dotted] \arrow[d, "(\deno{\Gamma\ts M}\tensor (\sigma'\tensor\deno{\Gamma\ts N})) \tensor \deno{\Gamma\ts P}" description, dotted]
                \& \oc\V_\Gamma \tensor ((\oc\V_\Gamma \tensor \oc\V_\Gamma) \tensor \oc\V_\Gamma) \arrow[d, "\deno{\Gamma\ts M} \tensor ((\sigma'\tensor\deno{\Gamma\ts N})\tensor \deno{\Gamma\ts P})" description] \\
            ((\oc\V_\Gamma \tensor \oc\V_\Gamma) \tensor \oc\V_\Gamma) \tensor \oc\V_\Gamma \arrow[d, "((\deno{\Gamma\ts M} \tensor \sigma') \tensor \deno{\Gamma\ts N}) \tensor \deno{\Gamma\ts P}" {description, xshift=-20pt}, thick, dashed] \arrow[ur, "{\assoc_{\oc\V_\Gamma,\oc\V_\Gamma,\oc\V_\Gamma}\tensor\oc\V_\Gamma}" description, to=Z.west, dotted]
              \& |[alias=Y]| (\deno T \tensor (A' \tensor X)) \tensor X \arrow[r, "{\assoc_{\deno T,A'\tensor X,X}}" description, dotted] \arrow[d, "{\wk_{T,A'\tensor X}\tensor X}" description, dotted]
                \& \deno T \tensor ((A' \tensor X) \tensor X) \arrow[d, "{\wk_{\deno T,(A'\tensor X)\tensor X}}"] \\
            ((\deno T\tensor A') \tensor X)\tensor X \arrow[ur, "{\assoc_{\deno T,A',X}\tensor X}" description, to=Y.west, dotted] \arrow[d, "{(\wk_{\deno T,A'}\tensor X)\tensor X}"', thick, dashed]
              \& (\deno T \sequoid (A' \tensor X))\tensor X \arrow[dr, "{\wk_{\deno T\sequoid (A'\tensor X),X}}" description, dotted] \arrow[d, "{\passoc_{\deno T,A',X}\tensor X}" description, dotted]
                \& \deno T \sequoid ((A' \tensor X)\tensor X) \arrow[d, "{\passoc_{\deno T,A'\tensor X,X}\inv}"] \\
            ((\deno T\sequoid A') \tensor X) \tensor X \arrow[r, "{\wk_{\deno T \sequoid A',X}\tensor X}", dotted] \arrow[d, "(\tau'\tensor X)\tensor X)"', thick, dashed]
              \& ((\deno T \sequoid A') \sequoid X) \tensor X \arrow[dr, "{\wk_{(\deno T\sequoid A') \sequoid X,X}}" description, dotted] \arrow[d, "(\tau'\sequoid X)\tensor X" description, dotted]
                \& (\deno T \sequoid (A' \tensor X)) \sequoid X \arrow[d, "{\passoc_{\deno T,A',X}\inv\sequoid X}"] \\
            (Y \tensor X) \tensor X \arrow[r, "{\wk_{Y,X}\tensor X}", dotted] \arrow[d, "\Lambda\inv(\Lambda\inv(\eta))"', thick, dashed]
              \& (Y \sequoid X) \tensor X \arrow[dr, "{\wk_{Y\sequoid X,X}}" description, dotted] \arrow[dl, "\Lambda\inv(\Lambda_s\inv(\eta))" description, dotted]
                \& ((\deno T \sequoid A') \sequoid X) \sequoid X \arrow[d, "(\tau'\sequoid X) \sequoid X"] \\
            X
              \&
                \& (Y \sequoid X)\sequoid X \arrow[ll, "\Lambda_s\inv(\Lambda_s\inv(\eta))"']
          \end{tikzcd}
          \]
          \normalsize
        \caption[The property in Lemma \ref{LemEvContexLemma} is preserved by conditionals.]{The property in Lemma \ref{LemEvContexLemma} is preserved by conditionals.
        We use the fact that $\eta\in\{\If_X,\IfO_X\}$ is a strict strategy, and that the $\Lambda_s\inv$ is a function from strict strategies to strict strategies, so that $\Lambda_s\inv(\Lambda_s\inv(\eta))$ is well-defined.}
        \label{FigEvContextCond}
      \end{SidewaysFigure}
    \item Lastly, suppose that $\EE = \EE' \gets n$ for some numeral $n$, where $\EE'$ is a context of type $\Var$, and suppose that $M\from T$ fits into the hole.  
      The denotation $\deno{\Gamma\ts \EE[M]}$ is given by
      \[
        \oc\V_\Gamma \xrightarrow{\deno{\Gamma\ts \EE'[M]}} \Varr \xrightarrow{\lunit_{\Varr}} I \tensor \Varr \xrightarrow{n\tensor\Varr} \bN \tensor \Varr \xrightarrow{\assign} \bC\,.
        \]
      By the induction hypothesis, $\deno{\Gamma\ts\EE'[M]}$ takes the form
      \[
        \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}}
        \oc\V_\Gamma\tensor\oc\V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma'}
        \deno{T}\tensor A' \xrightarrow{\wk_{\deno{T},A'}}
        \deno T\sequoid A' \xrightarrow{\tau'}
        \Varr\,,
        \]
      for suitable $A',\sigma',\tau'$.  
      Then, if we compose on the right by the morphism $\lunit_{\Varr};(n\tensor\Varr);\assign$, in order to give us the denotation $\deno{\Gamma\ts \EE'[M]\gets n} = \deno{\Gamma\ts\EE[M]}$, then we are already in the required form, with
      \begin{mathpar}
        A = A' \and \sigma = \sigma' \and \tau = \tau';\lunit_{\Varr};(n\tensor\Varr);\assign\,.\hspace{1em plus 1fill}\qedhere
      \end{mathpar}
  \end{itemize}
\end{proof}

Our next lemma will help us deal with the base $\oopto$ rules.  
We will then use Lemma \ref{LemEvContexLemma} to extend this to the $\opto$ relation.

\begin{definition}
  Let $\Gamma,s\ts M\from T$ be a term with store.  
  Then the \emph{sequoidal denotation} $\seqdeno{\Gamma,s\ts M}$ is the composite
  \[
    I \xrightarrow{\deno s} \oc S_\Gamma \xrightarrow{\cell^\Gamma} \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\oc\V_\Gamma} \deno T \tensor\oc\V_\Gamma \xrightarrow{\wk_{\deno T,\oc\V_\Gamma}} \deno T \sequoid \oc\V_\Gamma\,.
    \]
\end{definition}

\begin{lemma}
  The relation $\oopto$ betwen triples $\Gamma,s\ts M$ preserves the sequoidal denotation $\seqdeno{\Gamma,s\ts M}$.

  In other words, if $\Gamma,s\ts M \oopto \Gamma,\Delta,s'\ts N$, where $M,N$ have type $T$, then the following diagram commutes.
  \[
    \begin{tikzcd}[column sep=28pt]
      I \arrow[r, "\oc \deno s"] \arrow[d, "\oc \deno s'"']
        & \oc S_\Gamma \arrow[r, "\cell^\Gamma"]
          & \oc \V_\Gamma \arrow[r, "\mu_{\V_\Gamma}"]
            &[22pt] \oc \V_\Gamma \tensor \oc \V_\Gamma \arrow[d, "\deno{\Gamma\ts M}\tensor \oc V_\Gamma"] \\
      {\oc S_{\Gamma,\Delta}} \arrow[d, "{\cell^{\Gamma,\Delta}}"']
        &
          &
            & \deno T \tensor \oc V_\Gamma \arrow[d, "{\wk_{\deno T,\oc \V_{\Gamma}}}"] \\
      {\oc \V_{\Gamma,\Delta}} \arrow[d, "{\mu_{\V_{\Gamma,\Delta}}}"']
        &
          &
            &  \deno{T}\sequoid \oc\V_\Gamma \\
      {\oc \V_{\Gamma,\Delta} \tensor \oc \V_{\Gamma,\Delta}} \arrow[rr, "{\deno{\Gamma,\Delta\ts N} \tensor \oc \V_{\Gamma,\Delta}}"]
        &
          & {\deno T \tensor \oc \V_{\Gamma,\Delta}} \arrow[r, "{\wk_{\deno T,\oc \V_{\Gamma,\Delta}}}"]
            & {{\deno T \sequoid \oc \V_{\Gamma,\Delta}}\,.} \arrow[u, "\deno{T}\sequoid\oc\pr_\Gamma"']
    \end{tikzcd}
    \]
  I.e., if $\Gamma,s\ts M \oopto \Gamma,\Delta,s'\ts N$, then $\seqdeno{\Gamma,s\ts M} = \seqdeno{\Gamma,\Delta,s'\ts N};\oc\pr_\Gamma$.
  \label{LemSoundnessOopto}
\end{lemma}
\begin{proof}
  We prove this on a case-by-case basis.
  \begin{itemize}
    \item For most of the rules, $\Delta=\_$ and $s=s'$; i.e., the rule is of the form
      \[
        \Gamma,s\ts M \oopto \Gamma,s \ts N
        \]
      for some $M,N$.
      In such a case, it suffices to show that $\deno{\Gamma\ts M}=\deno{\Gamma\ts N}$.
      Indeed, we have
      \begin{itemize}
        \item $\deno{\Gamma\ts(\lambda x.M)N} = \deno{\Gamma\ts M[N/x]}$ (by a usual substitution-lemma argument);
        \item $\deno{\Gamma\ts\Y M} = \deno{\Gamma\ts (\lambda F.\lambda f.f(F f)) \Y M} = \deno{\Gamma\ts M(\Y M)}$;
        \item $\deno{\Gamma\ts \suc n} = \deno{\Gamma \ts n+1}$;
        \item $\deno{\Gamma\ts \pred (n+1)} = \deno{\Gamma\ts n}$;
        \item $\deno{\Gamma\ts \pred 0} = \deno{\Gamma\ts 0}$;
        \item $\deno{\Gamma\ts\skipp;M} = \deno{\Gamma\ts M}$;
        \item $\deno{\Gamma\ts\If \true \Then N \Else P} = \deno{\Gamma\ts (\lambda x.\lambda y.x)NP} = \deno{\Gamma\ts N}$;
        \item $\deno{\Gamma\ts\If \false \Then N \Else P} = \deno{\Gamma\ts (\lambda x.\lambda y.y)NP} = \deno{\Gamma\ts P}$;
        \item $\deno{\Gamma\ts\IfO 0 \Then N \Else P} = \deno{\Gamma\ts (\lambda x.\lambda y.x)NP} = \deno{\Gamma\ts N}$;
        \item $\deno{\Gamma\ts\IfO (n+1) \Then N \Else P} = \deno{\Gamma\ts (\lambda x.\lambda y.y)NP} = \deno{\Gamma\ts P}$;
        \item \parbox[t][][t]{0.8\textwidth}{$\deno{\Gamma\ts(\mkvar W\,R)\gets n} = \langle \deno{\Gamma\ts Wn}_{n\in\bN},\deno{\Gamma\ts R}\rangle;\pr_n = \deno{\Gamma\ts Wn}$; and}
        \item $\deno{\Gamma\ts\oc(\mkvar W\,R)} = \langle \deno{\Gamma\ts Wn}_{n\in\bN},\deno{\Gamma\ts R}\rangle;\pr_{\bN} = \deno{\Gamma\ts R}$.
      \end{itemize}
    \item Now consider the rule
      \[
        \Gamma,s\ts\neww \lambda x.M\oopto \Gamma,x,(s\vert x\mapsto 0)\ts M\,,
        \]
      where $\Gamma\ts M\from T$.
      The first observation to make is that the denotation $\deno{\Gamma\ts \neww \lambda x.M}$ may be written as
      \[
        \oc\V_\Gamma \xrightarrow{\runit_{\oc\V_\Gamma}} \oc\V_\Gamma \tensor I \xrightarrow{\oc\V_\Gamma\tensor (0;\cell)} \oc\V_\Gamma \tensor \oc\Varr \to \oc\V_{\Gamma,x} \xrightarrow{\Lambda\inv(\deno{\Gamma \ts \lambda x.M})} \deno{T}\,,
        \]
      where, of course $\Lambda\inv(\deno{\Gamma\ts\lambda x.M})=\deno{\Gamma,x\ts M}$, and that the projection $\pr_\Gamma \from \oc\V_{\Gamma,x}$ is a right inverse for the composite $\runit_{\oc\V_\Gamma};(\oc\V_{\Gamma}\tensor(0;\cell));\cong$, since we have a commutative diagram
      \[
        \begin{tikzcd}[column sep=50pt]
          \oc\V_\Gamma \arrow[r, "\runit_{\oc\V_\Gamma}"] \arrow[d, Rightarrow, no head]
            & \oc\V_\Gamma \tensor I \arrow[r, "\oc\V_\Gamma\tensor(0;\cell)"] \arrow[d, "\id_{\oc\V_\Gamma\tensor I}" description]
              & \oc\V_\Gamma \tensor \oc\Varr \arrow[d] \arrow[dl, "\oc\V_\Gamma\tensor()" description] \\
          \oc\V_\Gamma
            & \oc\V_\Gamma \tensor I \arrow[l, "\runit\inv"']
              & {\oc\V_{\Gamma,x}\,.} \arrow[ll, "\oc\pr_\Gamma", bend left=20]
        \end{tikzcd}
        \]
      Then we may prove this case using the commutative diagram in Figure \ref{FigSoundnessOoptoNew}.
      \begin{figure}[htbp]
        \[
          \begin{tikzcd}[column sep=34pt, row sep=30pt]
            I \arrow[r, "\oc\deno s"] \arrow[d, "{\oc\langle\deno s,0\rangle}" description]
              &[5pt] \oc S_\Gamma \arrow[r, "\cell^\Gamma"]
                &[-5pt] \oc\V_\Gamma \arrow[r, "\mu_{\V_\Gamma}"] \arrow[d, "\mu_{\V_\Gamma}" description]
                  & \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[d, "\runit_{\oc\V_\Gamma};(\oc\V_\Gamma\tensor (0;\cell));\cong" {description, xshift=-16pt}] \\
            {\oc S_{\Gamma,x}} \arrow[ur, "\oc\pr_\Gamma" description] \arrow[d, "{\cell^{\Gamma,x}}" description]
              &
                & \oc\V_\Gamma\tensor\oc\V_\Gamma
                  & {\oc\V_{\Gamma,x}\tensor\oc\V_\Gamma} \arrow[d, "{\deno{\Gamma,x\ts M}\tensor\oc\V_\Gamma}" description] \arrow[l, "\pr_\Gamma\tensor\oc\V_\Gamma"'] \\
            {\oc\V_{\Gamma,x}} \arrow[uurr, "\oc\pr_\Gamma" description] \arrow[d, "{\mu_{\V_{\Gamma,x}}}"]
              &
                &
                  & \deno T \tensor \oc\V_\Gamma \arrow[d, "{\wk_{\deno T,\oc\V_\Gamma}}" description] \\
            {\oc\V_{\Gamma,x}\tensor\oc\V_{\Gamma,x}} \arrow[uurr, "\oc\pr_\Gamma\tensor\oc\pr_\Gamma" {description, pos=0.7}] \arrow[uurrr, "{\V_{\Gamma,x}\tensor\pr_\Gamma}" {description, pos=0.7}] \arrow[r, "{\deno{\Gamma,x\ts M}\tensor\oc\V_{\Gamma,x}}"' yshift=-3pt]
              & {\deno T \tensor \oc\V_{\Gamma,x}} \arrow[r, "{\wk_{\deno T,\oc\V_{\Gamma,x}}}"' yshift=-3pt]
                & {\deno T \sequoid \oc\V_{\Gamma,x}} \arrow[r, "\deno T \sequoid\pr_\Gamma"' yshift=-3pt]
                  & \deno T \sequoid\oc\V_\Gamma
          \end{tikzcd}
          \]
        \caption{The conclusion of Lemma \ref{LemSoundnessOopto} holds for the $\neww$ rule.}
        \label{FigSoundnessOoptoNew}
      \end{figure}
    \item Now consider the rules
      \begin{mathpar}
        x,\Gamma,s\ts x\gets n \oopto x,\Gamma,(s\vert x\mapsto n) \ts \skipp
        \and
        x,\Gamma,s\ts \oc x\oopto x,\Gamma,s\ts s(x)\,.
      \end{mathpar}
      In each of these cases, the outer context $\Gamma$ is unchanged by the rule; moreover, each term ignores the variables in $\Gamma$.
      So the denotations terms-in-context $x,\Gamma\ts M\from T$ on either side of each rule are of the form
      \[
        \oc\V_{x,\Gamma} \xrightarrow{\oc\pr_1} \oc \Varr \xrightarrow{\deno{x\ts M}} \deno{T}\,.
        \]
      Now the diagram in Figure \ref{FigSoundnessOoptoContext} tells us that each $\seqdeno{\Gamma,x,s\ts M}$ may be written as the composite
      \begin{mathpar}
        \oc\deno{s\vert_\Gamma};\cell^\Gamma;\lunit_{\oc\V_\Gamma};\\((\oc\deno{s\vert_x};\cell;\mu_{\Varr};(\deno{x\ts M}\tensor\oc\Varr);\wk_{\deno T,\oc\Varr})\tensor\oc\V_\Gamma);\\\wk_{\deno T\sequoid \oc\Varr,\oc\V_\Gamma};\passoc_{\deno T,\oc\Varr,\oc\V_\Gamma};\cong
      \end{mathpar}
      (where $\cong$ represents the natural isomorpism between $\deno T\sequoid(\oc\Varr\tensor\oc\V_\Gamma)$ and $\deno T \sequoid\oc\V_{x,\Gamma}$),
      and so is completely determined by the value of the composite
      \[
        \oc\deno{s\vert_x};\cell;\mu_{\Varr};(\deno{x\ts M}\tensor\oc\Varr);\wk_{\deno T,\oc\Varr}\,;
        \]
      i.e., the sequoidal denotation $\seqdeno{x,s\vert_x\ts M}$.

      This tells us that we can assume that $\Gamma$ is the empty context, so that the rules take on the form
      \begin{mathpar}
        x,s\ts x\gets n \oopto x,(x\mapsto n)\ts \skipp
        \and
        x,s \ts \oc x \oopto x,s\ts s(x)\,.
      \end{mathpar}
      \begin{SidewaysFigure}
        \[
          \begin{tikzcd}[ampersand replacement=\&, column sep=5pt]
            I \arrow[r, "\oc\deno{s\vert_\Gamma}"] \arrow[d, "\oc\deno s"' {description, yshift=2pt}, thick, dashed]
              \& \oc S_\Gamma \arrow[r, "\cell^\Gamma"] \arrow[dr, "\lunit_{\oc S_\Gamma}" description, dotted]
                \&[18pt] \oc \V_\Gamma \arrow[r, "\lunit_{\oc\V_\Gamma}"] 
                  \&[17pt] I \tensor \oc\V_\Gamma \arrow[dd, "\oc\deno{s\vert_x}\tensor\oc\V_\Gamma" description, thick] \\
            {\oc S_{x,\Gamma}} \arrow[drr, Isom, dotted] \arrow[dd, "{\cell^{x,\Gamma}}"' description, thick, dashed]
              \&
                \& I \tensor \oc S_\Gamma \arrow[ur, "I \tensor\cell^\Gamma" description, dotted] \arrow[d, "\oc\deno{s\vert_x}\tensor\oc S_\Gamma" description, dotted]
                  \& \\
            %
              \&
                \& \oc\bN\tensor\oc S_\Gamma \arrow[r, "\oc\bN\tensor\cell^\Gamma" description, dotted] \arrow[dr, "\cell\tensor\cell^\Gamma" description, dotted]
                  \& \oc\bN \tensor\oc\V_\Gamma \arrow[d, "\cell\tensor\oc\V_\Gamma" description, thick] \\
            {\oc\V_{x,\Gamma}} \arrow[rrr, Isom, dotted] \arrow[d, "{\mu_{\V_{x,\Gamma}}}"' description, thick, dashed]
              \&
                \&
                  \& \oc\Varr \tensor \oc\V_\Gamma \arrow[d, "\mu_{\Varr}\tensor\oc\V_\Gamma" description, thick] \arrow[dl, "\mu_{\Varr}\tensor\mu_{\V_\Gamma}" description, bend right=15, dotted] \\[10pt]
            {\oc\V_{x,\Gamma}\tensor\oc\V_{x,\Gamma}} \arrow[r, dotted] \arrow[d, "{\oc\pr_1\tensor\oc\V_{x,\Gamma}}" description, dotted] \arrow[dd, "{\deno{x,\Gamma\ts M}\tensor\oc\V_{x,\Gamma}}" description, bend right=68, thick, dashed, end anchor={[xshift=-3pt]}]
              \& (\oc\Varr \tensor \oc\V_\Gamma) \tensor (\oc\Varr \tensor\oc\V_\Gamma) \arrow[r, dotted] \arrow[d, "(\oc\Varr\tensor())\tensor(\oc\Varr\tensor\oc\V_{\Gamma})" description, dotted]
                \& (\oc\Varr \tensor \oc\Varr) \tensor (\oc\V_\Gamma \tensor\oc\V_\Gamma) \arrow[r, "(\oc\Varr\tensor\oc\Varr)\tensor(()\tensor\oc\V_\Gamma)" yshift=5pt, dotted]
                  \& (\oc\Varr \tensor \oc\Varr) \tensor\oc\V_\Gamma \arrow[d, "(\deno{x\ts M}\tensor \oc\Varr) \tensor \oc\V_\Gamma" description, thick] \\[30pt]
            {\oc\Varr \tensor \oc\V_{x,\Gamma}} \arrow[r, Isom, dotted] \arrow[d, "{\deno{x\ts M} \tensor \oc\V_{x,\Gamma}}"' {description, yshift=1pt}, dotted]
              \& \oc\Varr \tensor (\oc\Varr \tensor\oc\V_\Gamma) \arrow[urr, "{\assoc_{\oc\Varr,\oc\Varr,\oc\V_\Gamma}\inv}" {description, xshift=-5pt, yshift=5pt}, start anchor={[xshift=-25pt]}, bend left=5, dotted] \arrow[r, "\deno{x\ts M} \tensor (\oc\Varr\tensor\oc\V_\Gamma)" yshift=2pt, dotted]
                \& \deno{T} \tensor (\oc\Varr \tensor \oc\V_\Gamma) \arrow[r, "{\assoc_{\deno T,\oc\Varr,\oc\V_\Gamma}}" yshift=2pt, dotted] \arrow[ddl, "{\wk_{\deno T,(\oc\Varr\tensor\oc\V_\Gamma)}}" description, dotted]
                  \& (\deno T \tensor \oc\Varr) \tensor \oc\V_\Gamma\arrow[d, "{\wk_{\deno T,\oc\Varr}\tensor\oc\V_\Gamma}" {description, yshift=1pt}, thick] \\
            {\deno T \tensor \oc\V_{x,\Gamma}} \arrow[d, "{\wk_{\deno T,\oc\V_{x,\Gamma}}}"' {description, yshift=2pt}, thick, dashed] \arrow[urr, Isom, dotted]
              \&
                \&
                  \& (\deno T \sequoid \oc\Varr) \tensor \oc\V_\Gamma \arrow[d, "{\wk_{(\deno T\sequoid\oc\Varr),\oc\V_\Gamma}}" {description, yshift=2pt}] \\[5pt]
            {\deno T \sequoid \oc\V_{x,\Gamma}} \arrow[r, Isom]
              \& \deno T \sequoid (\oc\Varr \tensor\oc\V_\Gamma)
                \&
                  \& (\deno T \sequoid \oc\Varr) \sequoid\oc\V_\Gamma \arrow[ll, "{\passoc_{\deno T,\oc\Varr,\oc\V_\Gamma}}"]
          \end{tikzcd}
          \]
          \caption{Diagram proving that if we want to prove the conclusion of Lemma \ref{LemSoundnessOopto} for a small-step rule that does not change the context and only mentions one variable, then it suffices to assume that that variable is the only variable in the context.}
          \label{FigSoundnessOoptoContext}
      \end{SidewaysFigure}

      Now the commutative diagrams in Figure \ref{FigSoundnessOoptoStorage} prove that
      \[
        \seqdeno{x,s\vert_x\ts x\gets n} = \seqdeno{x,(x\mapsto n)\ts \skipp}
        \]
      and that
      \[
        \seqdeno{x,s\vert_x\ts \oc x} = \seqdeno{x,s\vert_x\ts s(x)}\,,
        \]
      completing the proof.\qedhere
      \begin{figure}[htbp]
        \begin{mathpar}
          \begin{tikzcd}[column sep=41pt, row sep=30pt]
            I \arrow[r, "\oc s(x)"] \arrow[d, "\oc n" description] \arrow[dr, Rightarrow, no head]
              & \oc \bN \arrow[r, "\cell"] \arrow[d, "()" description] \arrow[dr, "\cell_0" description]
                & \oc\Varr \arrow[r, "\mu_{\Varr}"] \arrow[dd, "\alpha_{\Varr}" description, controls={+(1,-0.25) and +(0.8,0.75)}, start anchor={[yshift=-1pt]}, end anchor = {[xshift=25pt]}] \arrow[dr, phantom, "\text{P. \ref{PropFormulaForAlpha}}" {xshift=20pt, yshift=-7pt}]
                  & \oc \Varr \tensor \oc \Varr \arrow[d, "\der_{\Varr} \tensor \oc\Varr" {description, near start}]  \\
            \oc\bN \arrow[dd, "\cell" description] \arrow[ddr, "\lunit_{\oc\bN}" description, end anchor={[xshift=-3pt, yshift=-2pt]}] \arrow[ddrr, phantom, "\text{L. \ref{LemCellProjections}}" {xshift=2pt, yshift=20pt}]
              & I \arrow[l, "\oc n" description]
                & \Varr \sequoid \oc\bN \arrow[d, "\Varr\sequoid\cell" description] \arrow[dd, "\pr_n\sequoid\oc\bN" {description, pos=0.44}, controls={+(-2.5,-0.2) and (-0.5,0.5)}]
                  & \Varr \tensor \oc\Varr \arrow[dl, "{\wk_{\Varr,\oc\Varr}}" description] \arrow[dd, "\pr_n\tensor\oc\Varr" description] \\
            %
              & \bC \tensor \oc\bN \arrow[dr, "{\wk_{\bC,\oc\bN}}" description] \arrow[ddr, "\bC \tensor \cell" description]
                & \Varr \sequoid\oc\Varr \arrow[ddr, "\pr_n\sequoid\oc\Varr" description]
                  & \\
            \oc\Varr \arrow[d, "\mu_{\Varr}" description] \arrow[dr, "\lunit_{\oc\Varr}" description]
              & I \tensor \oc\bN \arrow[u, "\skipp\tensor\oc\bN" {description, pos=0.44}] \arrow[d, "I\tensor \cell" description]
                & \bC \sequoid \oc\bN \arrow[dr, "\bC \sequoid \cell" description]
                  & \bC \tensor \oc\Varr \arrow[d, "{\wk_{\bC,\oc\Varr}}" {description, pos=0.44}] \\
            \oc\Varr \tensor \oc\Varr \arrow[r, "()\tensor\oc\Varr"']
              & I \tensor \oc\Varr \arrow[r, "\skipp \tensor \oc\Varr"']
                & \oc\bC \tensor \oc\Varr \arrow[r, "{\wk_{\bC,\oc\Varr}}"']
                  & \bC \sequoid \oc\Varr
          \end{tikzcd}
          \and
          \begin{tikzcd}[row sep=30pt]
            I \arrow[r, "\oc s(x)"] \arrow[d, "\oc s(x)" description] \arrow[dr]
              &[-31pt] \oc\bN \arrow[r, "\cell"] \arrow[dr, "\mu_\bN" description] \arrow[ddr, "\cell_0" {description, near end}, bend left=50, end anchor={[xshift=4pt]}] \arrow[ddd, phantom, "\text{L.\ref{LemCellProjections}}" {xshift=3pt,yshift=-7pt}]
                &[-100pt] \oc\Varr \arrow[r, "\mu_{\Varr}"] \arrow[ddd, "\alpha_{\Varr}" description] \arrow[dr, phantom, "\text{P.\ref{PropFormulaForAlpha}}", {yshift=-5pt}]
                  &[-21pt] \oc\Varr \tensor \oc\Varr \arrow[d, "\der_{\Varr}\tensor\oc\Varr" {description, near start}] \\
            |[alias=Z]| \oc\bN \arrow[d, "\lunit_{\oc\bN}" description] \arrow[dd, "\cell" description]
              & |[left=40pt of Z.east]| I \tensor I \arrow[dl, "I \tensor \oc s(x)" description] \arrow[r, "\oc s(x) \tensor \oc s(x)"] \arrow[d, "s(x)\tensor \oc s(x)" description]
                & |[left=50pt of Z.west]| \oc \bN \tensor \oc\bN \arrow[dl, "\der_\bN \tensor \oc\bN" {description, near start}, bend right=10]
                  & \Varr \tensor \oc\Varr \arrow[ddl, "{\wk_{\Varr,\oc\Varr}}" {description, pos=0.65}] \arrow[dd, "\pr_{\bN}\tensor\oc\Varr" description] \\
            |[right=of Z.west]| I \tensor \oc\bN \arrow[r, "s(x)\tensor\oc\bN"'] \arrow[ddr, "I \tensor \cell" description]
              & \bN \tensor \oc\bN \arrow[d, "{\wk_{\bN,\oc\bN}}" description] \arrow[ddr, "\bN \tensor\cell" {description, pos=0.4, xshift=-5pt}, bend right=30]
                & |[left=of Z]| \Varr \sequoid \oc\bN \arrow[dl, "\pr_\bN \sequoid \oc\bN" {description, pos=0.65}, bend left=30] \arrow[d, "\Varr\sequoid\cell" {description, xshift=-5pt}, bend left=30]
                  & \\
            \oc\Varr \arrow[d, "\mu_{\Varr}" description] \arrow[dr, "\lunit_{\Varr}" description]
              & |[right=of Z]| \bN \sequoid \oc\bN \arrow[drr, "\bN \sequoid \cell" {description, pos=0.4}, controls={+(0.2,-1.2) and +(-0.3,0.2)}, to=Y.north west, end anchor={[yshift=-2pt]}]
                & \Varr \sequoid\oc\Varr \arrow[dr, "\pr_\bN \sequoid \oc\Varr" {description, pos=0.35}]
                  & \bN \tensor \oc\Varr \arrow[d, "{\wk_{\bN},\oc\Varr}" description] \\
            \oc\Varr \tensor \oc\Varr \arrow[r, "()\tensor\oc\Varr"']
              & I \tensor \oc\Varr \arrow[r, "s(x)\tensor\oc\Varr"']
                & \bN \tensor \oc\Varr \arrow[r, "{\wk_{\bN,\oc\Varr}}"']
                  & |[alias=Y]| \bN \sequoid \oc\Varr
          \end{tikzcd}
        \end{mathpar}
        \caption[Diagrams to prove that the conclusion of Lemma \ref{LemSoundnessOopto} holds for the storage cell rules.]{Diagrams to prove that the conclusion of Lemma \ref{LemSoundnessOopto} holds for the storage cell rules.  
        References in the middle of a shape refer to Lemma \ref{LemCellProjections} and Proposition \ref{PropFormulaForAlpha} above.  
        Note the prominent role played in both diagrams by the anamorphism square for $\cell$ as in Section \ref{SecCell}.}
        \label{FigSoundnessOoptoStorage}
      \end{figure}
  \end{itemize}
\end{proof}

Now that we have dealt with the base rules, we can move on to the full relation $\opto$.

\begin{lemma}
  The relation $\opto$ between triples $\Gamma,s\ts M$ preserves the composite
  \[
    \oc\deno s;\cell^\Gamma;\mu_{\V_\Gamma};(\deno{\Gamma\ts M}\tensor\oc\V_\Gamma);\wk_{\deno T,\oc\V_\Gamma}\,.
    \]
  I.e., if $\Gamma,s\ts M \oopto \Gamma,\Delta,s'\ts N$, where $M,N$ have type $T$, and $\EE$ is a context of type $U$ with a hole of type $T$, then the following diagram commutes.
  \[
    \begin{tikzcd}[column sep=24pt]
      I \arrow[r, "\oc \deno s"] \arrow[d, "\oc \deno {s'}"']
        & \oc S_\Gamma \arrow[r, "\cell^\Gamma"]
          & \oc \V_\Gamma \arrow[r, "\mu_{\V_\Gamma}"]
            &[22pt] \oc \V_\Gamma \tensor \oc \V_\Gamma \arrow[d, "\deno{\Gamma\ts \EE[M]}\tensor \oc V_\Gamma"] \\
      {\oc S_{\Gamma,\Delta}} \arrow[d, "{\cell^{\Gamma,\Delta}}"']
        &
          &
            & \deno U \tensor \oc V_\Gamma \arrow[d, "{\wk_{\deno U,\oc \V_{\Gamma}}}"] \\
      {\oc \V_{\Gamma,\Delta}} \arrow[d, "{\mu_{\V_{\Gamma,\Delta}}}"']
        &
          &
            &  \deno{U}\sequoid \oc\V_\Gamma \arrow[d, "{\deno{U} \sequoid (\Gamma+0_\Delta)}"] \\
      {\oc \V_{\Gamma,\Delta} \tensor \oc \V_{\Gamma,\Delta}} \arrow[rr, "{\deno{\Gamma,\Delta\ts \EE[N]} \tensor \oc \V_{\Gamma,\Delta}}"]
        &
          & {\deno U \tensor \oc \V_{\Gamma,\Delta}} \arrow[r, "{\wk_{\deno U,\oc \V_{\Gamma,\Delta}}}"]
            & {{\deno U \sequoid \oc \V_{\Gamma,\Delta}}\,,}
    \end{tikzcd}
    \]
  \label{LemSoundnessOpto}
\end{lemma}
\begin{proof}
  We use Lemma \ref{LemEvContexLemma} to reduce this to Lemma \ref{LemSoundnessOpto}.  
  Indeed, Lemma \ref{LemEvContexLemma} tells us that for any $\Gamma,s\ts M$, $\deno{\Gamma\ts \EE[M]}$ may be written as
  \[
    \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma\tensor\oc\V_\Gamma \xrightarrow{\deno{\Gamma\ts M}\tensor\sigma} \deno T \tensor A \xrightarrow{\wk_{\deno T,A}} \deno T \sequoid A \xrightarrow{\tau} \deno U
    \]
  for suitably chosen $A,\sigma,\tau$.

  Let us write $\seqdeno{\Gamma,s\ts M}$ for the composite
  \[
    \oc\deno s;\cell^\Gamma;\mu_{\V_\Gamma};(\deno{\Gamma\ts M}\tensor\oc\V_\Gamma);\wk_{\deno T,\oc\V_\Gamma};(\deno T \sequoid (\Gamma+0_\Delta))\,.
    \]
  So we are trying to show that $\seqdeno{\Gamma,s\ts \EE[M]}=\seqdeno{\Gamma,\Delta,s'\ts \EE[N]};(\deno U \sequoid \oc\pr_\Gamma)$.

  Now the diagram in Figure \ref{FigSoundnessOpto} shows us that for any $\Gamma,s\ts M$ we may write
  \[
    \seqdeno{\Gamma,s\ts \EE[M]} = \seqdeno{\Gamma,s\ts M};(\deno T \sequoid (\mu_{\V_\Gamma};(\sigma\tensor\oc\V_\Gamma));\passoc_{\deno T,A,\oc\V_\Gamma}\inv;(\tau\sequoid\oc\V_\Gamma)\,.
    \]

  \begin{SidewaysFigure}
    \[
      \begin{tikzcd}[column sep=45pt, row sep=30pt, ampersand replacement=\&]
        \oc S_\Gamma \arrow[d, "\cell^\Gamma"', thick]
          \& I \arrow[l, "\oc\deno s"', thick]
            \&
              \& \\
        \oc\V_\Gamma \arrow[r, "\mu_{\V_\Gamma}", thick] \arrow[d, "\mu_{\V_\Gamma}"', thick, dashed]
          \& \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[r, "\deno{\Gamma\ts M}\tensor\oc\V_\Gamma", thick] \arrow[dd, "\oc\V_\Gamma\tensor\mu_{\V_\Gamma}" description, dotted]
            \& \deno T \tensor \oc\V_\Gamma \arrow[r, "{\wk_{\deno T,\oc\V_\Gamma}}", thick] \arrow[dd, "\deno T \tensor \mu_{\V_\Gamma}" description, dotted]
              \& \deno T \sequoid \oc\V_\Gamma \arrow[dd, "\deno T \sequoid \mu_{\V_\Gamma}"] \\
        \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[d, "\mu_{\V_\Gamma}\tensor\oc\V_\Gamma"', thick, dashed]
          \&
            \&
              \& \\
        (\oc\V_\Gamma \tensor \oc\V_\Gamma) \tensor \oc\V_\Gamma \arrow[r, "{\assoc_{\oc\V_\Gamma,\oc\V_\Gamma,\oc\V_\Gamma}}" yshift=3pt, dotted] \arrow[d, "(\deno{\Gamma\ts M}\tensor \sigma) \tensor\oc\V_\Gamma"', thick, dashed]
          \& \oc\V_\Gamma \tensor (\oc\V_\Gamma \tensor \oc\V_\Gamma) \arrow[r, "\deno{\Gamma\ts M} \tensor (\oc\V_\Gamma\tensor \oc\V_\Gamma)" yshift=3pt, dotted] \arrow[d, "\deno{\Gamma\ts M}\tensor (\sigma\tensor\oc\V_\Gamma)" description, dotted]
            \& \deno T \tensor (\oc\V_\Gamma\ \tensor \oc\V_\Gamma) \arrow[r, "{\wk_{\deno T,\oc\V_\Gamma\tensor\oc\V_\Gamma}}" yshift=3pt, dotted] \arrow[dl, "\deno T \tensor (\sigma \tensor\oc\V_\Gamma)" description, dotted]
              \& \deno T \sequoid (\oc\V_\Gamma \tensor \oc\V_\Gamma) \arrow[d, "\deno T \sequoid (\sigma \tensor \oc\V_\Gamma)"] \\
        (\deno T \tensor A) \tensor \oc\V_\Gamma \arrow[d, "{\wk_{\deno T,A}\tensor\oc\V_\Gamma}"', thick, dashed] \arrow[r, "{\assoc_{\deno T,A,\oc\V_\Gamma}}", dotted]
          \& \deno T \tensor (A \tensor \oc\V_\Gamma) \arrow[rr, "{\wk_{\deno T,A\tensor\oc\V_\Gamma}}", dotted]
            \&
              \& \deno T \sequoid (A \tensor \oc\V_\Gamma) \\
        (\deno T \sequoid A) \tensor \oc\V_\Gamma \arrow[r, "{\wk_{\deno T\sequoid A,\oc\V_\Gamma}}", dotted] \arrow[d, "\tau\tensor\oc\V_\Gamma", thick, dashed]
          \& (\deno T \sequoid A) \sequoid \oc\V_\Gamma \arrow[d, "\tau\sequoid\oc\V_\Gamma"] \arrow[urr, "{\passoc_{\deno T,A,\oc\V_\Gamma}}"']
            \&
              \& \\
        \deno U \tensor \oc\V_\Gamma \arrow[r, "{\wk_{\deno U,\oc\V_\Gamma}}", thick, dashed]
          \& \deno U \sequoid \oc\V_\Gamma
            \&
              \&
      \end{tikzcd}
      \]
      \caption{Diagram proving that the conclusion of Lemma \ref{LemSoundnessOopto} can be lifted to the $\opto$ relation.}
      \label{FigSoundnessOpto}
  \end{SidewaysFigure}

  Therefore, Lemma \ref{LemSoundnessOopto} tells us that if $\Gamma,s\ts M \oopto \Gamma,\Delta,s'\ts N$, then we have
  \begin{IEEEeqnarray*}{Cl}
    & \seqdeno{\Gamma,s\ts \EE[M]} \\
    = & \seqdeno{\Gamma,s\ts M};(\deno T\sequoid(\mu_{\V_\Gamma};(\sigma\tensor\oc\V_\Gamma));\passoc\inv;(\tau\sequoid\oc\V_\Gamma) \\
    = & \seqdeno{\Gamma,s\ts N};(\deno T \sequoid \oc\pr_\Gamma);(\deno T\sequoid(\mu_{\V_\Gamma};(\sigma\tensor\oc\V_\Gamma));\passoc\inv;(\tau\sequoid\oc\V_\Gamma) \\
    = & \seqdeno{\Gamma,s\ts N};(\deno T \sequoid (\mu_{\V_{\Gamma,\Delta}};((\pr_\Gamma;\sigma)\tensor\oc\V_{\Gamma,\Delta})));\passoc\inv; \\
    &\qquad(\tau\sequoid\oc\V_\Gamma);(\deno U\sequoid\oc\pr_\Gamma) \\
    = & \seqdeno{\Gamma,s\ts \EE[N]};(\deno U\sequoid\oc\pr_\Gamma)\,,
  \end{IEEEeqnarray*}
  as desired.
\end{proof}

It is now a simple induction to show that we can extend this to the $\converges$ relation.

\begin{lemma}
  Suppose that $\Gamma,s\ts M \converges c,s'$, where $M,c\from T$.
  Then the following diagram commutes.
  \[
    \begin{tikzcd}[column sep=40pt]
      I \arrow[r, "\oc\deno s"] \arrow[d, "\oc\deno{s'}"']
        & \oc S_\Gamma \arrow[r, "\cell^\Gamma"]
          & \oc\V_\Gamma \arrow[r, "\mu_{\V_\Gamma}"]
            & \oc\V_\Gamma\tensor\oc\V_\Gamma \arrow[d, "\deno{\Gamma\ts M}\tensor\oc\V_\Gamma"] \\
      \oc S_\Gamma \arrow[d, "\cell^\Gamma"']
        &
          &
             & \deno{T} \tensor \oc\V_\Gamma \arrow[d, "{\wk_{\deno T,\oc\V_\Gamma}}"] \\
      \oc\V_\Gamma \arrow[r, "\mu_{\V_\Gamma}"]
        & \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[r, "\deno{\Gamma\ts c}\tensor\oc\V_\Gamma"]
          & \deno T \tensor \oc\V_\Gamma \arrow[r, "{\wk_{\deno T,\oc\V_\Gamma}}"]
            & \deno T \sequoid \oc\V_\Gamma
    \end{tikzcd}
    \]
  \label{LemSoundness}
\end{lemma}
\begin{proof}
  By Proposition \ref{PropBigToSmall}, there are sequences $\Gamma=\Gamma_1,\cdots,\Gamma_n=\Gamma,\Delta$, $s=s^{(1)},\cdots,s^{(n)}$, $M=M_1,\cdots,M_n=c$ such that
  \[
    \Gamma_1,s^{(1)}\ts M_1 \opto \cdots \opto \Gamma_n,s^{(n)} \ts M_n\,,
    \]
  and $s^{(n)}\vert_\Gamma = s'$.

  By inductively applying Lemma \ref{LemSoundnessOpto}, we see that we have a commutative diagram
  \[
    \begin{tikzcd}[column sep=28pt]
      I \arrow[r, "\oc \deno s"] \arrow[d, "\oc \deno {s^{(n)}}"']
        & \oc S_\Gamma \arrow[r, "\cell^\Gamma"]
          & \oc \V_\Gamma \arrow[r, "\mu_{\V_\Gamma}"]
            &[22pt] \oc \V_\Gamma \tensor \oc \V_\Gamma \arrow[d, "\deno{\Gamma\ts M}\tensor \oc V_\Gamma"] \\
      {\oc S_{\Gamma,\Delta}} \arrow[d, "{\cell^{\Gamma,\Delta}}"']
        &
          &
            & \deno T \tensor \oc V_\Gamma \arrow[d, "{\wk_{\deno T,\oc \V_{\Gamma}}}"] \\
      {\oc \V_{\Gamma,\Delta}} \arrow[d, "{\mu_{\V_{\Gamma,\Delta}}}"']
        &
          &
            &  \deno{T}\sequoid \oc\V_\Gamma \\
      {\oc \V_{\Gamma,\Delta} \tensor \oc \V_{\Gamma,\Delta}} \arrow[rr, "{\deno{\Gamma,\Delta\ts c} \tensor \oc \V_{\Gamma,\Delta}}"]
        &
          & {\deno T \tensor \oc \V_{\Gamma,\Delta}} \arrow[r, "{\wk_{\deno T,\oc \V_{\Gamma,\Delta}}}"]
            & {{\deno T \sequoid \oc \V_{\Gamma,\Delta}}\,,} \arrow[u, "\deno T \sequoid \oc\pr_\Gamma"]
    \end{tikzcd}
    \]
  Now, since $s^{(n)}\vert_\Gamma = s'$, we have a commutative diagram
  \[
    \begin{tikzcd}[column sep=50pt]
      I \arrow[r, "\deno {s'}"] \arrow[d, "\deno{s^{(n)}}"']
        & \oc S_\Gamma \arrow[dd, "\cell^\Gamma"] \\
      {\oc S_{\Gamma,\Delta}} \arrow[ur, "\oc\pr_\Gamma" description] \arrow[d, "{\cell^{\Gamma,\Delta}}"']
        & \\
      {\oc\V_{\Gamma,\Delta}} \arrow[r, "\oc\pr_\Gamma"] \arrow[d, "{\mu_{\V_{\Gamma,\Delta}}}"']
        & \oc\V_\Gamma \arrow[d, "\mu_{\V_\Gamma}"] \\
      {\oc\V_{\Gamma,\Delta}\tensor\oc\V_{\Gamma,\Delta}} \arrow[d, "{\deno{\Gamma,\Delta\ts c}\tensor\oc\V_{\Gamma,\Delta}}"'] \arrow[r, "\oc\pr_\Gamma\tensor\oc\pr_\Gamma"]
        & \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[d, "\deno{\Gamma\ts c}\tensor\oc\V_\Gamma"]  \\
      {\deno T \tensor \oc\V_{\Gamma,\Delta}} \arrow[r, "\deno T \tensor \oc\pr_\Gamma"] \arrow[d, "{\wk_{\deno T,\oc\V_{\Gamma,\Delta}}}"']
        & \deno T \tensor \oc\V_\Gamma \arrow[d, "{\wk_{\deno T,\oc\V_\Gamma}}"] \\
      {\deno T \sequoid \oc\V_{\Gamma,\Delta}} \arrow[r, "\deno T \sequoid \oc\pr_\Gamma"]
        & \deno T \sequoid \oc\V_\Gamma \\
    \end{tikzcd}
    \]
  which, together with the diagram above, gives us the commutative diagram in the statement.
\end{proof}

It is then an easy corollary to show the sense in which our semantics is sound.

\begin{proposition}[\cite{SamsonGuyIAActive}]
  Suppose that $\Gamma,s\ts M\converges c,s'$.  
  Then
  \[
    \deno s;\cell^\Gamma;\deno{\Gamma\ts M} = \deno{s'};\cell^\Gamma;\deno{\Gamma\ts c}\,.
    \]
\end{proposition}
\begin{proof}
  Lemma \ref{LemSoundness}, plus the fact that if $\Gamma,s\ts P\from T$, then we have a commutative diagram
  \[
    \begin{tikzcd}[column sep=14.5pt]
      I \arrow[r, "\deno{s}", thick]
        & \oc S_\Gamma \arrow[r, "\cell^\Gamma", thick]
          & \oc\V_\Gamma \arrow[rr, "\mu_{\V_\Gamma}", thick, dashed] \arrow[ddd, "\deno{\Gamma\ts P}"', thick] \arrow[drr, "\runit_{\oc\V_\Gamma}" description, dotted]
            &
              & \oc\V_\Gamma \tensor \oc\V_\Gamma \arrow[rr, "\deno{\Gamma\ts P}\tensor\oc\V_\Gamma", thick, dashed] \arrow[d, "\oc\V_\Gamma\tensor()" description, dotted]
                &
                  & \deno T \tensor\oc\V_\Gamma \arrow[ddd, "{\wk_{\deno T,\oc\V_\Gamma}}" description, thick, dashed] \arrow[ddl, "\deno T \tensor ()" description, dotted] \\
      %
        &
          &
            &
              & \oc\V_\Gamma \tensor I \arrow[dr, "\deno{\Gamma\ts P}\tensor I" description, dotted] \arrow[dl, "{\wk_{\oc\V_\Gamma,I}}" description, dotted]
                &
                  & \\
      %
        &
          &
            & \oc\V_\Gamma \sequoid I \arrow[dr, "\deno{\Gamma\ts P}\sequoid I" description, dotted] \arrow[uul, "\run_{\oc\V_\Gamma}" description, dotted]
              &
                & \deno T \tensor I \arrow[dl, "{\wk_{\deno T,I}}" description, dotted]
                  & \\
      %
        &
          & \deno T
            &
              & \deno T \sequoid I \arrow[ll, "{\run_{\deno T}}"']
                &
                  & \deno T \sequoid \oc\V_\Gamma \arrow[ll, "\deno T \sequoid()"']\,,
    \end{tikzcd}
    \]
  allowing us to recover $\deno{s};\cell^\Gamma;\deno{\Gamma\ts P}$ from 
  \[
    \seqdeno{\Gamma,s\ts P} = \deno{s};\cell^\Gamma;\mu_{\V_\Gamma};(\deno{\Gamma\ts P}\tensor\oc\V_\Gamma);\wk_{\deno T,\oc\V_\Gamma}\,,
    \]
  for $P=M,c$.
\end{proof}

\section{Computational Adequacy}

Our proof of computational adequacy is based on that from \cite{SamsonGuyIAActive}, but modified to make use of the coalgebraic definition of the $\cell$ strategy.  
As is usual in proofs of computational adequacy, our proof relies on logical relations.

First, we note some additional order-theoretic properties of our model.  
For any game $A$, we have a strategy $\bot_A\from A$, given by $\bot_A=\{\epsilon\}$; i.e., the strategy that has no reply even for the very first move.  
It is clear that $\bot$ is the bottom element of the set of strategies for $A$, ordered by inclusion.  

It is then easy to see the following.
\begin{proposition}
  \begin{itemize}
    \item Given $\sigma\from A \implies B$, $\sigma;\bot_{B\implies C}=\bot_{A\implies C}$.
    \item Given a strict strategy $\tau\from B\implies C$, $\bot_{A\implies B};\tau=\bot_{A\implies C}$.
    \item Given a zigzag (copycat) strategy $\zz_\phi\from B \implies C$ and a strategy $\sigma\from A\implies B$, if $\sigma;\zz_\phi=\bot_{A\implies C}$ then $\sigma=\bot_{A\implies B}$.
  \end{itemize}
\end{proposition}

\begin{definition}
  Given a $\Var$-store $\Gamma$, a strategy $\sigma\from\oc\V_\Gamma \implies A$ and a $\Gamma$-store $s$, we write
  \[
    \seqdeno{s,\sigma}
    \]
  for the composite
  \[
    I \xrightarrow{\oc\deno s} \oc S_\Gamma \xrightarrow{\cell^\Gamma} \oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\sigma\tensor\oc\V_\Gamma} A \tensor \oc\V_\Gamma \xrightarrow{\wk_{A,\oc\V_\Gamma}} A \sequoid \oc\V_\Gamma\,.
    \]
  In particular, if $\Gamma\ts M\from T$ is a term in context, then $\seqdeno{s,\deno{\Gamma\ts M}}$ is equal to the sequoidal denotation $\seqdeno{\Gamma,s\ts M}$.
\end{definition}

\begin{definition}
  We inductively define a relation $\plot_T^\Gamma$, where $\Gamma$ is a $\Var$-store and $T$ a type, between strategies for $\oc\V_\Gamma \implies \deno T$ and terms $\Gamma\ts M\from T$ in context as follows.
  \begin{itemize}
    \item If $X\in\{\bC,\bB,\bN\}$ is a datatype, $M\from X$ and $\sigma\from \oc\V_\Gamma\implies X$, then we say that $\sigma \plot_X^\Gamma u$ if for all $\Gamma$-stores $s$, either $\seqdeno{s,\sigma}=\bot_{A\sequoid\oc\V_\Gamma}$ or $\seqdeno{s,\sigma}=\seqdeno{s',u}$ for some $\Gamma$-store $s'$ and some canonical form $u\in X$ such that $\Gamma,s\ts M \converges u,s'$.

    \item If $\sigma\from \oc\V_\Gamma \implies \Varr$ and $\Gamma\ts M\from \Var$, we say that $\sigma\plot_{\Var}^\Gamma M$ if
      \[
        \sigma;\pr_n\plot_{\com}^\Gamma M\gets n
        \]
      for all $n$, and if
      \[
        \sigma;\pr_{\bN}\plot_{\nat}^\Gamma \oc M\,.
        \]
      
    \item If $\sigma \from \oc\V_\Gamma \implies (\oc\deno{S} \implies \deno T)$ and $M\from S \to T$, we say that $\sigma\plot_{S\to T}^\Gamma M$ if whenever $\tau\from \oc\V_\Gamma \implies \deno S$ is a strategy and $N\from S$ is a term such that $\tau\plot_S^\Gamma N$, then
      \[
        \left(\oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\sigma\tensor\tau^\dag} (\oc\deno S \implies \deno T) \tensor \oc\deno S \xrightarrow{\ev} \deno T\right) \plot_T^\Gamma M\,N\,,
        \]
      and in addition if $S=\Var$ and $T=X$ for some datatype $X$, then
      \small
      \[
        \left(\oc\V_\Gamma \xrightarrow{\mu_{\V_\Gamma}} \oc\V_\Gamma \tensor \oc\V_\Gamma \xrightarrow{\sigma\tensor \cell} (\oc\Varr \implies X) \tensor \oc\Varr \xrightarrow{\ev} X\right) \plot_X^\Gamma \neww_X (\lambda x.M\,x)\,.
        \]
      \normalsize
  \end{itemize}
\end{definition}

\begin{lemma}
  Let $\Gamma\ts M,N\from T$ be terms in context of Idealized Algol such that
  \[
    \Gamma,s\ts M\opto \Gamma,s\ts N
    \]
  for all $\Gamma$-stores $s$.  
  Suppose $\sigma\from\oc\V_\Gamma\implies\deno T$ is a strategy such that $\sigma\plot_T^\Gamma N$.  
  Then $\sigma\plot_T^\Gamma M$.
\end{lemma}
\begin{proof}
  Induction on $T$.

  Suppose that $\Gamma,s\ts M,N\ts X$, where $X$ is some datatype, and that $\Gamma,s\ts M\opto \Gamma,s\ts N$ for all $\Gamma$-stores $s$.  
  Fix some $\Gamma$-store $s$ and some strategy $\sigma\from \oc\V_\Gamma\implies \deno T$, and suppose that $\sigma\plot_T^\Gamma N$.  

  If $\seqdeno{s,\sigma}\ne\bot_{\oc\V_\Gamma\implies X}$, then by hypothesis it is equal to $\seqdeno{s',u}$ for some $u$ such that $\Gamma,s\ts N\converges u,s'$.  
  Then, by Lemma \ref{LemSmallToBig}, $\Gamma,s\ts M\converges u,s'$.

  If $\Gamma,s\ts M,N\from \Var$ and $\sigma\plot_\Var^\Gamma N$, then we have $\sigma;\pr_n\plot_\com^\Gamma N\gets n$ for each $n$ and $\sigma;\pr_\bN\plot_\nat^\Gamma \oc N$.  
  If $\Gamma,s\ts M\opto \Gamma,s\ts N$, then $\Gamma,s\ts M\gets n\opto\Gamma,s\ts N\gets n$ for each $n$ and $\Gamma,s\ts \oc M\opto\Gamma,s\ts \oc N$.  
  Then, by the previous paragraph, we must have $\sigma;\pr_n\plot_{\com}^\Gamma M\gets n$ for each $n$ and $\sigma;\pr_\bN\plot_{\nat}^\Gamma \oc M$, and therefore $\sigma\plot_{\Var}^\Gamma M$.

  Lastly, suppose that 
\end{proof}

\begin{lemma}
  Let $\Gamma$ be a $\Var$-context, let $\Delta$ be an arbitrary context and let $T$ be an Idealized Algol type.
  Write $\Delta=x_1\from T_1,\cdots,x_n\from T_n$.  
  Suppose that $\sigma_i\from \oc\V_\Gamma \implies \deno{T_i}$ are strategies and $\Gamma\ts N_i\from T_i$ are terms-in-context such that $\sigma_i\plot_{T_i}^\Gamma N_i$ for each $i$.  

  Given a strategy $\sigma\from \oc\V_{\Gamma,\Delta}\implies \deno{T}$, we write
  \[
    (\sigma_i)\semicom \sigma
    \]
  for the composite
  \[
    \oc\V_\Gamma \xrightarrow{\langle \oc\V_\Gamma,\sigma_1^\dag,\cdots,\sigma_n^\dag\rangle} \oc\V_{\Gamma,\Delta} \xrightarrow{\sigma} \deno{T}\,.
    \]

  Then for any term-in-context $\Gamma,\Delta \ts M\from T$, we have
  \[
    (\sigma_i)\semicom\deno{\Gamma\ts M} \plot_T^{\Gamma} M[N_i/x_i]\,.
    \]
\end{lemma}

\bibliographystyle{alpha2}
\bibliography{../common/phd_bibliography}

\end{document}
